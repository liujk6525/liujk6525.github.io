<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="/lib/pace/pace-theme-mac-osx.min.css"><script src="/lib/pace/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"liujk6525.github.io",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"right",width:320,display:"always",padding:5,offset:12,onmobile:!0},copycode:{enable:!0,show_result:!0,style:"mac"},back2top:{enable:!1,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="角点特征 如下图所示，蓝色框中的区域是一个平面，无论向哪个方向移动蓝色框，都是一样的。对于黑色框中的区域，它是一个边缘。如果沿垂直方向移动，它会改变。但是如果沿水平方向移动就不会改变。而红色框中的角点，无论你向那个方向移动，得到的结果都不同，这说明它是唯一的。 所以说，角点是一个好的图像特征。"><meta property="og:type" content="article"><meta property="og:title" content="图像特征提取与描述"><meta property="og:url" content="https://liujk6525.github.io/OpenCV/%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%B8%8E%E6%8F%8F%E8%BF%B0/index.html"><meta property="og:site_name" content="你不是单打独斗"><meta property="og:description" content="角点特征 如下图所示，蓝色框中的区域是一个平面，无论向哪个方向移动蓝色框，都是一样的。对于黑色框中的区域，它是一个边缘。如果沿垂直方向移动，它会改变。但是如果沿水平方向移动就不会改变。而红色框中的角点，无论你向那个方向移动，得到的结果都不同，这说明它是唯一的。 所以说，角点是一个好的图像特征。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191008141945745-1684510965118-1.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191008144647540-1684511183358-3.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191008153014984-1684511417820-5.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191008160908338-1684512358754-7.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191008161040473-1684512385628-9.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191008161904372-1684512700094-11.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191008164344988-1684512767151-13.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191008174257711.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191008181535222-1684547971195-2.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191009110944907-1684549584975-4.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191009113953721-1684549912508-6.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191009115023016-1684549955480-8.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191009143818527-1684552168908-10.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191009144726492-1684552637576-16.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191009150008701-1684552598604-14.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191025112522974-1684552568027-12.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191009161647267-1684552834400-18.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191009161756423-1684552865043-20.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191009162914982-1684552898801-22.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191009181525538-1684553395070-26.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191016163330835-1684553312569-24.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image17-1684555943527-30.jpg"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191010114459269-1684556434454-32.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191010120822413-1684557401983-34.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191010153907973-1684559140937-36.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191010161944491-1684559749207-38.png"><meta property="og:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191010162532196-1684559841023-40.png"><meta property="article:published_time" content="2023-05-19T15:38:12.000Z"><meta property="article:modified_time" content="2023-05-26T05:22:33.647Z"><meta property="article:author" content="一月十号"><meta property="article:tag" content="Jupyter Notebook"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://liujk6525.github.io/imgs/$%7Bfiilename%7D/image-20191008141945745-1684510965118-1.png"><link rel="canonical" href="https://liujk6525.github.io/OpenCV/%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%B8%8E%E6%8F%8F%E8%BF%B0/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><link rel="stylesheet" type="text/css" href="/css/injector/main.css"><link rel="preload" as="style" href="/css/injector/light.css"><link rel="preload" as="style" href="/css/injector/dark.css"><title>图像特征提取与描述 | 你不是单打独斗</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/liujk6525" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#fd6c6c;color:#fff;position:absolute;top:0;border:0;right:0" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">你不是单打独斗</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">问所闻而来，见所见而去</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">14</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">8</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">34</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://liujk6525.github.io/OpenCV/%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%B8%8E%E6%8F%8F%E8%BF%B0/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="一月十号"><meta itemprop="description" content=""></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="你不是单打独斗"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">图像特征提取与描述</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-05-19 23:38:12" itemprop="dateCreated datePublished" datetime="2023-05-19T23:38:12+08:00">2023-05-19</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-05-26 13:22:33" itemprop="dateModified" datetime="2023-05-26T13:22:33+08:00">2023-05-26</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a> </span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span id="busuanzi_value_page_pv"></span></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>13k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>12 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="角点特征">角点特征</h1><p>如下图所示，蓝色框中的区域是一个平面，无论向哪个方向移动蓝色框，都是一样的。对于黑色框中的区域，它是一个边缘。如果沿垂直方向移动，它会改变。但是如果沿水平方向移动就不会改变。而红色框中的角点，无论你向那个方向移动，得到的结果都不同，这说明它是唯一的。 所以说，角点是一个好的图像特征。</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191008141945745-1684510965118-1.png" style="zoom:80%"></p><span id="more"></span><h1 id="harris和shi-tomas算法">Harris和Shi-Tomas算法</h1><h2 id="harris角点检测">Harris角点检测</h2><p>Harris角点检测的思想是通过图像的局部的小窗口观察图像，角点的特征是窗口沿任意方向移动都会导致图像灰度的明显变化，如下图所示：</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191008144647540-1684511183358-3.png" style="zoom:33%"></p><p>将局部窗口向各个方向移动<span class="math inline">\((u,v)\)</span>，并计算所有灰度差异的总和，表达式如下： <span class="math display">\[ E(u,v)=\sum_{x,y}w(x,y)[I(x+u,y+v)-I(x,y)]^2 \]</span> 其中<span class="math inline">\(E(u,v)\)</span>是局部窗口的图像灰度，<span class="math inline">\(I(x+u,y+v)\)</span>是平移后的图像灰度，<span class="math inline">\(w(x,y)\)</span>是窗口函数，该可以是矩形窗口，也可以是对每一个像素赋予不同权重的高斯窗口，如下所示：</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191008153014984-1684511417820-5.png" style="zoom:50%"></p><p>角点检测中使<span class="math inline">\(E(u,v)\)</span>的值最大。利用一阶泰勒展开有： <span class="math display">\[ I(x+u,y+v)=I(x,y)+I_xu+I_yv \]</span> 其中<span class="math inline">\(I_x\)</span>和<span class="math inline">\(I_y\)</span>是沿<span class="math inline">\(x\)</span>和<span class="math inline">\(y\)</span>方向的导数，可用<code>sobel算子</code>计算 <span class="math display">\[ E(u,v)=\sum_{x,y}w(x,y)[I(x+u,y+v)-I(x,y)]^2 \]</span> <span class="math display">\[ =\sum_{x,y}w(x,y)[I(x,y)+I_xu+I_yv-I(x,y)]^2 \]</span></p><p><span class="math display">\[ =\sum_{x,y}w(x,y)[I_x^2u^2+2I_xI_yuv+I_y^2v^2] \]</span></p><p><span class="math display">\[ =\sum_{x,y}w(x,y)\left[\begin{matrix}u&amp;v\end{matrix}\right] \left[\begin{matrix}I_x^2&amp;I_xI_y\\I_xI_y&amp;I_y^2\end{matrix}\right] \left[\begin{matrix}u\\v\end{matrix}\right] \]</span></p><p><span class="math display">\[ =\left[\begin{matrix}u&amp;v\end{matrix}\right]\underbrace{\sum_{x,y}w(x,y) \left[\begin{matrix}I_x^2&amp;I_xI_y\\I_xI_y&amp;I_y^2\end{matrix}\right]}_M \left[\begin{matrix}u\\v\end{matrix}\right]=\left[\begin{matrix}u&amp;v\end{matrix}\right]M \left[\begin{matrix}u\\v\end{matrix}\right] \]</span></p><p><span class="math inline">\(M\)</span>矩阵决定了<span class="math inline">\(E(u,v)\)</span>的取值，下面我们利用<span class="math inline">\(M\)</span>来求角点，<span class="math inline">\(M\)</span>是<span class="math inline">\(I_x\)</span>和<span class="math inline">\(I_y\)</span>的二次项函数，可以表示成椭圆的形状，椭圆的长短半轴由<span class="math inline">\(M\)</span>的特征值<span class="math inline">\(\lambda_1\)</span>和<span class="math inline">\(\lambda_2\)</span>决定，方向由特征矢量决定，如下图所示：</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191008160908338-1684512358754-7.png" style="zoom:60%"></p><p>椭圆函数特征值与图像中的角点、直线（边缘）和平面之间的关系如下图所示。</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191008161040473-1684512385628-9.png" style="zoom:45%"></p><p>共可分为三种情况：</p><ol type="1"><li>图像中的直线。一个特征值大，另一个特征值小，<span class="math inline">\(\lambda_1&gt;&gt;\lambda_2\)</span>或 <span class="math inline">\(\lambda_2&gt;&gt;\lambda_1\)</span>。椭圆函数值在某一方向上大，在其他方向上小。</li><li>图像中的平面。两个特征值都小，且近似相等；椭圆函数数值在各个方向上都小。</li><li>图像中的角点。两个特征值都大，且近似相等，椭圆函数在所有方向都增大</li></ol><p>Harris给出的角点计算方法并不需要计算具体的特征值，而是计算一个<strong>角点响应值<span class="math inline">\(R\)</span></strong>来判断角点。<span class="math inline">\(R\)</span>的计算公式是 <span class="math display">\[ R=detM-\alpha(traceM)^2\\ detM=\lambda_1\lambda_2\\ traceM=\lambda_1+\lambda_2 \]</span> 式中，<span class="math inline">\(detM\)</span>为矩阵<span class="math inline">\(M\)</span>的行列式；<span class="math inline">\(traceM\)</span>为矩阵<span class="math inline">\(M\)</span>的迹；<span class="math inline">\(\alpha\)</span>为常数，取值范围为0.04~0.06。</p><p>如下图所示：</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191008161904372-1684512700094-11.png" style="zoom:50%"></p><ul><li>当R为大数值的正数时是角点</li><li>当R为大数值的负数时是边界</li><li>当R为小数是认为是平坦区域</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dst=cv.cornerHarris(src, blockSize, ksize, k)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>img：数据类型为 ﬂoat32 的输入图像。</li><li>blockSize：角点检测中要考虑的邻域大小。</li><li>ksize：<code>sobel算子</code>求导使用的核大小。</li><li>k：角点检测方程中的自由参数，取值参数为 [0.04，0.06]。</li></ul><h3 id="示例代码">示例代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像，并转换成灰度图像</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/chessboard.jpg&#x27;</span>)</span><br><span class="line">gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 2 角点检测</span></span><br><span class="line"><span class="comment"># 2.1 输入图像必须是 float32</span></span><br><span class="line">gray = np.float32(gray)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 最后一个参数在 0.04 到 0.05 之间</span></span><br><span class="line">dst = cv.cornerHarris(gray,<span class="number">2</span>,<span class="number">3</span>,<span class="number">0.04</span>)</span><br><span class="line"><span class="comment"># 3 设置阈值，将角点绘制出来，阈值根据图像进行选择</span></span><br><span class="line">img[dst&gt;<span class="number">0.001</span>*dst.<span class="built_in">max</span>()] = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>]</span><br><span class="line"><span class="comment"># 4 图像显示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.imshow(img[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;Harris角点检测&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/imgs/$%7Bfiilename%7D/image-20191008164344988-1684512767151-13.png" style="zoom:33%"></p><p>Harris角点检测的优缺点：</p><p>优点：</p><ul><li>旋转不变性，椭圆转过一定角度但是其形状保持不变（特征值保持不变）</li><li>对于图像灰度的仿射变化具有部分的不变性，由于仅仅使用了图像的一介导数，对于图像灰度平移变化不变；对于图像灰度尺度变化不变</li></ul><p>缺点：</p><ul><li>对尺度很敏感，不具备几何尺度不变性。</li><li>提取的角点是像素级的</li></ul><h2 id="shi-tomasi角点检测">Shi-Tomasi角点检测</h2><p><code>Shi-Tomasi算法</code>是对<code>Harris算法</code>的改进，具体地：若矩阵M的两个特征值<span class="math inline">\(\lambda_1,\lambda_2\)</span>中较小的一个大于阈值，则认为他是角点，即： <span class="math display">\[ R=min(\lambda_1,\lambda_2) \]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">corners = cv2.goodFeaturesToTrack ( image, maxcorners, qualityLevel, minDistance )</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>Image：输入灰度图像</li><li>maxCorners：获取角点数的数目。</li><li>qualityLevel：指出最低可接受的角点质量水平，在0-1之间。</li><li>minDistance：角点之间最小的欧式距离，避免得到相邻特征点。</li></ul><p>返回：</p><ul><li>Corners: 搜索到的角点，在这里所有低于质量水平的角点被排除掉，然后把合格的角点按质量排序，然后将质量较好的角点附近（小于最小欧式距离）的角点删掉，最后找到maxCorners个角点返回。</li></ul><h3 id="示例代码-1">示例代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/tv.jpg&#x27;</span>) </span><br><span class="line">gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 2 角点检测</span></span><br><span class="line">corners = cv.goodFeaturesToTrack(gray,<span class="number">1000</span>,<span class="number">0.01</span>,<span class="number">10</span>)  </span><br><span class="line"><span class="comment"># 3 绘制角点</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> corners:</span><br><span class="line">    x,y = i.ravel()</span><br><span class="line">    cv.circle(img,(x,y),<span class="number">2</span>,(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>),-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 4 图像展示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.imshow(img[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;shi-tomasi角点检测&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/imgs/$%7Bfiilename%7D/image-20191008174257711.png" style="zoom:45%"></p><h1 id="sift和surf算法">SIFT和SURF算法</h1><h2 id="sift算法"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://baike.baidu.com/item/SIFT/1396275?fr=aladdin">SIFT算法</a></h2><p><code>Harris</code>和<code>Shi-Tomasi</code>角点检测算法具有旋转不变性，但不具有尺度不变性，以下图为例，在左侧小图中可以检测到角点，但是图像被放大后，在使用同样的窗口，就检测不到角点了。</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191008181535222-1684547971195-2.png" style="zoom:80%"></p><p><strong>尺度不变特征转换</strong>（Scale-invariant feature transform，SIFT）。此算法由 David Lowe在1999年所发表，2004年完善总结。它的实质是在不同的尺度空间上查找关键点(特征点)，并计算出关键点的方向。SIFT所查找到的关键点是一些十分突出，不会因光照，仿射变换和噪音等因素而变化的点，如<strong>角点、边缘点、暗区的亮点及亮区的暗点</strong>等。</p><ol type="1"><li>尺度空间极值检测：搜索所有尺度上的图像位置。通过高斯差分函数来识别潜在的对于尺度和旋转不变的关键点。</li><li>关键点定位：在每个候选的位置上，通过一个拟合精细的模型来确定位置和尺度。关键点的选择依据于它们的稳定程度。</li><li>关键点方向确定：基于图像局部的梯度方向，分配给每个关键点位置一个或多个方向。所有后面的对图像数据的操作都相对于关键点的方向、尺度和位置进行变换，从而保证了对于这些变换的不变性。</li><li>关键点描述：在每个关键点周围的邻域内，在选定的尺度上测量图像局部的梯度。这些梯度作为关键点的描述符，它允许比较大的局部形状的变形或光照变化。</li></ol><h3 id="尺度空间极值检测">尺度空间极值检测</h3><p>在不同的尺度空间是不能使用相同的窗口检测极值点，对小的关键点使用小的窗口，对大的关键点使用大的窗口，为了达到上述目的，使用<strong>尺度空间滤波器</strong>。（高斯核是唯一可以产生多尺度空间的核函数）</p><p>一个图像的尺度空间<span class="math inline">\(L(x,y,\sigma)\)</span>定义为原始图像<span class="math inline">\(I(x,y)\)</span>与一个可变尺度的2维高斯函数<span class="math inline">\(G(x,y,\sigma)\)</span><strong>卷积运算</strong> ，即： <span class="math display">\[ L(x,y,\sigma)=G(x,y,\sigma)*I(x,y) \]</span> 其中<span class="math inline">\(\sigma\)</span>是尺度空间因子，它决定图像的模糊程度。在大尺度下(<span class="math inline">\(\sigma\)</span>值大)表现的是图像的概貌信息，在小尺度下(<span class="math inline">\(\sigma\)</span>值小)表现的是图像的细节信息。</p><p>在计算高斯函数的离散近似时，在大概<span class="math inline">\(3\sigma\)</span>距离之外的像素都可以看作不起作用，这些像素的计算也就可以忽略。所以，在实际应用中，只计算<span class="math inline">\((6\sigma+1)\times(6\sigma+1)\)</span>的高斯卷积核就可以保证相关像素影响。</p><p>下面构建图像的高斯金字塔，它采用高斯函数对图像进行模糊以及降采样处理得到的， 1. 将图像扩大一倍，在扩大的图像的基础之上构建高斯金字塔， 2. 对该尺寸下图像进行高斯模糊，几幅模糊之后的图像集合构成了一个Octave， 3. 对该Octave下选择一幅图像进行下采样，长和宽分别缩短一倍，图像面积变为原来四分之一。这幅图像就是下一个Octave的初始图像，在初始图像的基础上完成属于这个Octave的高斯模糊处理， 4. 以此类推，完成整个算法。</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191009110944907-1684549584975-4.png" style="zoom:40%"></p><p>利用高斯拉普拉斯算子(Laplacian of Gaussian, <code>LoG</code>)，即图像的二阶导数，可以在不同的尺度下检测图像的关键点信息，从而确定图像的特征点。但<code>LoG</code>的计算量大，效率低。所以通过两个相邻高斯尺度空间的图像相减，得到高斯差分(Difference of Gaussians，<a target="_blank" rel="noopener external nofollow noreferrer" href="https://baike.baidu.com/item/%E9%AB%98%E6%96%AF%E5%B7%AE%E5%88%86%E5%87%BD%E6%95%B0/1597793?fr=aladdin">DOG</a>)来近似<code>LoG</code>。</p><ol type="1"><li>构建<strong>高斯差分金字塔</strong><ul><li>将<strong>高斯金字塔</strong>中每个Octave中相邻两层相减就构成了高斯差分金字塔。</li><li>高斯差分金字塔的<strong>第o组第i层图</strong>像是由高斯金字塔的<strong>第o组第i+1层减第o组第i层</strong>得到的。</li></ul></li></ol><p><img src="/imgs/$%7Bfiilename%7D/image-20191009113953721-1684549912508-6.png" style="zoom:33%"></p><ol start="2" type="1"><li>在不同的尺度空间中搜索局部最大值<ul><li>对于图像中的每一个像素点而言，它需要与自己周围的<span class="math inline">\(8\)</span>邻域，以及尺度空间中上下两层中的相邻的<span class="math inline">\(18(2\times9)\)</span>个点相比。</li><li>如果是局部最大值，它就可能是一个关键点。 <img src="/imgs/$%7Bfiilename%7D/image-20191009115023016-1684549955480-8.png" style="zoom:50%"></li><li>搜索过程从每组的第二层开始，以第二层为当前层，对第二层的<code>DoG</code>图像中的每个点取一个<span class="math inline">\(3\times3\)</span>的立方体，立方体上下层为第一层与第三层。搜索得到的极值点既有位置坐标(<code>DoG</code>的图像坐标)，又有空间尺度坐标(层坐标)。</li><li>当第二层搜索完成后，再以第三层作为当前层，其过程与第二层的搜索类似。</li><li>当<span class="math inline">\(S=3\)</span>时，每组里面要搜索3层，所以在高斯差分金字塔中就有<span class="math inline">\(S+2\)</span>层，在高斯金字塔中每组有<span class="math inline">\(S+3\)</span>层。</li></ul></li></ol><h3 id="关键点定位">关键点定位</h3><p>由于<code>DoG</code>对噪声和边缘比较敏感，因此在高斯差分金字塔中检测到的局部极值点需经过进一步的检验才能精确定位为特征点。</p><p>使用尺度空间的泰勒级数展开来获得极值的准确位置， 如果<strong>极值点的灰度值小于阈值</strong>（一般为0.03或0.04）就会被忽略掉。 在 OpenCV 中这种阈值被称为 contrastThreshold。</p><p>欠佳的关键点在平行边缘的方向有较大的主曲率，而在垂直于边缘的方向有较小的曲率，两者的比值如果高于某个阈值（在OpenCV中叫做边界阈值），就认为该关键点为边界，将被忽略，一般该阈值为10。</p><p>将低对比度和边界的关键点去除，得到的就是我们感兴趣的关键点。</p><h3 id="关键点方向确定">关键点方向确定</h3><p>为了实现旋转不变性，还需要为每个关键点分配一个方向角度，也就是在高斯尺度图像的邻域结构中求得一个方向基准。</p><p>对于任一关键点，采集其所在高斯金字塔图像以<span class="math inline">\(r\)</span>为半径的区域内所有像素的梯度特征（幅值和幅角），<span class="math inline">\(r=3\times1.5\sigma\)</span>，其中<span class="math inline">\(\sigma\)</span>是关键点所在octave的图像的尺度，可以得到对应的尺度图像。</p><p>梯度的幅值和方向的计算公式为： <span class="math display">\[ m(x,y)=\sqrt{(L(x+1,y)-L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2} \]</span> <span class="math display">\[ \theta(x,y)=\arctan(\frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)} \]</span> 邻域像素梯度的计算结果如下图所示：</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191009143818527-1684552168908-10.png" style="zoom:50%"></p><p>使用直方图统计关键点邻域内像素的梯度幅值和方向。</p><ol type="1"><li><p>将<span class="math inline">\(360^\circ\)</span>分为<span class="math inline">\(36\)</span>柱，每<span class="math inline">\(10^\circ\)</span>为一柱，然后在以<span class="math inline">\(r\)</span>为半径的区域内，将梯度方向在某一个柱内的像素找出来。</p></li><li><p>将他们的幅值相加在一起作为柱的高度。因为在r为半径的区域内像素的梯度幅值对中心像素的贡献是不同的，因此还需要对幅值进行加权处理，采用高斯加权，方差为<span class="math inline">\(1.5\sigma\)</span>。 <img src="/imgs/$%7Bfiilename%7D/image-20191009144726492-1684552637576-16.png" style="zoom:33%"></p></li><li><p>每个特征点必须分配一个主方向，还需要一个或多个辅方向，增加辅方向的目的是为了增强图像匹配的鲁棒性。辅方向的定义是，当一个柱体的高度大于主方向柱体高度的<span class="math inline">\(80\%\)</span>时，则该柱体所代表的的方向就是给特征点的辅方向。</p></li><li><p>直方图的峰值，即最高的柱代表的方向是特征点邻域范围内图像梯度的主方向，但该柱体代表的角度是一个范围，所以我们还要对离散的直方图进行插值拟合，以得到更精确的方向角度值。利用抛物线对离散的直方图进行拟合。 <img src="/imgs/$%7Bfiilename%7D/image-20191009150008701-1684552598604-14.png" style="zoom:40%"></p></li></ol><p>获得图像关键点主方向后，使用一个带箭头的圆或直接使用箭头表示SIFT区域的三个值：中心表示特征点位置<span class="math inline">\((x,y)\)</span>，半径表示关键点尺度<span class="math inline">\((\sigma)\)</span>，箭头表示方向<span class="math inline">\((\theta)\)</span>。</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191025112522974-1684552568027-12.png" style="zoom:50%"></p><h3 id="关键点描述">关键点描述</h3><p>为每个关键点建立一个描述符，该描述符既具有可区分性，又具有对某些变量的不变性，如光照，视角等。而且描述符不仅仅包含关键点，也包括关键点周围对其有贡献的的像素点。</p><p>在关键点所在的高斯尺度图像上生成对应的描述符。以特征点为中心，将其附近邻域划分为<span class="math inline">\(d\times d\)</span>个子区域（一般取<span class="math inline">\(d=4\)</span>)，每个子区域都是一个正方形，边长为<span class="math inline">\(3\sigma\)</span>，考虑到实际计算时，需进行三次线性插值，所以特征点邻域的为<span class="math inline">\(3\sigma(d+1)\times3\sigma(d+1)\)</span>的范围，如下图所示：</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191009161647267-1684552834400-18.png" style="zoom:67%"></p><p>为了保证特征点的旋转不变性，以特征点为中心，将坐标轴旋转为关键点的主方向，如下图所示：</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191009161756423-1684552865043-20.png" style="zoom:67%"></p><p>计算子区域内的像素的梯度，并按照<span class="math inline">\(\sigma=0.5d\)</span>进行高斯加权，然后插值计算得到每个种子点的八个方向的梯度，插值方法如下图所示：</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191009162914982-1684552898801-22.png" style="zoom:67%"></p><p>每个种子点的梯度都是由覆盖其的<span class="math inline">\(4\)</span>个子区域插值而得的。如图中的红色点，落在第<span class="math inline">\(0\)</span>行和第<span class="math inline">\(1\)</span>行之间，对这两行都有贡献。</p><ul><li>对第<span class="math inline">\(0\)</span>行第<span class="math inline">\(3\)</span>列种子点的贡献因子为<span class="math inline">\(dr\)</span>，对第<span class="math inline">\(1\)</span>行第<span class="math inline">\(3\)</span>列的贡献因子为<span class="math inline">\(1-dr\)</span>，</li><li>对邻近两列的贡献因子为<span class="math inline">\(dc\)</span>和<span class="math inline">\(1-dc\)</span></li><li>对邻近两个方向的贡献因子为<span class="math inline">\(do\)</span>和<span class="math inline">\(1-do\)</span>。</li></ul><p>最终累加在每个方向上的梯度大小为： <span class="math display">\[ weight=w*dr^k(1-dr)^{(1-k)}dc^m(1-dc)^{1-m}do^n(1-do^{1-n}) \]</span> 其中<span class="math inline">\(k,m,n\)</span>为0或为1。 如上统计<span class="math inline">\(4\times4\times8=128\)</span>个梯度信息即为该关键点的特征向量，按照特征点的对每个关键点的特征向量进行排序，就得到了SIFT特征描述向量。</p><p><strong>实例化sift</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sift = cv.xfeatures2d.SIFT_create()</span><br></pre></td></tr></table></figure><p><strong>利用<code>sift.detectAndCompute()</code>检测关键点并计算</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kp,des = sift.detectAndCompute(gray,<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>gray：进行关键点检测的图像，注意是灰度图像</li></ul><p>返回：</p><ul><li>kp：关键点信息，包括位置，尺度，方向信息</li><li>des：关键点描述符，每个关键点对应128个梯度信息的特征向量</li></ul><p><strong>将关键点检测结果绘制在图像上</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.drawKeypoints(image, keypoints, outputimage, color, flags)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li><p>image: 原始图像</p></li><li><p>keypoints：关键点信息，将其绘制在图像上</p></li><li><p>outputimage：输出图片，可以是原始图像</p></li><li><p>color：颜色设置，通过修改b、g、r的值,更改画笔的颜色</p></li><li><p>flags：绘图功能的标识设置</p><ul><li><p>cv2.DRAW_MATCHES_FLAGS_DEFAULT：创建输出图像矩阵，使用现存的输出图像绘制匹配对和特征点，对每一个关键点只绘制中间点</p></li><li><p>cv2.DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG：不创建输出图像矩阵，而是在输出图像上绘制匹配对</p></li><li><p>cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS：对每一个特征点绘制带大小和方向的关键点图形</p></li><li><p>cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS：单点的特征点不被绘制</p></li></ul></li></ul><h3 id="示例代码-2">示例代码：</h3><p>利用SIFT算法在中央电视台的图片上检测关键点，并将其绘制出来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/tv.jpg&#x27;</span>)</span><br><span class="line">gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># 2 sift关键点检测</span></span><br><span class="line"><span class="comment"># 2.1 实例化sift对象</span></span><br><span class="line">sift = cv.xfeatures2d.SIFT_create()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 关键点检测：kp关键点信息包括方向，尺度，位置信息，des是关键点的描述符</span></span><br><span class="line">kp,des=sift.detectAndCompute(gray,<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 2.3 在图像上绘制关键点的检测结果</span></span><br><span class="line">cv.drawKeypoints(img,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class="line"><span class="comment"># 3 图像显示</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">6</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.imshow(img[:,:,::-<span class="number">1</span>]),plt.title(<span class="string">&#x27;sift检测&#x27;</span>)</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/imgs/$%7Bfiilename%7D/image-20191009181525538-1684553395070-26.png" style="zoom:50%"></p><h2 id="surf算法">SURF算法</h2><p>使用 SIFT 算法进行关键点检测和描述的执行速度比较慢， 需要速度更快的算法。 2006 年 Bay提出了 SURF 算法，是SIFT算法的增强版，它的计算量小，运算速度快，提取的特征与SIFT几乎相同，将其与SIFT算法对比如下：</p><p><img src="/imgs/$%7Bfiilename%7D/image-20191016163330835-1684553312569-24.png" style="zoom:67%"></p><h1 id="fast和orb算法">Fast和ORB算法</h1><h2 id="fast算法"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://en.wikipedia.org/wiki/Features_from_accelerated_segment_test">Fast算法</a></h2><p>Fast(Features from accelerated segment test)是一种角点检测算法，Edward Rosten和Tom Drummond在2006年提出了FAST算法，并在2010年对其进行了修正。该算法的原理是取图像中检测点，以该点为圆心的周围邻域内像素点判断检测点是否为角点，通俗的讲就是<strong>若一个像素周围有一定数量的像素与该点像素值不同，则认为其为角点</strong>。</p><ol type="1"><li><p>在图像中选取一个像素点<span class="math inline">\(p\)</span>，来判断它是不是关键点。<span class="math display">\[I_p\]</span>等于像素点<span class="math inline">\(p\)</span>的灰度值。</p></li><li><p>以<span class="math inline">\(r\)</span>为半径画圆，覆盖<span class="math inline">\(p\)</span>点周围的<span class="math inline">\(M\)</span>个像素，通常情况设置<span class="math inline">\(r=3\)</span>，则<span class="math inline">\(M=16\)</span>。 <img src="/imgs/$%7Bfiilename%7D/image17-1684555943527-30.jpg" style="zoom:67%"></p></li><li><p>设置阈值<span class="math inline">\(t\)</span>，如果在这<span class="math inline">\(16\)</span>个像素点中存在<span class="math inline">\(n\)</span>个连续像素点的灰度值都高于<span class="math inline">\(I_p+t\)</span>，或者低于<span class="math inline">\(I_p-t\)</span>，那么像素点<span class="math inline">\(p\)</span>就被认为是一个角点。如上图中的虚线所示，一般取值为<span class="math inline">\(n=12\)</span>。</p></li><li><p>采用一种<strong>非特征点判别</strong>的方法：首先对候选点的周围每个<span class="math inline">\(90^\circ\)</span>的点（<span class="math inline">\(1,9,5,13\)</span>）进行测试(先测试<span class="math inline">\(1\)</span>和<span class="math inline">\(9\)</span>，如果它们符合阈值要求再测试<span class="math inline">\(5\)</span>和<span class="math inline">\(13\)</span>)。如果<span class="math inline">\(p\)</span>是角点，那么这四个点中至少有 3 个要符合阈值要求，否则直接剔除。对保留下来的点再继续进行测试。</p></li></ol><h3 id="机器学习的角点检测器">机器学习的角点检测器</h3><ol type="1"><li><p>选择一组训练图片</p></li><li><p>使用<code>FAST算法</code>找出每幅图像的特征点，对图像中的每一个特征点，将其周围的<span class="math inline">\(16\)</span>个像素存储构成一个向量<span class="math inline">\(P\)</span>。 <img src="/imgs/$%7Bfiilename%7D/image-20191010114459269-1684556434454-32.png" style="zoom:67%"></p></li><li><p>每一个特征点的 16 像素点都属于下列三类中的一种 $$ S_{px}=</p><span class="math display">\[\begin{cases} d\quad I_{p\rightarrow x}\leq I_{p}-t\quad (darker)\\ s\quad I_{p}-t\leq I_{p\rightarrow x}\leq I_{p}+t\quad (similar)\\ b\quad I_{p}+t\leq I_{p\rightarrow x}\quad (brighter)\\ \end{cases}\]</span><p>$$</p></li><li><p>根据这些像素点的分类，特征向量<span class="math inline">\(P\)</span>也被分为<span class="math inline">\(3\)</span>个子集(<span class="math inline">\(P_d,P_s,P_b\)</span>)，</p></li><li><p>定义一个新的布尔变量<span class="math inline">\(K_p\)</span>，如果<span class="math inline">\(p\)</span>是角点就设置为<span class="math inline">\(True\)</span>，如果不是就设置为<span class="math inline">\(False\)</span>。</p></li><li><p>利用特征值向量<span class="math inline">\(p\)</span>，目标值是<span class="math inline">\(K_p\)</span>，训练<span class="math inline">\(ID3\)</span>树（决策树分类器）。</p></li><li><p>将构建好的决策树运用于其他图像的快速检测。</p></li></ol><h3 id="非极大值抑制">非极大值抑制</h3><p><strong>在筛选出来的候选角点中有很多是紧挨在一起的，需要通过非极大值抑制来消除这种影响。</strong></p><p>为所有的候选角点确定一个打分函数<span class="math inline">\(V\)</span></p><ol type="1"><li><p>分别计算<span class="math inline">\(I_p\)</span>与圆上<span class="math inline">\(16\)</span>个点的像素值差值，取绝对值，</p></li><li><p>将这16个绝对值相加，就得到了<span class="math inline">\(V\)</span>的值 <span class="math display">\[ V = \sum_{i}^{16}|I_p-I_i| \]</span></p></li><li><p>比较毗邻候选角点的<span class="math inline">\(V\)</span>值，把<span class="math inline">\(V\)</span>值较小的候选角点去除掉。</p></li></ol><p><strong>实例化Fast</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fast = =cv.FastFeatureDetector_create( threshold, nonmaxSuppression)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>threshold：阈值t，默认值10</li><li>nonmaxSuppression：是否进行非极大值抑制，默认值True</li></ul><p>返回：</p><ul><li>Fast：创建的FastFeatureDetector对象</li></ul><p><strong>利用<code>fast.detect()</code>检测关键点，没有对应的关键点描述</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kp = fast.detect(grayImg, <span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>gray: 进行关键点检测的图像，注意是灰度图像</li></ul><p>返回：</p><ul><li>kp: 关键点信息，包括位置，尺度，方向信息</li></ul><p><strong>将关键点检测结果绘制在图像上</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.drawKeypoints(image, keypoints, outputimage, color, flags)</span><br></pre></td></tr></table></figure><h3 id="示例代码-3">示例代码：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 读取图像</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/tv.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># 2 Fast角点检测</span></span><br><span class="line"><span class="comment"># 2.1 创建一个Fast对象，传入阈值，注意：可以处理彩色空间图像</span></span><br><span class="line">fast = cv.FastFeatureDetector_create(threshold=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 检测图像上的关键点</span></span><br><span class="line">kp = fast.detect(img,<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># 2.3 在图像上绘制关键点</span></span><br><span class="line">img2 = cv.drawKeypoints(img, kp, <span class="literal">None</span>, color=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.4 输出默认参数</span></span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;Threshold: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(fast.getThreshold()) )</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;nonmaxSuppression:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(fast.getNonmaxSuppression()) )</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;neighborhood: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(fast.getType()) )</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;Total Keypoints with nonmaxSuppression: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(kp)) )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.5 关闭非极大值抑制</span></span><br><span class="line">fast.setNonmaxSuppression(<span class="number">0</span>)</span><br><span class="line">kp = fast.detect(img,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>( <span class="string">&quot;Total Keypoints without nonmaxSuppression: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="built_in">len</span>(kp)) )</span><br><span class="line"><span class="comment"># 2.6 绘制为进行非极大值抑制的结果</span></span><br><span class="line">img3 = cv.drawKeypoints(img, kp, <span class="literal">None</span>, color=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 绘制图像</span></span><br><span class="line">fig,axes=plt.subplots(nrows=<span class="number">1</span>,ncols=<span class="number">2</span>,figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">axes[<span class="number">0</span>].imshow(img2[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;加入非极大值抑制&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].imshow(img3[:,:,::-<span class="number">1</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;未加入非极大值抑制&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/imgs/$%7Bfiilename%7D/image-20191010120822413-1684557401983-34.png" style="zoom:50%"></p><h2 id="orb-算法"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://medium.com/data-breach/introduction-to-orb-oriented-fast-and-rotated-brief-4220e8ec40cf">ORB 算法</a></h2><p>ORB（Oriented Fast and Rotated Brief）可以用来对图像中的关键点快速创建特征向量，并用这些特征向量来识别图像中的对象。</p><p>ORB算法结合了Fast和Brief算法，提出了构造金字塔，为Fast特征点添加了方向，从而使得关键点具有了尺度不变性和旋转不变性。</p><ol type="1"><li>构造尺度金字塔<ul><li>金字塔共有<span class="math inline">\(n\)</span>层，与SIFT不同的是，每一层仅有一幅图像。第<span class="math inline">\(s\)</span>层的尺度为<span class="math inline">\(\sigma_s=\sigma_0^s\)</span>， <span class="math inline">\(\sigma_0\)</span>是初始尺度，默认为<span class="math inline">\(1.2\)</span>，原图在第<span class="math inline">\(0\)</span>层。第<span class="math inline">\(s\)</span>层图像的大小<span class="math inline">\(Size = (H*\frac{1}{\sigma_s})\times(W*\frac{1}{\sigma_s})\)</span></li></ul></li><li>在不同的尺度上利用<code>Fast算法</code>检测特征点<ul><li>采用Harris角点响应函数，根据角点的响应值排序，选取前<span class="math inline">\(N\)</span>个特征点，作为本尺度的特征点。</li></ul></li><li>计算特征点的主方向<ul><li><p>计算以特征点为圆心，半径为<span class="math inline">\(r\)</span>的圆形邻域内的灰度质心位置，将从特征点位置到质心位置的方向做特征点的主方向。 <span class="math display">\[ m_{pq}=\sum_{x,y}x^py^qI(x,y) \]</span> 质心位置： <span class="math inline">\(C=(\frac{m_{10}}{m_{00}},\frac{m_{01}}{m_{10}})\)</span></p><p>主方向： <span class="math inline">\(\theta = arctan(m_{01},m_{10})\)</span></p></li></ul></li></ol><h3 id="brief算法">BRIEF算法</h3><p>了解决旋转不变性，将特征点的邻域旋转到主方向上利用<code>Brief算法</code>构建特征描述符，至此就得到了ORB的特征描述向量。</p><p><code>Brief算法</code>是一种特征描述子提取算法，并非特征点的提取算法，匹配只需要使用简单的汉明距离(Hamming Distance)利用比特之间的异或操作就可以完成。</p><ol type="1"><li>图像滤波<ul><li>原始图像中存在噪声时，会对结果产生影响，所以需要对图像进行滤波，去除部分噪声。</li></ul></li><li>选取点对<ul><li><p>以特征点为中心，取<span class="math inline">\(S\times S\)</span>的邻域窗口，在窗口内随机选取<span class="math inline">\(N\)</span>组点对，一般<span class="math inline">\(N=128,256,512\)</span>，默认是<span class="math inline">\(256\)</span>，关于选取随机点对，提供了五种形式</p><ul><li><span class="math inline">\(x,y\)</span>方向平均分布采样</li><li><span class="math inline">\(x,y\)</span>均服从<span class="math inline">\(Gauss(0,\frac{S^2}{25})\)</span>各向同性采样</li><li><span class="math inline">\(x\)</span>服从<span class="math inline">\(Gauss(0,\frac{S^2}{25})\)</span>，<span class="math inline">\(y\)</span>服从<span class="math inline">\(Gauss(0,\frac{S^2}{100})\)</span>采样</li><li><span class="math inline">\(x,y\)</span>从网格中随机获取</li><li><span class="math inline">\(x\)</span>一直在<span class="math inline">\((0,0)\)</span>，<span class="math inline">\(y\)</span>从网格中随机选取</li></ul><p><img src="/imgs/$%7Bfiilename%7D/image-20191010153907973-1684559140937-36.png" style="zoom:67%"></p></li><li><p>图中一条线段的两个端点就是一组点对，其中第二种方法的结果比较好。</p></li></ul></li><li>构建描述符<ul><li><p>假设<span class="math inline">\(x,y\)</span>是某个点对的两个端点，<span class="math inline">\(p(x),p(y)\)</span>是两点对应的像素值， <span class="math display">\[ t(x,y)=\begin{cases}1 &amp;if&amp;p(x)&gt;p(y)\\ 0&amp; else\end{cases} \]</span></p></li><li><p>对每一个点对都进行上述的二进制赋值，形成<code>Brief</code>的关键点的描述特征向量，该向量一般为<span class="math inline">\(128-512\)</span>位的字符串，其中仅包含<span class="math inline">\(1\)</span>和<span class="math inline">\(0\)</span></p><p><img src="/imgs/$%7Bfiilename%7D/image-20191010161944491-1684559749207-38.png" style="zoom:50%"></p></li></ul></li></ol><p><strong>实例化ORB</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">orb = cv.xfeatures2d.orb_create(nfeatures)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>nfeatures: 特征点的最大数量</li></ul><p><strong>利用<code>orb.detectAndCompute()</code>检测关键点并计算</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kp,des = orb.detectAndCompute(gray,<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>gray: 进行关键点检测的图像，注意是灰度图像</li></ul><p>返回：</p><ul><li>kp: 关键点信息，包括位置，尺度，方向信息</li><li>des: 关键点描述符，每个关键点BRIEF特征向量，二进制字符串，</li></ul><p><strong>将关键点检测结果绘制在图像上</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.drawKeypoints(image, keypoints, outputimage, color, flags)</span><br></pre></td></tr></table></figure><h3 id="示例代码-4">示例代码：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1 图像读取</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;./image/tv.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 ORB角点检测</span></span><br><span class="line"><span class="comment"># 2.1 实例化ORB对象</span></span><br><span class="line">orb = cv.ORB_create(nfeatures=<span class="number">500</span>)</span><br><span class="line"><span class="comment"># 2.2 检测关键点,并计算特征描述符</span></span><br><span class="line">kp,des = orb.detectAndCompute(img,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(des.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3 将关键点绘制在图像上</span></span><br><span class="line">img2 = cv.drawKeypoints(img, kp, <span class="literal">None</span>, color=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), flags=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 绘制图像</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>),dpi=<span class="number">100</span>)</span><br><span class="line">plt.imshow(img2[:,:,::-<span class="number">1</span>])</span><br><span class="line">plt.xticks([]), plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/imgs/$%7Bfiilename%7D/image-20191010162532196-1684559841023-40.png" style="zoom:45%"></p></div><div><hr></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>一月十号</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://liujk6525.github.io/OpenCV/%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%B8%8E%E6%8F%8F%E8%BF%B0/" title="图像特征提取与描述">https://liujk6525.github.io/OpenCV/图像特征提取与描述/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Jupyter-Notebook/" rel="tag"><i class="fa fa-tag"></i> Jupyter Notebook</a></div><div class="post-nav"><div class="post-nav-item"><a href="/OpenCV/OpenCV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E4%B8%8B/" rel="prev" title="OpenCV图像处理(下)"><i class="fa fa-chevron-left"></i> OpenCV图像处理(下)</a></div><div class="post-nav-item"><a href="/OpenCV/%E8%A7%86%E9%A2%91%E8%BF%BD%E8%B8%AA/" rel="next" title="视频追踪">视频追踪 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><script>window.addEventListener("tabs:register",()=>{let t=CONFIG.comments["activeClass"];var e;(t=CONFIG.comments.storage?localStorage.getItem("comments_active")||t:t)&&(e=document.querySelector(`a[href="#comment-${t}"]`))&&e.click()}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%A7%92%E7%82%B9%E7%89%B9%E5%BE%81"><span class="nav-number">1.</span> <span class="nav-text">角点特征</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#harris%E5%92%8Cshi-tomas%E7%AE%97%E6%B3%95"><span class="nav-number">2.</span> <span class="nav-text">Harris和Shi-Tomas算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#harris%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B"><span class="nav-number">2.1.</span> <span class="nav-text">Harris角点检测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81"><span class="nav-number">2.1.1.</span> <span class="nav-text">示例代码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#shi-tomasi%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B"><span class="nav-number">2.2.</span> <span class="nav-text">Shi-Tomasi角点检测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81-1"><span class="nav-number">2.2.1.</span> <span class="nav-text">示例代码</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#sift%E5%92%8Csurf%E7%AE%97%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">SIFT和SURF算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#sift%E7%AE%97%E6%B3%95"><span class="nav-number">3.1.</span> <span class="nav-text">SIFT算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%BA%E5%BA%A6%E7%A9%BA%E9%97%B4%E6%9E%81%E5%80%BC%E6%A3%80%E6%B5%8B"><span class="nav-number">3.1.1.</span> <span class="nav-text">尺度空间极值检测</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E7%82%B9%E5%AE%9A%E4%BD%8D"><span class="nav-number">3.1.2.</span> <span class="nav-text">关键点定位</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E7%82%B9%E6%96%B9%E5%90%91%E7%A1%AE%E5%AE%9A"><span class="nav-number">3.1.3.</span> <span class="nav-text">关键点方向确定</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E7%82%B9%E6%8F%8F%E8%BF%B0"><span class="nav-number">3.1.4.</span> <span class="nav-text">关键点描述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81-2"><span class="nav-number">3.1.5.</span> <span class="nav-text">示例代码：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#surf%E7%AE%97%E6%B3%95"><span class="nav-number">3.2.</span> <span class="nav-text">SURF算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#fast%E5%92%8Corb%E7%AE%97%E6%B3%95"><span class="nav-number">4.</span> <span class="nav-text">Fast和ORB算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#fast%E7%AE%97%E6%B3%95"><span class="nav-number">4.1.</span> <span class="nav-text">Fast算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B%E5%99%A8"><span class="nav-number">4.1.1.</span> <span class="nav-text">机器学习的角点检测器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6"><span class="nav-number">4.1.2.</span> <span class="nav-text">非极大值抑制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81-3"><span class="nav-number">4.1.3.</span> <span class="nav-text">示例代码：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#orb-%E7%AE%97%E6%B3%95"><span class="nav-number">4.2.</span> <span class="nav-text">ORB 算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#brief%E7%AE%97%E6%B3%95"><span class="nav-number">4.2.1.</span> <span class="nav-text">BRIEF算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81-4"><span class="nav-number">4.2.2.</span> <span class="nav-text">示例代码：</span></a></li></ol></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="一月十号" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">一月十号</p><div class="site-description" itemprop="description"></div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">34</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">8</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">14</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/liujk6525" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;liujk6525" rel="noopener external nofollow noreferrer" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="https://blog.csdn.net/qq_55782745?type=blog" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_55782745?type&#x3D;blog" rel="noopener external nofollow noreferrer" target="_blank"><i class="csdn fa-fw"></i>CSDN</a> </span><span class="links-of-author-item"><a href="https://space.bilibili.com/314846134" title="bilibili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;314846134" rel="noopener external nofollow noreferrer" target="_blank"><i class="bilibili fa-fw"></i>bilibili</a> </span><span class="links-of-author-item"><a href="mailto:1542669276@qq.com" title="E-Mail → mailto:1542669276@qq.com" rel="noopener external nofollow noreferrer" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-block"><div class="links-of-blogroll-title"><i class="fa fa-history fa-" aria-hidden="true"></i> 近期文章</div><ul class="links-of-blogroll-list"><li><a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" title="支持向量机" target="_blank">支持向量机</a></li><li><a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/" title="主成分分析" target="_blank">主成分分析</a></li><li><a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/" title="聚类算法" target="_blank">聚类算法</a></li><li><a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/" title="贝叶斯算法" target="_blank">贝叶斯算法</a></li><li><a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" title="集成学习" target="_blank">集成学习</a></li></ul></div><div><canvas id="canvas" style="width:60%">当前浏览器不支持canvas，请更换浏览器后再试</canvas></div><script>!function(){var h,o,r,f,t,e,d=[[[0,0,1,1,1,0,0],[0,1,1,0,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,0,1,1,0],[0,0,1,1,1,0,0]],[[0,0,0,1,1,0,0],[0,1,1,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[1,1,1,1,1,1,1]],[[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,0,1,1,0,0,0],[0,1,1,0,0,0,0],[1,1,0,0,0,0,0],[1,1,0,0,0,1,1],[1,1,1,1,1,1,1]],[[1,1,1,1,1,1,1],[0,0,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,0,1,1,1,0,0],[0,0,0,0,1,1,0],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[0,0,0,0,1,1,0],[0,0,0,1,1,1,0],[0,0,1,1,1,1,0],[0,1,1,0,1,1,0],[1,1,0,0,1,1,0],[1,1,1,1,1,1,1],[0,0,0,0,1,1,0],[0,0,0,0,1,1,0],[0,0,0,0,1,1,0],[0,0,0,1,1,1,1]],[[1,1,1,1,1,1,1],[1,1,0,0,0,0,0],[1,1,0,0,0,0,0],[1,1,1,1,1,1,0],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[0,0,0,0,1,1,0],[0,0,1,1,0,0,0],[0,1,1,0,0,0,0],[1,1,0,0,0,0,0],[1,1,0,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[1,1,1,1,1,1,1],[1,1,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,0,0,1,1,0,0],[0,0,1,1,0,0,0],[0,0,1,1,0,0,0],[0,0,1,1,0,0,0],[0,0,1,1,0,0,0]],[[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,1,1,0]],[[0,1,1,1,1,1,0],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[1,1,0,0,0,1,1],[0,1,1,1,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,0,1,1],[0,0,0,0,1,1,0],[0,0,0,1,1,0,0],[0,1,1,0,0,0,0]],[[0,0,0,0,0,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,1,1,1,0,0],[0,0,0,0,0,0,0]]],i=document.getElementById("canvas");function a(t,e){for(var l=[1,2,3],n=["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"],a=0;a<d[e].length;a++)for(var h,o=0;o<d[e][a].length;o++)1==d[e][a][o]&&(h={x:14*(f+2)*t+2*o*(f+1)+(f+1),y:2*a*(f+1)+(f+1),stepX:Math.floor(4*Math.random()-2),stepY:-2*l[Math.floor(Math.random()*l.length)],color:n[Math.floor(Math.random()*n.length)],disY:1},r.push(h))}function l(){i.height=100;for(var t=0;t<o.length;t++){a=n=l=e=void 0;for(var e=t,l=o[t],n=0;n<d[l].length;n++)for(var a=0;a<d[l][n].length;a++)1==d[l][n][a]&&(h.beginPath(),h.arc(14*(f+2)*e+2*a*(f+1)+(f+1),2*n*(f+1)+(f+1),f,0,2*Math.PI),h.closePath(),h.fill())}for(t=0;t<r.length;t++)h.beginPath(),h.arc(r[t].x,r[t].y,f,0,2*Math.PI),h.fillStyle=r[t].color,h.closePath(),h.fill()}i.getContext&&(h=i.getContext("2d"),i.height=100,i.width=700,h.fillStyle="#f00",h.fillRect(10,10,50,50),o=[],r=[],f=i.height/20-1,e=/(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date),o.push(e[1],e[2],10,e[3],e[4],10,e[5],e[6]),clearInterval(t),t=setInterval(function(){!function(){var t=[],e=/(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date),l=[];l.push(e[1],e[2],10,e[3],e[4],10,e[5],e[6]);for(var n=o.length-1;0<=n;n--)l[n]!==o[n]&&t.push(n+"_"+(Number(o[n])+1)%10);for(n=0;n<t.length;n++)a.apply(this,t[n].split("_"));o=l.concat()}();for(var t=0;t<r.length;t++)r[t].stepY+=r[t].disY,r[t].x+=r[t].stepX,r[t].y+=r[t].stepY,(r[t].x>700+f||r[t].y>100+f)&&(r.splice(t,1),t--);l()},50))}()</script></div><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="400" src="//music.163.com/outchain/player?type=0&id=8418152015&auto=1&height=400"></iframe></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2023</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">一月十号</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">126k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">1:55</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener external nofollow noreferrer" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener external nofollow noreferrer" target="_blank">NexT.Gemini</a> 强力驱动</div><div class="translate-style">繁/简：<a id="translateLink" href="javascript:translatePage();" rel="external nofollow noreferrer">繁体</a></div><script type="text/javascript" src="/js/tw_cn.js"></script><script type="text/javascript">var defaultEncoding=2,translateDelay=0,cookieDomain="https://tding.top/",msgToTraditionalChinese="繁体",msgToSimplifiedChinese="简体",translateButtonId="translateLink";translateInitilization()</script><div class="busuanzi-count"><script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i> </span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span> </span></span><span class="post-meta-divider">|</span> <span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/pjax/pjax.min.js"></script><script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script>var pjax=new Pjax({selectors:["head title","#page-configurations",".content-wrap",".post-toc-wrap",".languages","#pjax"],switches:{".post-toc-wrap":Pjax.switches.innerHTML},analytics:!1,cacheBust:!1,scrollTo:!CONFIG.bookmark.enable});window.addEventListener("pjax:success",()=>{document.querySelectorAll("script[data-pjax], script#page-configurations, #pjax script").forEach(e=>{var t=e.text||e.textContent||e.innerHTML||"",a=e.parentNode,s=(a.removeChild(e),document.createElement("script"));e.id&&(s.id=e.id),e.className&&(s.className=e.className),e.type&&(s.type=e.type),e.src&&(s.src=e.src,s.async=!1),void 0!==e.dataset.pjax&&(s.dataset.pjax=""),""!==t&&s.appendChild(document.createTextNode(t)),a.appendChild(s)}),NexT.boot.refresh(),CONFIG.motion.enable&&NexT.motion.integrator.init().add(NexT.motion.middleWares.subMenu).add(NexT.motion.middleWares.postList).bootstrap(),NexT.utils.updateSidebarPosition()})</script><script src="/js/local-search.js"></script><div id="pjax"><script>"undefined"==typeof MathJax?(window.MathJax={loader:{source:{"[tex]/amsCd":"[tex]/amscd","[tex]/AMScd":"[tex]/amscd"}},tex:{inlineMath:{"[+]":[["$","$"]]},tags:"ams"},options:{renderActions:{findScript:[10,n=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/),t=new n.options.MathItem(e.textContent,n.inputJax[0],t),a=document.createTextNode("");e.parentNode.replaceChild(a,e),t.start={node:a,delim:"",n:0},t.end={node:a,delim:"",n:0},n.math.push(t)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{e=e.parentNode;"li"===e.nodeName.toLowerCase()&&e.parentNode.classList.add("has-jax")})},"",!1]}}},function(){var e=document.createElement("script");e.src="//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js",e.defer=!0,document.head.appendChild(e)}()):(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset())</script><script src="/js/cursor/cherry.js"></script><script src="/js/activate-power-mode.min.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!1,document.body.addEventListener("input",POWERMODE)</script><div class="moon-menu"><div class="moon-menu-items"><div id="moon-menu-item-back2bottom" class="moon-menu-item" onclick="back2bottom()"><i class="fa fa-chevron-down"></i></div><div id="moon-menu-item-back2top" class="moon-menu-item" onclick="back2top()"><i class="fa fa-chevron-up"></i></div></div><div class="moon-menu-button"><svg class="moon-menu-bg"><circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle><circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle></svg><div class="moon-menu-content"><div class="moon-menu-icon"><i class="fas fa-ellipsis-v"></i></div><div class="moon-menu-text"></div></div></div></div><script src="/js/injector.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.9}});</script></body></html>