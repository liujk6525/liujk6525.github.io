{"meta":{"title":"你不是单打独斗","subtitle":"问所闻而来，见所见而去","description":"","author":"一月十号","url":"https://liujk6525.github.io","root":"/"},"pages":[{"title":"分类","date":"2023-05-08T07:36:10.000Z","updated":"2023-05-08T07:41:26.000Z","comments":true,"path":"categories/index.html","permalink":"https://liujk6525.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2023-05-08T07:39:23.000Z","updated":"2023-05-08T07:42:14.000Z","comments":true,"path":"tags/index.html","permalink":"https://liujk6525.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"支持向量机","slug":"支持向量机","date":"2023-06-07T13:39:07.000Z","updated":"2023-06-08T04:27:30.819Z","comments":true,"path":"机器学习/支持向量机/","link":"","permalink":"https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/","excerpt":"","text":"支持向量机（Support Vector Machines，SVM） SVM SVM寻找区分两类的超平面（hyper plane), 使边际（margin）最大 向量内积 \\[ x=(x_1,x_2,\\cdots,x_n)^T,y=(y_1,y_2,\\cdots,y_n)^T \\] \\[ x\\cdot y=x_1y_1+x_2y_2+\\cdots+x_ny_n=||x||\\cdot||y||\\cos(\\theta) \\] \\[ ||x||=\\sqrt{x\\cdot x}=\\sqrt{x_1^2+x_2^2+\\cdots+x_n^2} \\] 当\\(||x||\\neq0,||y||\\neq0\\)时，求解余弦相似度 \\[ \\cos(\\theta)=\\frac{x\\cdot y}{||x||\\cdot||y||} \\] 推导 \\[ w\\cdot x_1+b=1 \\] \\[ w\\cdot x_2+b=-1 \\] \\[ w(x_1-x_2)=2 \\] \\[ ||w||\\cdot||(x_1-x_2)||\\cdot||\\cos(\\theta)||=2 \\] \\[ ||w||\\cdot||d||=2 \\] \\[ d=\\frac{2}{||w||} \\] 转化为凸优化问题 \\[ y(w\\cdot x+b)\\geq1\\begin{cases}w\\cdot x+b\\geq1\\quad y=1\\\\w\\cdot x+b\\leq1\\quad y=-1\\end{cases} \\] 求\\(d=\\frac{2}{||w||}\\)最大值，也就是求\\(min\\frac{||w||^2}{2}\\) 凸优化问题 无约束优化问题：\\(minf(x)\\)——费马定理 带等式约束的优化问题：\\(minf(x)\\)–拉格朗日乘子法 \\[ s.t.h_i(x)=0,\\quad i=1,2,\\cdots,n\\\\ L(x,\\lambda)=f(x)+\\sum_{i=1}^{n}{\\lambda_ih_i(x)} \\] 带不等式约束的优化问题：\\(minf(x)\\)——KKT（Karush-Kuhn-Tucker）条件 \\[ s.t.h_i(x)=0,\\quad i=1,2,\\cdots,n\\\\ g_i(x)\\leq0,\\quad i=1,2,\\cdots,k\\\\ L(x,\\lambda,v)=f(x)+\\sum_{i=1}^{k}{\\lambda_ig_i(x)}+\\sum_{i=1}^{n}{v_ih_i(x)} \\] 这里我们处理的是带不等式约束的优化问题： \\[ L(\\alpha,w,b)=\\frac{1}{2}||w||^2-\\sum_{i=1}^{k}{\\alpha(1-y_i(w^Tx_i+b))} \\] \\[ s.t.\\quad 1-y_i(w^Tx_i+b)\\leq0 \\] 简化为对偶问题：\\(\\underset {w,b}{min}\\quad\\underset{\\alpha\\geq0}{max}\\quad L(\\alpha,w,b)\\) 可以等价为：\\(\\underset {\\alpha\\geq0}{max}\\quad\\underset {w,b}{min}\\quad L(\\alpha,w,b)\\) 所以，先对\\(w,b\\)进行求导， \\[ \\frac{\\partial L}{\\partial w}=0\\rightarrow w=\\sum_{i=1}^{n}{\\alpha_iy_ix_i} \\] \\[ \\frac{\\partial L}{\\partial b}=0\\rightarrow \\sum_{i=1}^{n}{\\alpha_iy_i}=0 \\] 然后，将上式代入\\(L(\\alpha,w,b)\\)得到一个只与\\(\\alpha\\)相关的函数。 \\[ L(\\alpha,w,b)=\\sum_{i=1}^{n}{\\alpha_i}-\\frac{1}{2}\\sum_{i,j=1}^{n}{\\alpha_i\\alpha_jy_iy_jx_i^Tx_j} \\] 最后优化问题可表示为： \\[ \\underset {\\alpha\\geq0}{max}\\quad\\underset {w,b}{min}\\quad L(\\alpha,w,b)=\\underset {\\alpha\\geq0}{max}\\quad\\sum_{i=1}^{n}{\\alpha_i}-\\frac{1}{2}\\sum_{i,j=1}^{n}{\\alpha_i\\alpha_jy_iy_jx_i^Tx_j} \\] \\[ =\\underset {\\alpha\\geq0}{min}\\quad \\frac{1}{2}\\sum_{i,j=1}^{n}{\\alpha_i\\alpha_jy_iy_jx_i^Tx_j}-\\sum_{i=1}^{n}{\\alpha_i} \\] \\[ s.t.\\quad \\sum_{i=1}^{n}{a_iy_i=0}\\quad a_i\\geq0,i=1,2,\\cdots,n \\] 由此，可求出最优解\\(\\alpha^{*}\\)，然后再反代回去求\\(w,b\\)。 \\[ w^{*}=\\sum_{i=1}^{n}{\\alpha^{*}_iy_ix_i} \\] \\[ b^{*}=y_i-(w^{*})^Tx_i \\] 线性分类示例代码 123456789101112131415161718192021222324252627282930313233343536373839import numpy as npimport matplotlib.pyplot as pltfrom sklearn import svm# 创建40个点x_data = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]y_data = [0]*20 +[1]*20plt.scatter(x_data[:,0],x_data[:,1],c=y_data)plt.show()# 训练和拟合模型# (SVC，C是Classification(分类);SVR，R是Regression(回归))。model = svm.SVC(kernel=&#x27;linear&#x27;) # linear是线性核model.fit(x_data, y_data)# 获取分离平面 plt.scatter(x_data[:,0],x_data[:,1],c=y_data)x_test = np.array([[-5],[5]])d = -model.intercept_/model.coef_[0][1]k = -model.coef_[0][0]/model.coef_[0][1]y_test = d + k*x_testplt.plot(x_test, y_test, &#x27;k&#x27;)plt.show()# 画出通过支持向量的分界线b1 = model.support_vectors_[0]y_down = k*x_test + (b1[1] - k*b1[0])b2 = model.support_vectors_[-1]y_up = k*x_test + (b2[1] - k*b2[0])plt.scatter(x_data[:,0],x_data[:,1],c=y_data)x_test = np.array([[-5],[5]])d = -model.intercept_/model.coef_[0][1]k = -model.coef_[0][0]/model.coef_[0][1]y_test = d + k*x_testplt.plot(x_test, y_test, &#x27;k&#x27;)plt.plot(x_test, y_down, &#x27;r--&#x27;)plt.plot(x_test, y_up, &#x27;b--&#x27;)plt.show() 非线性分类示例代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import matplotlib.pyplot as pltimport numpy as npfrom sklearn.metrics import classification_reportfrom sklearn import svm# 载入数据data = np.genfromtxt(&quot;LR-testSet2.txt&quot;, delimiter=&quot;,&quot;)x_data = data[:,:-1]y_data = data[:,-1] def plot(): x0 = [] x1 = [] y0 = [] y1 = [] # 切分不同类别的数据 for i in range(len(x_data)): if y_data[i]==0: x0.append(x_data[i,0]) y0.append(x_data[i,1]) else: x1.append(x_data[i,0]) y1.append(x_data[i,1]) # 画图 scatter0 = plt.scatter(x0, y0, c=&#x27;b&#x27;, marker=&#x27;o&#x27;) scatter1 = plt.scatter(x1, y1, c=&#x27;r&#x27;, marker=&#x27;x&#x27;) #画图例 plt.legend(handles=[scatter0,scatter1],labels=[&#x27;label0&#x27;,&#x27;label1&#x27;],loc=&#x27;best&#x27;) plot()plt.show()# 创建和训练模型# C和gammamodel = svm.SVC(kernel=&#x27;rbf&#x27;) # rbf是gai&#x27;si径向基函数model.fit(x_data, y_data)# 获取数据值所在的范围x_min, x_max = x_data[:, 0].min() - 1, x_data[:, 0].max() + 1y_min, y_max = x_data[:, 1].min() - 1, x_data[:, 1].max() + 1# 生成网格矩阵xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))z = model.predict(np.c_[xx.ravel(), yy.ravel()])# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据z = z.reshape(xx.shape)# 等高线图cs = plt.contourf(xx, yy, z)plot() plt.show() SMO（Sequential minimal optimization）算法 核函数 构造核函数使得运算结果等同于非线性映射， 同时运算量要远远小于非线性映射。 h次多项式核函数：\\(K(X_i,X_j)=(X_i,X_j)^h\\) 高斯径向基函数核函数：\\(K(X_i,X_j)=e^{-\\frac{||X_i-X_j||^2}{2\\sigma^2}}\\) S型核函数：\\(K(X_i,X_j)=\\tanh(kX_iY_i-\\delta)\\) 参考 支持向量机","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://liujk6525.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://liujk6525.github.io/tags/Python/"},{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"主成分分析","slug":"主成分分析","date":"2023-06-07T13:06:14.000Z","updated":"2023-06-07T13:39:25.497Z","comments":true,"path":"机器学习/主成分分析/","link":"","permalink":"https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/","excerpt":"","text":"主成分分析(Principal Component Analysis，PCA) 算法流程： 数据预处理：中心化\\(𝑋−\\overline𝑋\\)。 求样本的协方差矩阵\\(\\frac{1}{m}XX^T\\) 。 对协方差矩阵\\(\\frac{1}{m}XX^T\\)做特征值分解。 选出最大的\\(k\\)个特征值对应的\\(k\\)个特征向量。 将原始数据投影到选取的特征向量上。 输出投影后的数据集。 协方差 方差就是描述一个数据的离散程度： \\[ var(X)=\\frac{\\sum_{i=1}^{n}{(X_i-\\overline X)(X_i-\\overline X)}}{n-1} \\] 协方差是描述两个数据的相关性，接近1就是正相关， 接近-1就是负相关，接近0就是不相关。 \\[ cov(X,Y)=\\frac{\\sum_{i=1}^{n}{(X_i-\\overline X)(Y_i-\\overline Y)}}{n-1} \\] 协方差矩阵 协方差矩阵是一个对称的矩阵，对角线是各个维度的方差。 二维： \\[ C=\\left[\\begin{matrix} cov(x,x)&amp;cov(x,y)\\\\ cov(y,x)&amp;cov(y,y)) \\end{matrix})\\right]=\\left[\\begin{matrix} \\frac{\\sum_{i=1}^{m}{(x_i^2)}}{m}&amp;\\frac{\\sum_{i=1}^{m}{(x_iy_i)}}{m}\\\\ \\frac{\\sum_{i=1}^{m}{(y_ix_i)}}{m}&amp;\\frac{\\sum_{i=1}^{m}{(y_i^2)}}{m} \\end{matrix})\\right] \\] 三维： \\[ C=\\left[\\begin{matrix} cov(x,x)&amp;cov(x,y)&amp;cov(x,z)\\\\ cov(y,x)&amp;cov(y,y))&amp;cov(y,z)\\\\ cov(z,x)&amp;cov(z,y)&amp;cov(z,z) \\end{matrix})\\right] \\] 示例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364from sklearn.neural_network import MLPClassifierfrom sklearn.datasets import load_digitsfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import classification_report,confusion_matriximport numpy as npimport matplotlib.pyplot as pltdigits = load_digits()#载入数据x_data = digits.data #数据y_data = digits.target #标签x_train,x_test,y_train,y_test = train_test_split(x_data,y_data) #分割数据1/4为测试数据，3/4为训练数据# 创建并拟合多层感知机分类器模型mlp = MLPClassifier(hidden_layer_sizes=(100,50) ,max_iter=500)mlp.fit(x_train,y_train)# 数据中心化def zeroMean(dataMat): # 按列求平均，即各个特征的平均 meanVal = np.mean(dataMat, axis=0) newData = dataMat - meanVal return newData, meanValdef pca(dataMat,top): # 数据中心化 newData,meanVal=zeroMean(dataMat) # np.cov用于求协方差矩阵，参数rowvar=0说明数据一行代表一个样本 covMat = np.cov(newData, rowvar=0) # np.linalg.eig求矩阵的特征值和特征向量 eigVals, eigVects = np.linalg.eig(np.mat(covMat)) # 对特征值从小到大排序 eigValIndice = np.argsort(eigVals) # 最大的n个特征值的下标 n_eigValIndice = eigValIndice[-1:-(top+1):-1] # 最大的n个特征值对应的特征向量 n_eigVect = eigVects[:,n_eigValIndice] # 低维特征空间的数据 lowDDataMat = newData*n_eigVect # 利用低纬度数据来重构数据 reconMat = (lowDDataMat*n_eigVect.T) + meanVal # 返回低维特征空间的数据和重构的矩阵 return lowDDataMat,reconMat # PCA降二维lowDDataMat,reconMat = pca(x_data,2) # 重构的数据x = np.array(lowDDataMat)[:,0]y = np.array(lowDDataMat)[:,1]plt.scatter(x,y,c=y_data)plt.show()# PCA降三维lowDDataMat,reconMat = pca(x_data,3)from mpl_toolkits.mplot3d import Axes3D x = np.array(lowDDataMat)[:,0]y = np.array(lowDDataMat)[:,1]z = np.array(lowDDataMat)[:,2]ax = plt.figure().add_subplot(111, projection = &#x27;3d&#x27;) ax.scatter(x, y, z, c = y_data, s = 10) #点为红色三角形 plt.show() 参考 主成分分析","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://liujk6525.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://liujk6525.github.io/tags/Python/"},{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"聚类算法","slug":"聚类算法","date":"2023-06-07T11:53:51.000Z","updated":"2023-06-07T13:01:39.498Z","comments":true,"path":"机器学习/聚类算法/","link":"","permalink":"https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/","excerpt":"","text":"聚类（Cluster）算法 K-Means 以空间中k个点为中心进行聚类，对最靠近他们的对象归类。通过迭代的方法，逐次更新各聚类中心的值，直至得到最好的聚类结果。 同一聚类中的对象相似度较高；而不同聚类中的对象相似度较小。 算法流程： 先从没有标签的元素集合A中随机取k个元素，作为 k个子集各自的重心。 分别计算剩下的元素到k个子集重心的距离（这里的距离也可以使用欧氏距离），根据距离将这些元素分别划归到最近的子集。 根据聚类结果，重新计算重心（重心的计算方法是 计算子集中所有元素各个维度的算数平均数）。 将集合A中全部元素按照新的重心然后再重新聚类。 重复第4步，直到聚类结果不再发生变化。 示例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061from sklearn.cluster import KMeansimport numpy as npimport matplotlib.pyplot as plt# 忽视警告import warningswarnings.filterwarnings(&quot;ignore&quot;)# 载入数据data = np.genfromtxt(&quot;kmeans.txt&quot;, delimiter=&quot; &quot;)# 设置k值，这里需要手动设置K值k=4# 创建并训练模型model = KMeans(n_clusters=k,n_init=&#x27;auto&#x27;)model.fit(data)# 分类中心点坐标centers = model.cluster_centers_print(centers)# 预测结果result = model.predict(data)print(result)# 画出各个数据点，用不同颜色表示分类mark = [&#x27;^r&#x27;, &#x27;vb&#x27;, &#x27;pg&#x27;, &#x27;+c&#x27;]for i,d in enumerate(data): plt.plot(d[0], d[1], mark[result[i]])# 画出各个分类的中心点mark = [&#x27;*r&#x27;, &#x27;*b&#x27;, &#x27;*g&#x27;, &#x27;*c&#x27;]for i,center in enumerate(centers): plt.plot(center[0],center[1], mark[i], markersize=20) plt.show()# 获取数据值所在的范围x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1# 生成网格矩阵xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))z = model.predict(np.c_[xx.ravel(), yy.ravel()])# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据z = z.reshape(xx.shape)# 等高线图cs = plt.contourf(xx, yy, z)# 画出各个数据点，用不同颜色表示分类mark = [&#x27;^r&#x27;, &#x27;vb&#x27;, &#x27;pg&#x27;, &#x27;+c&#x27;]for i,d in enumerate(data): plt.plot(d[0], d[1], mark[result[i]])# 画出各个分类的中心点mark = [&#x27;*r&#x27;, &#x27;*b&#x27;, &#x27;*g&#x27;, &#x27;*c&#x27;]for i,center in enumerate(centers): plt.plot(center[0],center[1], mark[i], markersize=20) plt.show() Mini Batch K-Means 采用小批量的数据子集减小计算时间。也就是随机抽取数据子集进行训练算法，结果一般只略差于标准算法。 1：从数据集中随机抽取一些数据形成小批量，把他们分配给最近的质心 2：更新质心，与K-Means算法相比，数据的更新是在每一个小的样本集上。 示例代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162from sklearn.cluster import MiniBatchKMeansimport numpy as npimport matplotlib.pyplot as plt# 忽视警告import warningswarnings.filterwarnings(&quot;ignore&quot;)# 载入数据data = np.genfromtxt(&quot;kmeans.txt&quot;, delimiter=&quot; &quot;)# 设置k值k = 4 # 创建并训练模型model = MiniBatchKMeans(n_clusters=k,n_init=&#x27;auto&#x27;)model.fit(data)# 分类中心点坐标centers = model.cluster_centers_print(centers)# 预测结果result = model.predict(data)print(result)# 画出各个数据点，用不同颜色表示分类mark = [&#x27;or&#x27;, &#x27;ob&#x27;, &#x27;og&#x27;, &#x27;oy&#x27;]for i,d in enumerate(data): plt.plot(d[0], d[1], mark[result[i]])# 画出各个分类的中心点mark = [&#x27;*r&#x27;, &#x27;*b&#x27;, &#x27;*g&#x27;, &#x27;*y&#x27;]for i,center in enumerate(centers): plt.plot(center[0],center[1], mark[i], markersize=20) plt.show()# 获取数据值所在的范围x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1# 生成网格矩阵xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))z = model.predict(np.c_[xx.ravel(), yy.ravel()])# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据z = z.reshape(xx.shape)# 等高线图cs = plt.contourf(xx, yy, z)# 显示结果# 画出各个数据点，用不同颜色表示分类mark = [&#x27;or&#x27;, &#x27;ob&#x27;, &#x27;og&#x27;, &#x27;oy&#x27;]for i,d in enumerate(data): plt.plot(d[0], d[1], mark[result[i]])# 画出各个分类的中心点mark = [&#x27;*r&#x27;, &#x27;*b&#x27;, &#x27;*g&#x27;, &#x27;*y&#x27;]for i,center in enumerate(centers): plt.plot(center[0],center[1], mark[i], markersize=20) plt.show() ​ DBSCAN（Density-Based Spatial Clustering of Applications with Noise） 能够将具有足够高密度的区域划分为簇，并可在噪声的空间数据库中发现任意形状的聚类。 \\(\\Epsilon\\)邻域：给定对象半径\\(\\Epsilon\\)内的区域称为该对象的\\(\\Epsilon\\)邻域。 核心对象：如果给定\\(\\Epsilon\\)邻域内的样本点数大于等于\\(Minpoints\\)，则该对象为核心对象。 直接密度可达：给定一个对象集合\\(D\\)，如果\\(p\\)在\\(q\\)的\\(\\Epsilon\\)邻域内， 且\\(q\\)是一个核心对象，则我们说对象\\(p\\)从\\(q\\)触发是直接密度可达的（directly density-reachable）。 密度可达：集合\\(D\\)，存在一个对象链 \\(p_1,p_2,\\cdots ,pn,p_1=q,p_n=p\\)，\\(p_{i+1}\\)是从\\(p_i\\)关于𝜀和\\(Minpoints\\)直接密度可达，则称点\\(p\\)是从\\(q\\)关于\\(\\Epsilon\\)和\\(Minpoints\\)密度可达的。 密度相连：集合\\(D\\)存在点\\(o\\)，使得点\\(p、q\\)是从\\(o\\)关于\\(\\Epsilon\\)和 \\(Minpoints\\)密度可达的，那么点\\(p、q\\)是关于\\(\\Epsilon\\)和 \\(Minpoints\\)密度相连的。 算法流程： 指定合适的\\(\\Epsilon\\)和 \\(Minpoints\\)。 计算所有的样本点，如果点\\(p\\)的\\(\\Epsilon\\)邻域里有超过\\(Minpoints\\)个点，则创建一个以\\(p\\)为核心点的新簇。 反复寻找这些核心点直接密度可达（之后可能是密度可达） 的点，将其加入到相应的簇，对于核心点发生“密度相连” 状况的簇，给予合并。 没有新的点可以被添加到任何簇时，算法结束 示例代码 12345678910111213141516from sklearn.cluster import DBSCANimport numpy as npimport matplotlib.pyplot as plt# 载入数据data = np.genfromtxt(&quot;kmeans.txt&quot;, delimiter=&quot; &quot;)result = model.fit_predict(data)result# 画出各个数据点，用不同颜色表示分类mark = [&#x27;or&#x27;, &#x27;ob&#x27;, &#x27;og&#x27;, &#x27;oy&#x27;, &#x27;ok&#x27;, &#x27;om&#x27;]for i,d in enumerate(data): plt.plot(d[0], d[1], mark[result[i]]) plt.show() 12345678910111213141516import numpy as npimport matplotlib.pyplot as pltfrom sklearn import datasets# 载入数据x1, y1 = datasets.make_circles(n_samples=2000, factor=0.5, noise=0.05)x2, y2 = datasets.make_blobs(n_samples=1000, centers=[[1.2,1.2]], cluster_std=[[.1]])x = np.concatenate((x1, x2))plt.scatter(x[:, 0], x[:, 1], marker=&#x27;o&#x27;)plt.show()from sklearn.cluster import DBSCANy_pred = DBSCAN(eps = 0.2, min_samples=50).fit_predict(x)plt.scatter(x[:, 0], x[:, 1], c=y_pred)plt.show() 参考 聚类算法","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://liujk6525.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://liujk6525.github.io/tags/Python/"},{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"贝叶斯算法","slug":"贝叶斯算法","date":"2023-06-07T07:56:38.000Z","updated":"2023-06-07T11:52:30.005Z","comments":true,"path":"机器学习/贝叶斯算法/","link":"","permalink":"https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/","excerpt":"","text":"贝叶斯算法 总体信息：当前总体样本符合某种分布。比如抛硬币符合二项 分布；学生的某一科的成绩符合正态分布。 样本信息：通过抽样得到的部分样本的某种分布。 抽样信息=总体信息+样本信息 先验信息：抽样之前，有关推断问题中未知参数的一些信息， 通常来自于经验或历史资料。 基于抽样信息进行统计推断的理论和方法称为经典统计学。 基于抽样信息+先验信息进行统计推断的方法和理 论，称为贝叶斯统计学。 贝叶斯定理 已知\\(P(X|H)\\)，要求解\\(P(H|X)\\) \\[ P(H|X)=\\frac{P(X|H)P(H)}{P(X)} \\] 示例代码 123456789101112131415161718# 导入算法包以及数据集import numpy as npfrom sklearn import datasetsfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import classification_report,confusion_matrixfrom sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB# 载入数据iris = datasets.load_iris()x_train,x_test,y_train,y_test = train_test_split(iris.data, iris.target) # 创建并拟合模型mul_nb = GaussianNB()mul_nb.fit(x_train,y_train)# 评估print(classification_report(mul_nb.predict(x_test),y_test)) 词袋模型(Bag of Words) Bag of words model（BoW）最早出现在自然语言处理（Natural Language Processing）和信息检索 （Information Retrieval）领域。 该模型忽略掉文本的语法和语序等要素，将其仅仅看作是若干个词汇的集合，文档中每个单词的出现都是独立的。BoW使用一组无序的单词(words)来表达一段文字或一个文档。 简单例子 首先给出两个简单的文本文档如下： John likes to watch movies. Mary likes too. John also likes to watch football games. 对于上述两个文档中出现的单词，构建如下一个词典 (dictionary)： {“John”: 1, “likes”: 2,“to”: 3, “watch”: 4, “movies”: 5,“also”: 6, “football”: 7, “games”: 8,“Mary”: 9, “too”: 10} 上面的词典中包含10个单词, 每个单词有唯一的索引, 那么每个文本可以使用一个10维的向量来表示。 [1, 2, 1, 1, 1, 0, 0, 0, 1, 1] [1, 1,1, 1, 0, 1, 1, 1, 0, 0] 该向量与原来文本中单词出现的顺序没有关系，而是词典中每个单词在文本中出现的频率。 TF-IDF TF（Term Frequency） 词频 IDF （Inverse Document Frequency）逆文档频率 参考 贝叶斯算法","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://liujk6525.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://liujk6525.github.io/tags/Python/"},{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"集成学习","slug":"集成学习","date":"2023-06-07T01:32:09.000Z","updated":"2023-06-07T07:56:16.137Z","comments":true,"path":"机器学习/集成学习/","link":"","permalink":"https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/","excerpt":"集成学习（Ensemble Learning） 集成学习就是组合多个学习器，最后可以得到一个更 好的学习器。 集成学习算法： 个体学习器之间不存在强依赖关系，装袋（Bagging） 随机森林（Random Forest） 个体学习器之间存在强依赖关系，提升（Boosting） Stacking","text":"集成学习（Ensemble Learning） 集成学习就是组合多个学习器，最后可以得到一个更 好的学习器。 集成学习算法： 个体学习器之间不存在强依赖关系，装袋（Bagging） 随机森林（Random Forest） 个体学习器之间存在强依赖关系，提升（Boosting） Stacking Bagging Bagging也叫做Bootstrap Aggregating，是在原始 数据集选择S次后得到S个新数据集的一种技术。是一 种有放回抽样。 原始训练数据集\\(0,1,2,3,4,5,6,7,8,9\\) Bagging采样\\(1,3,5,2,6,4,2,5,7,0——未采样8,9\\) 示例代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 导入算法包以及数据集from sklearn import neighborsfrom sklearn import datasetsfrom sklearn.ensemble import BaggingClassifierfrom sklearn import treefrom sklearn.model_selection import train_test_splitimport numpy as npimport matplotlib.pyplot as plt划分数据集iris = datasets.load_iris()x_data = iris.data[:,:2]y_data = iris.targetx_train,x_test,y_train,y_test = train_test_split(x_data, y_data)# 创建并训练KNN模型knn = neighbors.KNeighborsClassifier()knn.fit(x_train, y_train)def plot(model): # 获取数据值所在的范围 x_min, x_max = x_data[:, 0].min() - 1, x_data[:, 0].max() + 1 y_min, y_max = x_data[:, 1].min() - 1, x_data[:, 1].max() + 1 # 生成网格矩阵 xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02)) z = model.predict(np.c_[xx.ravel(), yy.ravel()])# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据 z = z.reshape(xx.shape) # 等高线图 cs = plt.contourf(xx, yy, z) # 画图plot(knn)# 样本散点图plt.scatter(x_data[:, 0], x_data[:, 1], c=y_data)plt.xlabel(&quot;knn&quot;)plt.show()knn.score(x_test, y_test) # KNN模型准确率# 创建并训练bagging_knn模型bagging_knn = BaggingClassifier(knn, n_estimators=100)bagging_knn.fit(x_train, y_train)plot(bagging_knn)# 样本散点图plt.scatter(x_data[:, 0], x_data[:, 1], c=y_data)plt.xlabel(&#x27;bagging_knn&#x27;)plt.show()bagging_knn.score(x_test, y_test) # bagging_knn模型准确率 随机森林（Random Forest） 算法流程： 随机选取样本：在样本集用bagging的方式随机选择n个样本。 随机选取特征：从所有属性d中随机选择k个属性（k&lt;d），然后从k个属性中选择最佳分割属性作为节点建立 CART决策树。 重复以上两个步骤m次，建立m棵CART决策树。 这m棵CART决策树形成随机森林，通过投票表决结 果，决定数据属于哪一类。 示例代码 12345678910111213141516171819202122232425262728293031323334353637383940from sklearn import treefrom sklearn.model_selection import train_test_splitfrom sklearn.ensemble import RandomForestClassifier # 集成学习中的随机森林模块import numpy as npimport matplotlib.pyplot as plt# 载入数据data = np.genfromtxt(&quot;LR-testSet2.txt&quot;, delimiter=&quot;,&quot;)x_data = data[:,:-1]y_data = data[:,-1]plt.scatter(x_data[:,0],x_data[:,1],c=y_data)plt.show()# 划分数据集x_train,x_test,y_train,y_test = train_test_split(x_data, y_data, test_size = 0.5)def plot(model): # 获取数据值所在的范围 x_min, x_max = x_data[:, 0].min() - 1, x_data[:, 0].max() + 1 y_min, y_max = x_data[:, 1].min() - 1, x_data[:, 1].max() + 1 # 生成网格矩阵 xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02)) z = model.predict(np.c_[xx.ravel(), yy.ravel()])# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据 z = z.reshape(xx.shape) # 等高线图 cs = plt.contourf(xx, yy, z) # 样本散点图 plt.scatter(x_test[:, 0], x_test[:, 1], c=y_test) plt.show()# 创建并训练随机森林模型RF = RandomForestClassifier(n_estimators=50)RF.fit(x_train, y_train)plot(RF)RF.score(x_test, y_test) Boosting AdaBoost （Adaptive Boosting）算法，它的自适应在于，前一个基本分类器被错误分类的样本的权值会增大，而正确分类的样本的权值会减小，并再次用来训练下一个基本分类器。同时，在每一轮迭代中，加入一个新的弱分类器，直到达到某个预定的足够小的错误率或达到预先指定的最大迭代次数才确定最终的强分类器。 算法流程： 初始化训练数据的权值分布\\(D1\\)。假设有\\(N\\)个训练样本数据，则每一个训练样本最开始时，都被赋予 相同的权值\\(w~1~=1/N\\)。 训练弱分类器\\(h_i\\)。 如果某个训练样本点，被弱分类器\\(h_i\\)准确地分类，那么在构造下一个训练集中，它对应的权值要减小； 如果某个训练样本点，被弱分类器\\(h_i\\)错误分类，那么它的权值就应该增大。权值更新过的样本集被用于训练下一个分类器，整个训练过程如此迭代地进行下去。 将各个训练得到的弱分类器组合成一个强分类器。各个弱分类器的训练过程结束后， 加大分类误差率小的弱分类器的权重，使其在最终的分类函数中起着较大的决定作用， 降低分类误差率大的弱分类器的权重，使其在最终的分类函数中起着较小的决定作用。 示例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243import numpy as npimport matplotlib.pyplot as pltfrom sklearn import treefrom sklearn.ensemble import AdaBoostClassifierfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.datasets import make_gaussian_quantilesfrom sklearn.metrics import classification_report# 生成2维正态分布，生成的数据按分位数分为两类，500个样本,2个样本特征x1, y1 = make_gaussian_quantiles(n_samples=500, n_features=2,n_classes=2)# 生成2维正态分布，生成的数据按分位数分为两类，400个样本,2个样本特征均值都为3x2, y2 = make_gaussian_quantiles(mean=(3, 3), n_samples=500, n_features=2, n_classes=2)# 将两组数据合成一组数据x_data = np.concatenate((x1, x2))y_data = np.concatenate((y1, - y2 + 1))plt.scatter(x_data[:, 0], x_data[:, 1], c=y_data)plt.show()# AdaBoost模型model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),n_estimators=10)# 训练模型model.fit(x_data, y_data)# 获取数据值所在的范围x_min, x_max = x_data[:, 0].min() - 1, x_data[:, 0].max() + 1y_min, y_max = x_data[:, 1].min() - 1, x_data[:, 1].max() + 1# 生成网格矩阵xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))# 获取预测值z = model.predict(np.c_[xx.ravel(), yy.ravel()])z = z.reshape(xx.shape)# 等高线图cs = plt.contourf(xx, yy, z)# 样本散点图plt.scatter(x_data[:, 0], x_data[:, 1], c=y_data)plt.show()# 模型准确率model.score(x_data,y_data) Stacking 使用多个不同的分类器对训练集进预测，把预测 得到的结果作为一个次级分类器的输入。次级分 类器的输出是整个模型的预测结果。 示例代码 1234567891011121314151617181920212223242526272829303132from sklearn import datasets from sklearn import model_selection from sklearn.linear_model import LogisticRegressionfrom sklearn.neighbors import KNeighborsClassifier from sklearn.tree import DecisionTreeClassifierfrom mlxtend.classifier import StackingClassifierimport numpy as np # 载入数据集iris = datasets.load_iris() # 只要第1,2列的特征x_data, y_data = iris.data[:, 1:3], iris.target # 定义三个不同的分类器clf1 = KNeighborsClassifier(n_neighbors=1) clf2 = DecisionTreeClassifier() clf3 = LogisticRegression() # 定义一个次级分类器lr = LogisticRegression() sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr) for clf,label in zip([clf1, clf2, clf3, sclf], [&#x27;KNN&#x27;,&#x27;Decision Tree&#x27;,&#x27;LogisticRegression&#x27;,&#x27;StackingClassifier&#x27;]): scores = model_selection.cross_val_score(clf, x_data, y_data, cv=3, scoring=&#x27;accuracy&#x27;) print(&quot;Accuracy: %0.2f [%s]&quot; % (scores.mean(), label)) # 可视化 sclf.fit(x_train,y_train)plot(sclf)plt.scatter(x_data[:,0],x_data[:,1],c=y_data) 参考 集成学习","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://liujk6525.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://liujk6525.github.io/tags/Python/"},{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"决策树","slug":"决策树","date":"2023-06-06T12:25:49.000Z","updated":"2023-06-07T01:29:34.425Z","comments":true,"path":"机器学习/决策树/","link":"","permalink":"https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/","excerpt":"决策树 （Decision Tree） 比较适合分析离散数据。 如果是连续数据要先转成离散数据再做分析 熵（entropy） 1948年，香浓提出了“信息熵”的概念， 一条信息的信息量大小和它的不确定性有直接的关系， 要搞清楚一件非常非常不确定的事情，或者是一无所知的事情，需要了解大量信息。—&gt;信息量的度量就等于不确定性的多少。","text":"决策树 （Decision Tree） 比较适合分析离散数据。 如果是连续数据要先转成离散数据再做分析 熵（entropy） 1948年，香浓提出了“信息熵”的概念， 一条信息的信息量大小和它的不确定性有直接的关系， 要搞清楚一件非常非常不确定的事情，或者是一无所知的事情，需要了解大量信息。—&gt;信息量的度量就等于不确定性的多少。 信息熵公式： \\[ H[x]=-\\sum_{x}p(x)logp(x) \\] ID3算法 决策树会选择最大化信息增益来对结点进行划分。 信息增益（Information Gain）计算： \\[ Info(D)=-\\sum_{i=1}^{m}p_ilog(p_i) \\] \\[ Info_A(D)=-\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}\\times Info(D_j) \\] \\[ Gain(A)=Info(D)-Info_A(D) \\] RID age income student credit_rating class_buys_computer 1 youth high no fair no 2 youth high no excellent no 3 middle_aged high no fair yes 4 senior medium no fair yes 5 senior low yes fair yes 6 senior low yes excellent no 7 middle_aged low yes excellent yes 8 youth medium no fair no 9 youth low yes fair yes 10 senior medium yes fair yes 11 youth medium yes excellent yes 12 middle_aged medium no excellent yes 13 middle_aged high yes fair yes 14 senior medium no excellent no 计算age的信息增益: \\[ Info(D)=-\\frac{9}{14}log_2(\\frac{9}{14})-\\frac{5}{14}log_2(\\frac{5}{14})=0.94 \\] \\[ Info_{age}(D)=\\frac{5}{14}(-\\frac{2}{5}log_2\\frac{2}{5}-\\frac{3}{5}log_2\\frac{3}{5})+ \\frac{4}{14}(-\\frac{4}{4}log_2\\frac{4}{4}-\\frac{0}{4}log_2\\frac{0}{4})+ \\frac{5}{14}(-\\frac{3}{5}log_2\\frac{3}{5}-\\frac{2}{5}log_2\\frac{2}{5}) \\] \\[ Gain(age)=Info(D)-Info_A(D)=0.94-0.694=0.246 \\] 其他的也是类似计算。 C4.5算法 信息增益的方法倾向于首先选择因子数较多的变量 。 信息增益的改进：增益率 \\[ SplitInfo_A(D)=-\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}\\times log_2(\\frac{|D_j|}{|D|}) \\] \\[ GainRatio(A)=\\frac{Gain(A)}{SpliInfo_A(D)} \\] CART算法 CART决策树的生成就是递归地构建二叉决策树的过程。 CART用基尼（Gini）系数最小化准则来进行特征选择，生成二叉树。 Gini系数计算： \\[ Gini(D)=1-\\sum_{i=1}^{m}p_i^2 \\] \\[ Gini_A(D)=\\frac{|D_1|}{|D|}Gini(D_1)+\\frac{|D_2|}{|D|}Gini(D_2) \\] \\[ \\Delta Gini(A)=Gini(D)-Gini_A(D) \\] 优点：小规模数据集有效 缺点： 处理连续变量不好 类别较多时，错误增加的比较快 不能处理大量数据 线性二分类示例代码 12345678910111213141516171819202122232425262728293031323334353637import matplotlib.pyplot as pltimport numpy as npfrom sklearn.metrics import classification_reportfrom sklearn import tree # 决策树模块# 载入数据data = np.genfromtxt(&quot;LR-testSet.csv&quot;, delimiter=&quot;,&quot;)x_data = data[:,:-1]y_data = data[:,-1]plt.scatter(x_data[:,0],x_data[:,1],c=y_data) plt.show()# 创建决策树模型model = tree.DecisionTreeClassifier()# 输入数据建立模型model.fit(x_data, y_data)# 获取数据值所在的范围x_min, x_max = x_data[:, 0].min() - 1, x_data[:, 0].max() + 1y_min, y_max = x_data[:, 1].min() - 1, x_data[:, 1].max() + 1# 生成网格矩阵xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))z = model.predict(np.c_[xx.ravel(), yy.ravel()])# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据z = z.reshape(xx.shape)# 等高线图cs = plt.contourf(xx, yy, z)# 样本散点图plt.scatter(x_data[:, 0], x_data[:, 1], c=y_data)plt.show()# 测试与评估predictions = model.predict(x_data)print(classification_report(predictions,y_data)) 非线性二分类示例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243import matplotlib.pyplot as pltimport numpy as npfrom sklearn.metrics import classification_reportfrom sklearn import treefrom sklearn.model_selection import train_test_split# 载入数据data = np.genfromtxt(&quot;LR-testSet2.txt&quot;, delimiter=&quot;,&quot;)x_data = data[:,:-1]y_data = data[:,-1] plt.scatter(x_data[:,0],x_data[:,1],c=y_data) # s散点图plt.show()#分割数据x_train,x_test,y_train,y_test = train_test_split(x_data, y_data) # 创建决策树模型# max_depth，树的深度# min_samples_split 内部节点再划分所需最小样本数model = tree.DecisionTreeClassifier(max_depth=7,min_samples_split=4)# 拟合模型model.fit(x_train, y_train)# 获取数据值所在的范围x_min, x_max = x_data[:, 0].min() - 1, x_data[:, 0].max() + 1y_min, y_max = x_data[:, 1].min() - 1, x_data[:, 1].max() + 1# 生成网格矩阵xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))z = model.predict(np.c_[xx.ravel(), yy.ravel()])# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据z = z.reshape(xx.shape)# 等高线图cs = plt.contourf(xx, yy, z)# 样本散点图plt.scatter(x_data[:, 0], x_data[:, 1], c=y_data)plt.show()# 测试并评估predictions = model.predict(x_test)print(classification_report(predictions,y_test)) 回归树示例代码 123456789101112131415161718192021import numpy as npimport matplotlib.pyplot as pltfrom sklearn import tree# 载入数据data = np.genfromtxt(&quot;data.csv&quot;, delimiter=&quot;,&quot;)x_data = data[:,0,np.newaxis]y_data = data[:,1,np.newaxis]plt.scatter(x_data,y_data)plt.show()model = tree.DecisionTreeRegressor(max_depth=5)model.fit(x_data, y_data)x_test = np.linspace(20,80,100)x_test = x_test[:,np.newaxis]# 画图plt.plot(x_data, y_data, &#x27;b&#x27;)plt.plot(x_test, model.predict(x_test), &#x27;r&#x27;) plt.show() 参考 决策树","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://liujk6525.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://liujk6525.github.io/tags/Python/"},{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"KNN算法","slug":"KNN算法","date":"2023-06-06T12:05:23.000Z","updated":"2023-06-06T13:46:16.058Z","comments":true,"path":"机器学习/KNN算法/","link":"","permalink":"https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95/","excerpt":"K最近邻（K-Nearest Neighbor，KNN）分类算法 为了判断未知实例的类别，以所有已知类别的实例作为 参照选择参数K 计算未知实例与所有已知实例的距离 选择最近K个已知实例 根据少数服从多数的投票法则(majority-voting)，让 未知实例归类为K个最邻近样本中最多数的类别","text":"K最近邻（K-Nearest Neighbor，KNN）分类算法 为了判断未知实例的类别，以所有已知类别的实例作为 参照选择参数K 计算未知实例与所有已知实例的距离 选择最近K个已知实例 根据少数服从多数的投票法则(majority-voting)，让 未知实例归类为K个最邻近样本中最多数的类别 欧氏距离 \\[ E(x,y)=\\sqrt{\\sum_{i=0}^{n}(x_i-y_i)^2} \\] 其他的距离衡量：余弦值距离（cos），相关度（correlation），曼哈顿距离（Manhattan distance） 算法缺点： 算法复杂度较高（需要比较所有已知实例与要分类的实例） 当其样本分布不平衡时，比如其中一类样本过大（实例数量过多）占主导的时候，新的未知实例容易被归类为这个主导样本，因为这类样本实例的数量过大，但这个新的未知实例实际并没有接近目标样本 示例代码 1234567891011121314151617181920212223242526272829303132333435363738# 导入算法包以及数据集from sklearn import neighborsfrom sklearn import datasetsfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import classification_reportimport random# 载入数据iris = datasets.load_iris()print(iris)# 打乱数据切分数据集# x_train,x_test,y_train,y_test = train_test_split(iris.data, iris.target, test_size=0.2) #分割数据0.2为测试数据，0.8为训练数据#打乱数据data_size = iris.data.shape[0]index = [i for i in range(data_size)] random.shuffle(index) iris.data = iris.data[index]iris.target = iris.target[index]#切分数据集test_size = 40x_train = iris.data[test_size:]x_test = iris.data[:test_size]y_train = iris.target[test_size:]y_test = iris.target[:test_size]# 构建模型model = neighbors.KNeighborsClassifier(n_neighbors=3)model.fit(x_train, y_train)# 测试和评估prediction = model.predict(x_test)print(classification_report(y_test, prediction)) 参考 KNN算法","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://liujk6525.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://liujk6525.github.io/tags/Python/"},{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"逻辑回归","slug":"逻辑回归","date":"2023-06-05T13:32:23.000Z","updated":"2023-06-06T12:25:57.035Z","comments":true,"path":"机器学习/逻辑回归/","link":"","permalink":"https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/","excerpt":"逻辑回归（Logistic Regression） 是一种广义的线性回归分析模型，与多重线性回归有很多相同之处。它们的模型形式基本上相同，都具有$ w’x+b$，其区别在于他们的因变量不同， 多重线性回归直接将\\(w&#39;x+b\\)作为因变量， Logistic回归则通过函数L将\\(w&#39;x+b\\)对应一个隐状态\\(p\\)，\\(p =L(w&#39;x+b)\\)，然后根据\\(p\\)与\\(1-p\\)的大小决定因变量的值。 如果L是Logistic函数，就是Logistic回归， 如果L是多项式函数就是多项式回归。","text":"逻辑回归（Logistic Regression） 是一种广义的线性回归分析模型，与多重线性回归有很多相同之处。它们的模型形式基本上相同，都具有$ w’x+b$，其区别在于他们的因变量不同， 多重线性回归直接将\\(w&#39;x+b\\)作为因变量， Logistic回归则通过函数L将\\(w&#39;x+b\\)对应一个隐状态\\(p\\)，\\(p =L(w&#39;x+b)\\)，然后根据\\(p\\)与\\(1-p\\)的大小决定因变量的值。 如果L是Logistic函数，就是Logistic回归， 如果L是多项式函数就是多项式回归。 Logistic Function 定义逻辑回归的预测函数为\\(ℎ_\\theta(x) = 𝑔(\\theta^𝑇𝑥)\\) ，其中g(x)函数是sigmoid函数。 \\[ g(x)=\\frac{1}{1+e^{-x}} \\] \\[ h_\\theta(x)=\\frac{1}{1+e^{-\\theta^Tx}} \\] 当\\(\\theta^Tx≥0\\)，\\(g(\\theta^Tx)≥0.5\\) 当\\(\\theta^Tx≤0\\)，\\(g(\\theta^Tx)≤0.5\\) 逻辑回归的代价函数（Cost Function） \\[ Cost(h_\\theta(x),y)= \\begin{cases} -log(h_\\theta(x))\\quad\\quad\\quad if\\quad y=1\\\\ -log(1-h_\\theta(x))\\quad if\\quad y=0 \\end{cases} \\] \\[ =-ylog(h_\\theta(x))-(1-y)log(1-h_\\theta(x)) \\] 梯度下降法（Gradient Descent） \\[ J(\\theta)=-\\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}logh_\\theta(x^{(i)})+(1-y^{(i)})log(1-h_\\theta(x^{(i)}))] \\] 求解 \\(min_\\theta J(\\theta)\\) \\[ \\theta_j:=\\theta_j-\\alpha\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)} \\] 准确率|精准率|召回率|F1分数 混淆矩阵 实际 实际 1 0 预测 1 TP FP 预测 0 FN TN P（Positive）：代表1 N（Negative）：代表0 T（True）：代表预测正确 F（False）：代表预测错误 准确率：即预测正确的结果占总样本的百分比 \\[ 准确率=\\frac{TP+TN}{TP+TN+FP+FN} \\] 精准率（Precision）：是指在所有被预测为正的样本中实际为正的样本的概率。 \\[ 精准率=\\frac{TP}{TP+FP} \\] 精准率就是你认为找的是对的实际上多少是对的 召回率（Recall）：是指在实际为正的样本中被预测为正样本的概率。 \\[ 召回率=\\frac{TP}{TP+FN} \\] F1分数：精准率和召回率之间的一个平衡点。 \\[ F_1=\\frac{2\\times Precision\\times Recall}{Precision+Recall} \\] 逻辑回归示例代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import matplotlib.pyplot as pltimport numpy as npfrom sklearn.metrics import classification_reportfrom sklearn import preprocessingfrom sklearn import linear_model# 数据是否需要标准化scale = False# 载入数据data = np.genfromtxt(&quot;LR-testSet.csv&quot;, delimiter=&quot;,&quot;)x_data = data[:,:-1]y_data = data[:,-1] def plot(): x0 = [] x1 = [] y0 = [] y1 = [] # 切分不同类别的数据 for i in range(len(x_data)): if y_data[i]==0: x0.append(x_data[i,0]) y0.append(x_data[i,1]) else: x1.append(x_data[i,0]) y1.append(x_data[i,1]) # 画图 scatter0 = plt.scatter(x0, y0, c=&#x27;c&#x27;, marker=&#x27;+&#x27;) scatter1 = plt.scatter(x1, y1, c=&#x27;y&#x27;, marker=&#x27;*&#x27;) #画图例 plt.legend(handles=[scatter0,scatter1],labels=[&#x27;label0&#x27;,&#x27;label1&#x27;],loc=&#x27;best&#x27;) plot()plt.show()# 创建并拟合模型logistic = linear_model.LogisticRegression()logistic.fit(x_data, y_data)if scale == False: # 画图决策边界 plot() x_test = np.array([[-4],[3]]) y_test = (-logistic.intercept_ - x_test*logistic.coef_[0][0])/logistic.coef_[0][1] plt.plot(x_test, y_test, &#x27;k&#x27;) plt.show() # 测试与评估 predictions = logistic.predict(x_data)print(classification_report(y_data, predictions)) 非线性逻辑回归示例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243import numpy as npimport matplotlib.pyplot as pltfrom sklearn import linear_modelfrom sklearn.datasets import make_gaussian_quantilesfrom sklearn.preprocessing import PolynomialFeatures# 生成2维正态分布，生成的数据按分位数分为两类，500个样本,2个样本特征# 可以生成两类或多类数据x_data, y_data = make_gaussian_quantiles(n_samples=500, n_features=2,n_classes=2)plt.scatter(x_data[:, 0], x_data[:, 1], c=y_data)plt.show()# 创建并拟合模型logistic = linear_model.LogisticRegression()logistic.fit(x_data, y_data)# 定义多项式回归,degree的值可以调节多项式的特征poly_reg = PolynomialFeatures(degree=5) # 特征处理x_poly = poly_reg.fit_transform(x_data)# 定义逻辑回归模型logistic = linear_model.LogisticRegression()# 训练模型logistic.fit(x_poly, y_data)# 获取数据值所在的范围x_min, x_max = x_data[:, 0].min() - 1, x_data[:, 0].max() + 1y_min, y_max = x_data[:, 1].min() - 1, x_data[:, 1].max() + 1# 生成网格矩阵xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))z = logistic.predict(poly_reg.fit_transform(np.c_[xx.ravel(), yy.ravel()]))# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据z = z.reshape(xx.shape)# 等高线图cs = plt.contourf(xx, yy, z)# 样本散点图plt.scatter(x_data[:, 0], x_data[:, 1], c=y_data)plt.show()print(&#x27;score:&#x27;,logistic.score(x_poly,y_data)) 参考 逻辑回归","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://liujk6525.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://liujk6525.github.io/tags/Python/"},{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"线性回归及非线性回归","slug":"线性回归及非线性回归","date":"2023-06-05T01:37:27.000Z","updated":"2023-06-06T12:24:32.188Z","comments":true,"path":"机器学习/线性回归及非线性回归/","link":"","permalink":"https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%8F%8A%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","excerpt":"基本概念： 将数据划分为三部分：\\(\\begin{cases} 训练集(Train):用来训练，构建模型\\\\ 验证集(Validate):在模型训练阶段，测试模型的好坏\\\\ 测试集(Test):等模型训练好后，评估模型的好坏 \\end{cases}\\)","text":"基本概念： 将数据划分为三部分：\\(\\begin{cases} 训练集(Train):用来训练，构建模型\\\\ 验证集(Validate):在模型训练阶段，测试模型的好坏\\\\ 测试集(Test):等模型训练好后，评估模型的好坏 \\end{cases}\\) 学习方式：\\(\\begin{cases} 监督学习\\\\ 无监督学习\\\\ 半监督学习 \\end{cases}\\) 常见应用：\\(\\begin{cases} 回归：预测数据为连续型数值。\\\\ 分类：预测数据为类别型数据，并且类别已知。\\\\ 聚类：预测数据为类别型数据，但是类别未知。 \\end{cases}\\) 回归分析（Regression） 回归分析用来建立方程，模拟两个或者多个变量之间如何关联， 被预测的变量叫做：因变量/输出 被用来进行预测的变量叫做： 自变量,/输入 一元线性回归包含一个自变量和一个因变量，两个变量的关系用一条直线来模拟，如果包含两个以上的自变量，则称作多元回归分析（multiple regression） 一元线性回归 一元线性回归：\\(h_\\theta(x)=\\theta_0+\\theta_1x\\) 代价函数（Cost Function） 最小二乘法 假设真实值为\\(y\\)，预测值\\(h_\\theta(x)\\) ，则误差平方为\\((h_\\theta(x)-y)^2\\) 找到合适的参数，使得误差平方和\\(J(\\theta_0,\\theta_1)\\)最小。 \\[ J(\\theta_0,\\theta_1)=\\frac{1}{2m}\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})^{2}} \\] 梯度下降法（Gradient Descent） 最小化目标函数 \\(\\underset{\\theta_0,\\theta_1}{min}\\quad J(\\theta_0,\\theta_1)\\) 初始化参数\\(\\theta_0,\\theta_1\\) 不断改变\\(\\theta_0,\\theta_1\\) ，直到\\(J(\\theta_0,\\theta_1)\\)到达一个全局最小值，或局部极小值。 \\[ \\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta_0,\\theta_1)\\quad (j=0,1,2\\cdots) \\] 用梯度下降法求解线性回归 \\[ \\frac{\\partial}{\\partial\\theta_0}J(\\theta_0,\\theta_1)= \\frac{1}{m}\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})} \\\\ \\] \\[ \\frac{\\partial}{\\partial\\theta_1}J(\\theta_0,\\theta_1)= \\frac{1}{m}\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}\\times x^{(i)} \\] 不断迭代，直到收敛： \\[ \\theta_0:=\\theta_0-\\alpha\\frac{1}{m}{\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}} \\] \\[ \\theta_1:=\\theta_1-\\alpha\\frac{1}{m}{\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}}\\times x^{(i)} \\] 示例代码： 1234567891011121314151617181920212223242526from sklearn.linear_model import LinearRegression # 线性回归模型import numpy as npimport matplotlib.pyplot as plt# 载入数据data = np.genfromtxt(&quot;data.csv&quot;, delimiter=&quot;,&quot;)x_data = data[:,0]y_data = data[:,1]plt.scatter(x_data,y_data)plt.show()x_data = data[:,0,np.newaxis]y_data = data[:,1,np.newaxis]# 创建并拟合模型model = LinearRegression() # 线性回归model.fit(x_data, y_data)# 测试x_test = [[44.5]]predict = model.predict(x_test)print(&#x27;predict&#x27;,predict)# 画图plt.plot(x_data, y_data, &#x27;b.&#x27;)plt.plot(x_data, model.predict(x_data), &#x27;r&#x27;)plt.show() 多元线性回归（Multiple Linear Regression） 多特征时，假设：\\(h_\\theta(x)=\\theta_0+\\theta_1x_1+\\theta_2x_2+\\cdots+\\theta_nx_n\\) 当真实值\\(y\\)的影响因素不是唯一时，需采用多元线性回归模型。 代价函数： \\[ J(\\theta_0,\\theta_1,\\cdots,\\theta_n)=\\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^{2} \\] 梯度下降法： \\[ \\theta_j:=\\theta_j-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}\\times x_j^{(i)}\\quad (j=0,1,2\\cdots,n) \\] 注意这里的\\(j=0\\)时，\\(x_0=1\\) 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041import numpy as npfrom numpy import genfromtxtfrom sklearn import linear_model # 线性回归模型import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D # 读入数据 data = genfromtxt(r&quot;Delivery.csv&quot;,delimiter=&#x27;,&#x27;)print(data)# 切分数据x_data = data[:,:-1]y_data = data[:,-1]print(x_data)print(y_data)# 创建模型model = linear_model.LinearRegression()model.fit(x_data, y_data)# 测试x_test = [[102,4]]predict = model.predict(x_test)print(&quot;predict:&quot;,predict)ax = plt.figure().add_subplot(111, projection = &#x27;3d&#x27;) ax.scatter(x_data[:,0], x_data[:,1], y_data, c = &#x27;r&#x27;, marker = &#x27;o&#x27;, s = 100) #点为红色三角形 x0 = x_data[:,0]x1 = x_data[:,1]# 生成网格矩阵x0, x1 = np.meshgrid(x0, x1)z = model.intercept_ + x0*model.coef_[0] + x1*model.coef_[1]# 画3D图ax.plot_surface(x0, x1, z)#设置坐标轴 ax.set_xlabel(&#x27;Miles&#x27;) ax.set_ylabel(&#x27;Num of Deliveries&#x27;) ax.set_zlabel(&#x27;Time&#x27;) #显示图像 plt.show() 多项式回归 假如我们不是要找直线（或者超平面），而是需要找到一 个用多项式所表示的曲线（或者超曲面） 多项式回归：\\(h_\\theta(x)=\\theta_0+\\theta_1x+\\theta_2x^2+\\cdots+\\theta_nx^n\\) 示例代码： 12345678910111213141516171819202122232425262728293031323334import numpy as npimport matplotlib.pyplot as pltfrom sklearn.preprocessing import PolynomialFeatures from sklearn.linear_model import LinearRegression# 载入数据data = np.genfromtxt(&quot;job.csv&quot;, delimiter=&quot;,&quot;)x_data = data[1:,1]y_data = data[1:,2]plt.scatter(x_data,y_data)plt.show()x_data = x_data[:,np.newaxis]y_data = y_data[:,np.newaxis]# 定义多项式回归,degree的值可以调节多项式的特征poly_reg = PolynomialFeatures(degree=5) # 特征处理x_poly = poly_reg.fit_transform(x_data)# 定义回归模型lin_reg = LinearRegression()# 训练模型lin_reg.fit(x_poly, y_data)# 画图# 画图plt.plot(x_data, y_data, &#x27;b.&#x27;)x_test = np.linspace(1,10,100)x_test = x_test[:,np.newaxis]plt.plot(x_test, lin_reg.predict(poly_reg.fit_transform(x_test)), c=&#x27;r&#x27;)plt.title(&#x27;Truth or Bluff (Polynomial Regression)&#x27;)plt.xlabel(&#x27;Position level&#x27;)plt.ylabel(&#x27;Salary&#x27;)plt.show() 标准方程法（Normal Equation） 注意这里的符号：\\(w\\)其实就是上面公式里的\\(\\theta\\)，就是要求解的那个参数。 假设： \\[ h_w(x)=w_0+w_1x_1+w_2x_2+\\cdots+w_nx_n \\] \\[ h_w(x)=xw\\ \\] 目标函数: \\[ J(w_0,w_1,\\cdots,w_n)=\\frac{1}{2m}\\sum_{i=1}^{m}(h_w(x^{(i)})-y^{(i)})^{2} \\] 又因为 \\[ \\sum_{i=1}^{m}(h_w(x^{(i)})-y^{(i)})^{2}=(y-Xw)^T(y-Xw) \\] 所以 \\[ \\frac{\\partial J(w)}{\\partial w}=\\frac{\\partial(y-Xw)^T(y-Xw)}{\\partial w} \\] \\[ =\\frac{\\partial(y^Ty-y^TXw-w^TX^Ty+w^TX^TXw)}{\\partial w} \\] \\[ =\\frac{\\partial(y^Ty)}{\\partial w}-\\frac{\\partial(y^TXw)}{\\partial w}-\\frac{\\partial(w^TX^Ty)}{\\partial w}+\\frac{\\partial(w^TX^TXw)}{\\partial w} \\] \\[ =0-X^Ty-X^Ty+2X^TXw \\] 令 \\[ \\frac{\\partial J(w)}{\\partial w}=0 \\] 求解： \\[ -2X^Ty+2X^TXw=0 \\] \\[ X^TXw=X^Ty \\] \\[ w=(X^TX)^{-1}X^Ty \\] 特征缩放 数据归一化 数据归一化就是把数据的取值范围处理为\\(0-1\\)，或者\\(-1-1\\)之间。 任意数据转化为0-1之间： \\[ NewValue = \\frac{OldValue-min}{max-min} \\] 任意数据转化为-1-1之间： \\[ NewValue=2\\times(\\frac{OldVaule-min}{max-min}-0.5) \\] 均值标准化 \\(x\\)为特征数据，\\(u\\)为数据的平均值，\\(s\\)为数据的方差。 \\[ NewValue=\\frac{OldValue-u}{s} \\] 过拟合（Overfitting） 回归问题拟合有以下三种情况： 分类问题有以下三种情况： 防止过拟合：减少特征；增加数据量；正则化（Regularized） 正则化 L2正则化： \\[ J(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{\\theta_j^2}}] \\] L1正则化： \\[ J(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{|\\theta_j|}}] \\] 岭回归（Ridge Regression） 由标准方程法得出， \\[ w = (𝑋^𝑇𝑋)^{-1}𝑋^𝑇y \\] 如果数据的特征比样本点还多，（数据特征\\(n\\)，样本个数\\(m\\)），如果\\(n&gt;m\\)，\\(𝑋^𝑇𝑋\\)不是满秩矩阵，不可逆，计算\\(𝑋^𝑇𝑋^{-1}\\)时会出错。 为了解决这个问题，引入了岭回归的概念。\\(\\lambda\\)为岭系数，\\(I\\)为单位矩阵。 \\[ w = (𝑋^𝑇𝑋 + \\lambda I)^{-1}𝑋^𝑇y \\] 推导： \\[ J(\\theta)=\\frac{1}{2}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{\\theta_j^2}}] \\] \\[ =\\frac{1}{2}(Xw-y)^T(Xw-y)+\\lambda w^Tw \\] \\[ =\\frac{1}{2}(w^TX^TXw-w^TX^Ty-y^TXw+y^Ty)+\\lambda w^Tw \\] \\[ \\frac{\\partial J(w)}{\\partial w}=X^TXw-X^Ty+\\lambda w \\] 令 \\[ \\frac{\\partial J(w)}{\\partial w}=0 \\] \\[ w = (𝑋^𝑇𝑋 + \\lambda I)^{-1}𝑋^𝑇y \\] 示例代码： 123456789101112131415161718192021222324252627282930313233import numpy as npfrom numpy import genfromtxtfrom sklearn import linear_modelimport matplotlib.pyplot as plt# 读入数据 data = genfromtxt(r&quot;longley.csv&quot;,delimiter=&#x27;,&#x27;)print(data)# 切分数据x_data = data[1:,2:]y_data = data[1:,1]print(x_data)print(y_data)# 创建模型# 生成50个值alphas_to_test = np.linspace(0.001, 1)# 创建模型，保存误差值model = linear_model.RidgeCV(alphas=alphas_to_test, store_cv_values=True)model.fit(x_data, y_data)# 画图# 岭系数跟loss值的关系plt.plot(alphas_to_test, model.cv_values_.mean(axis=0))# 选取的岭系数值的位置plt.plot(model.alpha_, min(model.cv_values_.mean(axis=0)),&#x27;ro&#x27;)plt.xlabel(&#x27;alphas&#x27;)plt.ylabel(&#x27;loss&#x27;)plt.show()# 测试model.predict(x_data[2,np.newaxis]) [LASSO（Least Absolute Shrinkage and Selectionator operator）](https://baike.baidu.com/item/Lasso%E7%AE%97%E6%B3%95/22685468?fromtitle=LASSO&amp;fromid=20366865&amp;fr=aladdin) LASSO的代价函数： \\[ J(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{|\\theta_j|}}] \\] 示例代码： 12345678910111213141516171819202122232425import numpy as npfrom numpy import genfromtxtfrom sklearn import linear_model# 读入数据 data = genfromtxt(r&quot;longley.csv&quot;,delimiter=&#x27;,&#x27;)print(data)# 切分数据x_data = data[1:,2:]y_data = data[1:,1]print(x_data)print(y_data)# 创建并拟合模型model = linear_model.LassoCV()model.fit(x_data, y_data)# lasso系数print(model.alpha_)# 相关系数print(model.coef_)# 预测model.predict(x_data[-2,np.newaxis]) 弹性网（Elastic Net） 在\\(q\\)取不同值情况下的代价函数 \\[ J(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{|\\theta_j|^q}}] \\] Elastic Net的代价函数： \\[ J(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{\\alpha\\theta_j^2+(1-\\alpha)|\\theta_j|}}] \\] 示例代码： 12345678910111213141516171819202122232425import numpy as npfrom numpy import genfromtxtfrom sklearn import linear_model# 读入数据 data = genfromtxt(r&quot;longley.csv&quot;,delimiter=&#x27;,&#x27;)print(data)# 切分数据x_data = data[1:,2:]y_data = data[1:,1]print(x_data)print(y_data)# 创建并拟合模型model = linear_model.ElasticNetCV()model.fit(x_data, y_data)# 弹性网系数print(model.alpha_)# 相关系数print(model.coef_)# 预测model.predict(x_data[-2,np.newaxis]) 参考 线性回归及其非线性回归","categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://liujk6525.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://liujk6525.github.io/tags/Python/"},{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"跑通ssd.pytorch","slug":"跑通ssd-pytorch","date":"2023-05-31T02:16:02.000Z","updated":"2023-06-05T01:41:34.424Z","comments":true,"path":"目标检测/跑通ssd-pytorch/","link":"","permalink":"https://liujk6525.github.io/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E8%B7%91%E9%80%9Assd-pytorch/","excerpt":"补： Expected a ‘cuda‘ device type for generator but found ‘cpu‘ 后来我在服务器训练的时候，发现出bug了。原来是Pytorch版本的原因，我在faster-rcnn-pytorch这个项目跑的，里面有现成的VOC数据集。但是这个环境Pytorch是1.9。 修改/root/miniconda3/lib/python3.7/site-packages/torch/utils/data/sampler.py中代码，修改结果如下。 123generator = torch.Generator(device=&#x27;cuda&#x27;)yield from torch.randperm(n, generator=generator, device=&#x27;cuda&#x27;).tolist()","text":"补： Expected a ‘cuda‘ device type for generator but found ‘cpu‘ 后来我在服务器训练的时候，发现出bug了。原来是Pytorch版本的原因，我在faster-rcnn-pytorch这个项目跑的，里面有现成的VOC数据集。但是这个环境Pytorch是1.9。 修改/root/miniconda3/lib/python3.7/site-packages/torch/utils/data/sampler.py中代码，修改结果如下。 123generator = torch.Generator(device=&#x27;cuda&#x27;)yield from torch.randperm(n, generator=generator, device=&#x27;cuda&#x27;).tolist() 修改train.py中代码，修改结果如下。 1234data_loader = data.DataLoader(dataset, args.batch_size, num_workers=args.num_workers, shuffle=True, collate_fn=detection_collate, pin_memory=True, generator=torch.Generator(device=&#x27;cuda&#x27;)) [W pthreadpool-cpp.cc:90] Warning:Leaking Caffe2 thread-pool after fork.(function pthreadpool) 线程撕裂，出现了警告，警告数量为设置的线程数量，如果把线程数改小一些，就不会有警告了，但是会影响运行速度。修改train.py中的代码，修改结果如下。 1234data_loader = data.DataLoader(dataset, args.batch_size, num_workers=args.num_workers, shuffle=True, collate_fn=detection_collate, pin_memory=False,generator=torch.Generator(device=&#x27;cuda&#x27;)) 然后我想在服务器上用visdom看训练结果图，bug出现了。 NameError: name ‘viz’ is not defined 修改train.py中的代码，修改结果如下。 123import visdomglobal vizviz = visdom.Visdom() AssertionError: Must define a window to update 修改train.py中的代码，修改结果如下。 123if args.visdom and iteration != 0 and (iteration % epoch_size == 0): epoch += 1 update_vis_plot(epoch, loc_loss, conf_loss, epoch_plot, None, Legacy autograd function with non-static forward method is deprecated 原因是当前版本要求forward过程是静态的，所以需要将原代码进行修改。 从Single-Shot-Object-Detection-Updated下载detect.py文件，并将其替换掉原来的layers/functions/detection.py 修改ssd.py中的代码，修改结果如下。 123if phase == &#x27;test&#x27;: self.softmax = nn.Softmax(dim=-1) self.detect = Detect() 123456if self.phase == &quot;test&quot;: output = self.detect.apply(self.num_classes, 0, 200, 0.01, 0.45, loc.view(loc.size(0), -1, 4), # loc preds self.softmax(conf.view(-1, self.num_classes)), # conf preds self.priors.type(type(x.data)) # default boxes ) [Errno 2] No such file or directory: ‘test.txt’ 修改eval.py中的代码，修改结果如下。 1imgsetpath = os.path.join(args.voc_root, &#x27;VOC2007&#x27;, &#x27;ImageSets&#x27;, &#x27;Main&#x27;, &#x27;&#123;&#125;.txt&#x27;) 做实验对比，所以需要跑通ssd，这里部署的pytroch版本，大佬项目ssd.pytorch，中间踩了不少坑，记录如下 目标：ssd.pytorch 环境：cuda 11.3 | pytorch 1.8.1 修改xml文件的绝对路径 这是在之前的电脑打的标签，所以VOC数据集里面的标注文件.xml里面的&lt;path&gt;值还是老路径， 这里我更改成新的路径。 IndexError:invalid index of a 0-dim tensor… 修改train.py中代码，.data[0]写法不适用高版本的Pytorch，修改结果如下。 123456loc_loss += loss_l.item()conf_loss += loss_c.item()if iteration % 10 == 0: print(&#x27;timer: %.4f sec.&#x27; % (t1 - t0)) print(&#x27;iter &#x27; + repr(iteration) + &#x27; || Loss: %.4f ||&#x27; % (loss.item()), end=&#x27; &#x27;) StopInteration… 修改train.py中代码，修改结果如下。 12345try: images, targets = next(batch_iterator)except StopIteration: batch_iterator = iter(data_loader) images, targets = next(batch_iterator) IndexError: The shape of the mask [14, 8732] at index 0does… 交换layers/modules/multibox_loss.py中代码位置，修改结果如下。 12loss_c = loss_c.view(num, -1)loss_c[pos] = 0 # filter out pos boxes for now loss：NAN 如果lr设置过高，可能会导致训练过程中loss出现NAN的情况。它默认的参数是1e-3，我这里将学习率修改为1e-4。 1parser.add_argument(&#x27;--lr&#x27;, &#x27;--learning-rate&#x27;, default=1e-4, type=float, 警告 UserWarning: size_average and reduce args will be deprecated, please use reduction=‘sum’ instead. warnings.warn(warning.format(ret)) 在高版本的Pytorch中，size_average和reduce这两个参数都将不再支持，修改multibox_loss.py中代码，修改结果如下。 1234loss_l = F.smooth_l1_loss(loc_p, loc_t, reduction=&#x27;sum&#x27;)loss_c = F.cross_entropy(conf_p, targets_weighted, reduction=&#x27;sum&#x27;) UserWarning: volatile was removed and now has no effect. Use ‘with torch.no_grad():’ instead. 版本问题，修改ssd.py中代码，修改结果如下。 12with torch.no_grad(): self.priors = Variable(self.priorbox.forward()) UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_ .init.xavier_uniform(param) nn.init.xavier_uniform是以前的版本使用的，在高版本的Pytorch中已经被弃用。修改train.py中代码，修改结果如下。 12def xavier(param): init.xavier_uniform_(param) 可以发现很多警告就是版本不匹配的问题，但我是抱着只要能运行的心态，然而UserWarning又很影响观感，那就直接屏蔽它！ 123import warningswarnings.filterwarnings(&#x27;ignore&#x27;) 或者命令行执行xx.py脚本文件 1python -W ignore xx.py 运行train.py文件 1python -W ignore train.py 参考 amdegroot/ssd.pytorch/issues/421 SSD训练自己的数据集（pytorch版） Pytorch搭建SSD模型踩坑集锦 SSD训练数据集流程（学习记录）","categories":[{"name":"目标检测","slug":"目标检测","permalink":"https://liujk6525.github.io/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://liujk6525.github.io/tags/Python/"},{"name":"ssd.pytorch","slug":"ssd-pytorch","permalink":"https://liujk6525.github.io/tags/ssd-pytorch/"}]},{"title":"torch1.9-跑通ssd.pytorch","slug":"torch1-9-跑通ssd-pytorch","date":"2023-05-31T02:14:58.000Z","updated":"2023-05-31T03:40:45.344Z","comments":true,"path":"uncategorized/torch1-9-跑通ssd-pytorch/","link":"","permalink":"https://liujk6525.github.io/uncategorized/torch1-9-%E8%B7%91%E9%80%9Assd-pytorch/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"JupyterLab安装与配置","slug":"JupyterLab安装与配置","date":"2023-05-29T06:08:59.000Z","updated":"2023-06-05T01:42:11.748Z","comments":true,"path":"踩坑记录/JupyterLab安装与配置/","link":"","permalink":"https://liujk6525.github.io/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/JupyterLab%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/","excerpt":"Jupyter Lab是一个交互式笔记本，支持运行40多种编程语言。它本质上是一个web应用程序，可以很方便的创建和共享程序文档，支持实时代码，数学方程，可视化和markdown JupyterLab安装和初始配置记录如下：","text":"Jupyter Lab是一个交互式笔记本，支持运行40多种编程语言。它本质上是一个web应用程序，可以很方便的创建和共享程序文档，支持实时代码，数学方程，可视化和markdown JupyterLab安装和初始配置记录如下： 安装JupyterLab 1pip install jupyterlab 下载中文包 1pip install jupyterlab-language-pack-zh-CN 启动Jupyter Lab服务 1jupyter lab 设置中文界面 修改默认打开的工作目录 先执行以下指令生成 JupyteraLab 的配置文件jupyter_lab_config.py 1jupyter lab --generate-config 修改C:\\\\User\\liugn\\.jupyter_lab_congfig.py配置文件 我这里是把工作文件设置在了E:\\Pycharm Projects 切换虚拟环境 jupyter lab是安装在base环境下的，很多时候要用到其他虚拟环境的特定包。 给已创建好的虚拟环境添加ipykernel 1conda install -n yolov5 ipykernel 激活虚拟环境 1conda activate yolv5 将虚拟环境写入Jupyter的kernel中 1python -m ipykernel install --name yolov5 --display-name yolov5 第一个虚拟环境名称：创建的虚拟环境名称 第二个虚拟环境名称：其在jupyter noteboook的kernel选项中显示的名称","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://liujk6525.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"JupyterLab","slug":"JupyterLab","permalink":"https://liujk6525.github.io/tags/JupyterLab/"}]},{"title":"Jetson Nano部署Yolo-v5","slug":"Jetson-Nano部署Yolo-v5","date":"2023-05-29T05:57:24.000Z","updated":"2023-05-29T09:17:23.871Z","comments":true,"path":"踩坑记录/Jetson-Nano部署Yolo-v5/","link":"","permalink":"https://liujk6525.github.io/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/Jetson-Nano%E9%83%A8%E7%BD%B2Yolo-v5/","excerpt":"手上有一块国产版的Jetson Nano（懂得都懂），部署Yolo-v5；记录以下","text":"手上有一块国产版的Jetson Nano（懂得都懂），部署Yolo-v5；记录以下 安装Jtop Jetson Nano 没有 nvidia-smi 命令，所以用jtop来替代。 1pip install jetson-stats 执行命令； 1jtop 安装JupyterLab 先安装以下nodejs， 1sudo apt install nodejs 安装jupyterlab， 1pip install jupyterlab 设置密码， 1jupyter-lab password 修改配置文件， 123456789101112# 允许远程连接c.ServerApp.allow_remote_access = True# 允许远程连接者使用root权限c.ServerApp.allow_root = True# 服务器监听所有本机IPc.ServerApp.ip = &#x27;0.0.0.0&#x27;# 启动server不打开浏览器c.ServerApp.open_browser = False# 设置通信端口c.ServerApp.port = 8080# c.ServerApp.password 没必要设置，因为上面设置密码步骤时已经生成了密码文件# c.ServerApp.root_dir 没必要设置jupyter运行所在的文件夹 远程开启JupyterLab，首次登录需要密码。 12# nano局域网IP 192.168.55.0192.168.55.0:8080/lab JupyterLab开机自启 创建JupyterLab运行脚本autoJupyterLab.sh，我这里把该脚本文件放在/home/nvidia里面了。 123#!/bin/sh/home/nVidia/.local/bin/jupyter-lab 在/etc/systemd/system文件夹下创建auto-jupyter.service服务： 12345678910111213[Unit]Description=Auto Load JupyterLabAfter=network.target[Service]Type=simpleUser=your_usernameExecStart=/home/nvidia/autoJupyterLab.shRestart=on-failureRestartSec=15s[Install]WantedBy=default.target 设置Jupyter Service自启动 让systemd重新加载service文件 1sudo systemctl daemon-reload 然后设置auto-jupyter.service开机自启： 1sudo systemctl enable auto-jupyter.service 重启 1sudo reboot 关闭图形界面 1sudo systemctl set-default multi-user.target 1sudo reboot 开启图形界面 1sudo systemctl set-default graphical.target 1sudo reboot 命令行连接WiFi 扫描WiFi信号 1nmcli dev wifi 连接WiFi 1sudo nmcli dev wifi connect wifi_name password ******** 查看连接WiFi后的IP地址 1ifconfig","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://liujk6525.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Jetson Nano","slug":"Jetson-Nano","permalink":"https://liujk6525.github.io/tags/Jetson-Nano/"},{"name":"Yolo-v5","slug":"Yolo-v5","permalink":"https://liujk6525.github.io/tags/Yolo-v5/"}]},{"title":"wii11系统跑通Yolo-v5","slug":"跑通Yolo-v5","date":"2023-05-27T02:06:35.000Z","updated":"2023-06-05T01:41:48.244Z","comments":true,"path":"目标检测/跑通Yolo-v5/","link":"","permalink":"https://liujk6525.github.io/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E8%B7%91%E9%80%9AYolo-v5/","excerpt":"之前跑Yolo-v5是在服务器跑的，现在把权重文件跑完了，正好最近换了新电脑，在本地部署跑跑看，记录如下： 复现大佬们的项目之前一定要看这个项目所需的配置环境，掉大坑！！！ 目标：Yolo-v5 v6.1版本 环境：cuda 11.3 | pytorch 1.8.1","text":"之前跑Yolo-v5是在服务器跑的，现在把权重文件跑完了，正好最近换了新电脑，在本地部署跑跑看，记录如下： 复现大佬们的项目之前一定要看这个项目所需的配置环境，掉大坑！！！ 目标：Yolo-v5 v6.1版本 环境：cuda 11.3 | pytorch 1.8.1 安装Anaconda3 anaconda官网 直接点击Download下载安装包，双击安装 我把Anaconda安装在D盘了 安装CUDA 安装之前先看下自己电脑配置条件，在终端输入 1nvidia-smi 可以看到Driver Version: 512.98 在对照nvidia官网显卡驱动给出的版本要求选择CUDA版本，这里我选择的是CUDA 11.3 然后来到CUDA Toolkit Archive， 点击CUDA Toolkit 11.3.1即可跳转到CUDA Toolkit 11.3 Update 1 Downloads 直接点击Download(2.7GB)下载安装包，双击安装 这里选择自定义(c)(高级) 选择驱动程序组件时，视情况而定；我这里取消勾选Driver components和Other components，因为当前版本已经安装了。 点击下一步，等待安装完成。 配置cuDNN 进入Nvidia官网cuDNN Archive，选择for CUDA 11.X的。 我这里选择的是v8.8.0版本的，点击Local Install for Windows(Zip)下载 解压后里面有三个文件\\(bin|include|lib\\) 将其复制到CUDA安装目录就好了，我这里把CUDA安装在D盘了。 安装pytorch 打开Anaconda Prompt，输入如下命令，创建一个虚拟环境，我这里命名为yolov5； 1conda create -n yolov5 python=3.8 所用到的各种包都是在yolov5这个虚拟环境下配置的，所以需要激活yolov5环境 1conda activate yolov5 进入Pytorch官网Installing Previous Versions Of Pytorch conda install 安装 我这里是安装的CUDA 11.3，输入以下指令 1conda install pytorch==1.8.1 torchvision==0.9.1 torchaudio==0.8.1 cudatoolkit=11.3 -c pytorch -c conda-forge -c pytorch 表示在pytorch的官网下载；-c conda-forge 表示在conda官网下载 但是pytorch官网只有cpu版本的，conda索性找不到了。好在CUDA是向下兼容的，最后选择用pip install的方式下载了。 pip install 安装 最后选择的CUDA 11.1，输入以下指令； 1pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html 到这里pytorch环境就配置好了！ 下载Yolo-v5源代码 Yolo-v5更新的很快，但我当时用服务器跑的时候下载的v6.1版本，所以用git bash下载文件。 我是在Pycharm Projects里面创建一个文件夹Yolov5，然后右击选择Git Bash Here ifconfigbash 1git clone -b v6.1 https://github.com/ultralytics/yolov5.git 这样就把源代码下载完成了，我这里把它重命名了yolov5-6.1， 接下来从requirements.txt安装所需要的包。打开Anaconda Prompt，cd到yolov5-6.1文件夹 我这里是E:\\Pycharm Projects\\Yolov5\\yolov5-6.1 1pip install -r requirements.txt 到这里就全部部署完成好了，接下来就是把自己的权重文件替换成yolov5的预训练权重文件yolov5.pt。 执行detect.py，测试了一下。 还是能较好的把可采摘的苹果和被遮挡的苹果识别出来。","categories":[{"name":"目标检测","slug":"目标检测","permalink":"https://liujk6525.github.io/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://liujk6525.github.io/tags/Python/"},{"name":"Yolov5","slug":"Yolov5","permalink":"https://liujk6525.github.io/tags/Yolov5/"}]},{"title":"git clone连接不上","slug":"git-clone连接不上","date":"2023-05-26T11:10:59.000Z","updated":"2023-06-05T01:42:05.235Z","comments":true,"path":"踩坑记录/git-clone连接不上/","link":"","permalink":"https://liujk6525.github.io/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/git-clone%E8%BF%9E%E6%8E%A5%E4%B8%8D%E4%B8%8A/","excerpt":"当我用git clone下载代码时，发现老是连接不上, 1fatal: unable to access &#x27;https://github.com/.../.git&#x27;: Could not resolve host: github.com 解决办法： 对Git的配置文件.gitconfig设置代理服务器，我的端口是7890","text":"当我用git clone下载代码时，发现老是连接不上, 1fatal: unable to access &#x27;https://github.com/.../.git&#x27;: Could not resolve host: github.com 解决办法： 对Git的配置文件.gitconfig设置代理服务器，我的端口是7890 12git config --global http.proxy http:192.0.0.1:7890git config --global https.proxy http:192.0.0.1:7890 取消代理在终端输入以下代码 12git config --global --unset http.proxy git config --global --unset https.proxy 顺便说一嘴，./gitconfig配置文件在C:\\Users\\Liugn文件夹里面。 发现自己对英文界面的git bash用的不习惯，所以单机右键，点击Options 点击Window，它会切换到对应的界面，点击UI language下拉框选择zh_CN 最后点击Apply就好了。 外观什么的都可以在选项/options中设置，这按个人喜好去配了。 参考 Recv failure: Connection was reset","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://liujk6525.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://liujk6525.github.io/tags/Git/"}]},{"title":"Anaconda--配置文件修改","slug":"Anaconda-配置文件修改","date":"2023-05-26T05:44:08.000Z","updated":"2023-05-26T05:47:02.884Z","comments":true,"path":"踩坑记录/Anaconda-配置文件修改/","link":"","permalink":"https://liujk6525.github.io/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/Anaconda-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BF%AE%E6%94%B9/","excerpt":"将envs_dirs设置为自己anaconda安装的目录上（我的是在D:），不然他默认安装到.！！！ 因为我的anaconda安装在D盘，如果各位看官有充足的内存够安装在C盘，就当笑笑看啦~","text":"将envs_dirs设置为自己anaconda安装的目录上（我的是在D:），不然他默认安装到.！！！ 因为我的anaconda安装在D盘，如果各位看官有充足的内存够安装在C盘，就当笑笑看啦~ 首先第一步！ 修改 D：Anaconda3文件夹的权限，选中后右击选择属性，然后点击安全，选择User后点击编辑，将下面的权限全打勾， 稍微等待一会时间。 二选一 修改./condarc（推荐，手残党） 直接将.，将下面的内容粘入， 1234envs_dirs: - D:\\Anaconda3\\envspkgs_dirs: - D:\\Anaconda3\\pkgs 保存并关闭文件。 打开一个终端，执行指令可查看conda配置信息。 1conda config --show 修改指令 打开一个终端，执行添加指令， 12conda config --add envs_dirs D:\\Anaconda3\\envsconda config --add pkgs_dir D:\\Anaconda3\\pkgs 同样的，执行指令查看配置信息。 1conda config --show","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://liujk6525.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Anaconda","slug":"Anaconda","permalink":"https://liujk6525.github.io/tags/Anaconda/"}]},{"title":"机器人工具箱学习","slug":"机器人工具箱学习","date":"2023-05-23T01:56:52.000Z","updated":"2023-05-26T05:22:33.653Z","comments":true,"path":"uncategorized/机器人工具箱学习/","link":"","permalink":"https://liujk6525.github.io/uncategorized/%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%B7%A5%E5%85%B7%E7%AE%B1%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"人脸识别案例","slug":"人脸识别案例","date":"2023-05-20T06:16:48.000Z","updated":"2023-05-26T05:22:33.648Z","comments":true,"path":"OpenCV/人脸识别案例/","link":"","permalink":"https://liujk6525.github.io/OpenCV/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A1%88%E4%BE%8B/","excerpt":"基础 使用机器学习的方法完成人脸检测，首先需要大量的正样本图像（面部图像）和负样本图像（不含面部的图像）来训练分类器。我们需要从其中提取特征。下图中的 Haar 特征会被使用，就像我们的卷积核，每一个特征是一个值，这个值等于黑色矩形中的像素值之后减去白色矩形中的像素值之和。","text":"基础 使用机器学习的方法完成人脸检测，首先需要大量的正样本图像（面部图像）和负样本图像（不含面部的图像）来训练分类器。我们需要从其中提取特征。下图中的 Haar 特征会被使用，就像我们的卷积核，每一个特征是一个值，这个值等于黑色矩形中的像素值之后减去白色矩形中的像素值之和。 Haar特征值反映了图像的灰度变化情况。例如：脸部的一些特征能由矩形特征简单的描述，眼睛要比脸颊颜色要深，鼻梁两侧比鼻梁颜色要深，嘴巴比周围颜色要深等。 Haar特征可用于于图像任意位置，大小也可以任意改变，所以矩形特征值是矩形模版类别、矩形位置和矩形大小这三个因素的函数。故类别、大小和位置的变化，使得很小的检测窗口含有非常多的矩形特征。 得到图像的特征后，训练一个决策树构建的adaboost级联决策器来识别是否为人脸。 OpenCV中自带已训练好的检测器，包括面部，眼睛，猫脸等，都保存在XML文件中，利用这些文件来识别人脸，眼睛等。 读取图片，并转换成灰度图 实例化人脸和眼睛检测的分类器对象 1234# 实例化级联分类器classifier =cv.CascadeClassifier( &quot;haarcascade_frontalface_default.xml&quot; ) # 加载分类器classifier.load(&#x27;haarcascade_frontalface_default.xml&#x27;) 进行人脸和眼睛的检测 1rect = classifier.detectMultiScale(gray, scaleFactor, minNeighbors, minSize,maxsize) 参数： Gray: 要进行检测的人脸图像 scaleFactor: 前后两次扫描中，搜索窗口的比例系数 minneighbors：目标至少被检测到minNeighbors次才会被认为是目标 minsize和maxsize: 目标的最小尺寸和最大尺寸 将检测结果绘制出来就可以了。 示例代码： 123456789101112131415161718192021222324252627282930import cv2 as cvimport matplotlib.pyplot as plt# 1.以灰度图的形式读取图片img = cv.imread(&quot;16.jpg&quot;)gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)# 2.实例化OpenCV人脸和眼睛识别的分类器 face_cas = cv.CascadeClassifier( &quot;haarcascade_frontalface_default.xml&quot; ) face_cas.load(&#x27;haarcascade_frontalface_default.xml&#x27;)eyes_cas = cv.CascadeClassifier(&quot;haarcascade_eye.xml&quot;)eyes_cas.load(&quot;haarcascade_eye.xml&quot;)# 3.调用识别人脸 faceRects = face_cas.detectMultiScale( gray, scaleFactor=1.2, minNeighbors=3, minSize=(32, 32)) for faceRect in faceRects: x, y, w, h = faceRect # 框出人脸 cv.rectangle(img, (x, y), (x + h, y + w),(0,255,0), 3) # 4.在识别出的人脸中进行眼睛的检测 roi_color = img[y:y+h, x:x+w] roi_gray = gray[y:y+h, x:x+w] eyes = eyes_cas.detectMultiScale(roi_gray) for (ex,ey,ew,eh) in eyes: cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)# 5. 检测结果的绘制plt.figure(figsize=(8,6),dpi=100)plt.imshow(img[:,:,::-1]),plt.title(&#x27;检测结果&#x27;)plt.xticks([]), plt.yticks([])plt.show() 在视频中对人脸进行检测： 123456789101112131415161718192021222324import cv2 as cvimport matplotlib.pyplot as plt# 1.读取视频cap = cv.VideoCapture(&quot;movie.mp4&quot;)# 2.在每一帧数据中进行人脸识别while(cap.isOpened()): ret, frame = cap.read() if ret==True: gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) # 3.实例化OpenCV人脸识别的分类器 face_cas = cv.CascadeClassifier( &quot;haarcascade_frontalface_default.xml&quot; ) face_cas.load(&#x27;haarcascade_frontalface_default.xml&#x27;) # 4.调用识别人脸 faceRects = face_cas.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=3, minSize=(32, 32)) for faceRect in faceRects: x, y, w, h = faceRect # 框出人脸 cv.rectangle(frame, (x, y), (x + h, y + w),(0,255,0), 3) cv.imshow(&quot;frame&quot;,frame) if cv.waitKey(1) &amp; 0xFF == ord(&#x27;q&#x27;): break# 5. 释放资源cap.release() cv.destroyAllWindows()","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"https://liujk6525.github.io/categories/OpenCV/"}],"tags":[{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"视频追踪","slug":"视频追踪","date":"2023-05-20T05:31:48.000Z","updated":"2023-05-26T05:22:33.654Z","comments":true,"path":"OpenCV/视频追踪/","link":"","permalink":"https://liujk6525.github.io/OpenCV/%E8%A7%86%E9%A2%91%E8%BF%BD%E8%B8%AA/","excerpt":"视频读写 读取视频 创建读取视频的对象 1cap = cv.VideoCapture(filepath) 参数： filepath：视频文件路径","text":"视频读写 读取视频 创建读取视频的对象 1cap = cv.VideoCapture(filepath) 参数： filepath：视频文件路径 获取视频的某些属性 1retval = cap.get(propId) 参数： propId: 从0到18的数字，每个数字表示视频的属性 常用属性有： 修改视频的属性信息 1cap.set(propId，value) 参数： proid：属性的索引，与上面的表格相对应 value：修改后的属性值 判断图像是否读取成功 1isornot = cap.isOpened() 若读取成功则返回true，否则返回False 获取视频的一帧图像 1ret, frame = cap.read() 参数： ret：若获取成功返回True，获取失败，返回False frame：获取到的某一帧的图像 将视频释放掉 1cap.realease() 示例代码： 1234567891011121314151617import numpy as npimport cv2 as cv# 1.获取视频对象cap = cv.VideoCapture(&#x27;DOG.wmv&#x27;)# 2.判断是否读取成功while(cap.isOpened()): # 3.获取每一帧图像 ret, frame = cap.read() # 4. 获取成功显示图像 if ret == True: cv.imshow(&#x27;frame&#x27;,frame) # 5.每一帧间隔为25ms if cv.waitKey(25) &amp; 0xFF == ord(&#x27;q&#x27;): break# 6.释放视频对象cap.release()cv.destoryAllwindows() 保存视频 创建视频写入的对象 1out = cv2.VideoWriter(filename,fourcc, fps, frameSize) 参数： filename：视频保存的位置 fourcc：指定视频编解码器的4字节代码 fps：帧率 frameSize：帧大小 设置视频的编解码器 1retval = cv2.VideoWriter_fourcc( c1, c2, c3, c4 ) 参数： c1,c2,c3,c4：是视频编解码器的4字节代码，常用的有： 在Windows中：DIVX（.avi） 在OS中：MJPG（.mp4），DIVX（.avi），X264（.mkv）。 获取视频的一帧图像 1ret, frame = cap.read() 参数： ret：若获取成功返回True，获取失败，返回False frame：获取到的某一帧的图像 某一帧图像写入视频 1out.write() 释放资源 12cap.release()out.release() 示例代码： 12345678910111213141516171819202122232425import cv2 as cvimport numpy as np# 1. 读取视频cap = cv.VideoCapture(&quot;DOG.wmv&quot;)# 2. 获取图像的属性（宽和高，）,并将其转换为整数frame_width = int(cap.get(3))frame_height = int(cap.get(4))# 3. 创建保存视频的对象，设置编码格式，帧率，图像的宽高等out = cv.VideoWriter(&#x27;outpy.avi&#x27;,cv.VideoWriter_fourcc(&#x27;M&#x27;,&#x27;J&#x27;,&#x27;P&#x27;,&#x27;G&#x27;), 10, (frame_width,frame_height))while(True): # 4.获取视频中的每一帧图像 ret, frame = cap.read() if ret == True: # 5.将每一帧图像写入到输出文件中 out.write(frame) else: break # 6.释放资源cap.release()out.release()cv.destroyAllWindows() 视频追踪 meanshift算法 假设有一堆点集，还有一个小的窗口，这个窗口可能是圆形的，现在你可能要移动这个窗口到点集密度最大的区域当中。 最开始的窗口是蓝色圆环的区域，命名为\\(C1\\)。蓝色圆环的圆心用一个蓝色的矩形标注，命名为\\(C1_o\\)。而窗口中所有点的点集构成的质心在蓝色圆形点\\(C1_r\\)处，显然圆环的形心和质心并不重合。所以，移动蓝色的窗口，使得形心与之前得到的质心重合。在新移动后的圆环的区域当中再次寻找圆环当中所包围点集的质心，然后再次移动，通常情况下，形心和质心是不重合的。不断执行上面的移动过程，直到形心和质心大致重合结束。 这样，最后圆形的窗口会落到像素分布最大的地方，也就是图中的绿色圈，命名为\\(C2\\)。 首先在图像上选定一个目标区域 计算选定区域的直方图分布，一般是HSV色彩空间的直方图。 对下一帧图像\\(b\\)同样计算直方图分布。 计算图像\\(b\\)当中与选定区域直方图分布最为相似的区域，使用meanshift算法将选定区域沿着最为相似的部分进行移动，直到找到最相似的区域，便完成了在图像\\(b\\)中的目标追踪。 重复3、4的过程，就完成整个视频目标追踪。 通常情况下使用直方图反向投影得到的图像和第一帧目标对象的起始位置，目标对象的移动会反映到直方图反向投影图中，meanshift 算法把窗口移动到反向投影图像中灰度密度最大的区域。 直方图反向投影的流程是： 假设我们有一张\\(100\\times100\\)的输入图像，有一张\\(10\\times10\\)的模板图像， 从输入图像的左上角\\((0,0)\\)开始，切割一块\\((0,0)\\)至\\((10,10)\\)的临时图像， 生成临时图像的直方图， 用临时图像的直方图和模板图像的直方图对比，对比结果记为\\(c\\)， 直方图对比结果\\(c\\)，就是结果图像\\((0,0)\\)处的像素值， 切割输入图像从\\((0,1)\\)至\\((10,11)\\)的临时图像，对比直方图，并记录到结果图像， 重复1～5步直到输入图像的右下角，就形成了直方图的反向投影。 1cv.meanShift(probImage, window, criteria) 参数： probImage: ROI区域，即目标的直方图的反向投影 window： 初始搜索窗口，就是定义ROI的rect criteria: 确定窗口搜索停止的准则，主要有迭代次数达到设置的最大值，窗口中心的漂移值大于某个设定的限值等。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import numpy as npimport cv2 as cv# 1.获取图像cap = cv.VideoCapture(&#x27;DOG.wmv&#x27;)# 2.获取第一帧图像，并指定目标位置ret,frame = cap.read()# 2.1 目标位置（行，高，列，宽）r,h,c,w = 197,141,0,208 track_window = (c,r,w,h)# 2.2 指定目标的感兴趣区域roi = frame[r:r+h, c:c+w]# 3. 计算直方图# 3.1 转换色彩空间（HSV）hsv_roi = cv.cvtColor(roi, cv.COLOR_BGR2HSV)# 3.2 去除低亮度的值# mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))# 3.3 计算直方图roi_hist = cv.calcHist([hsv_roi],[0],None,[180],[0,180])# 3.4 归一化cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)# 4. 目标追踪# 4.1 设置窗口搜索终止条件：最大迭代次数，窗口中心漂移最小值term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )while(True): # 4.2 获取每一帧图像 ret ,frame = cap.read() if ret == True: # 4.3 计算直方图的反向投影 hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV) dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1) # 4.4 进行meanshift追踪 ret, track_window = cv.meanShift(dst, track_window, term_crit) # 4.5 将追踪的位置绘制在视频上，并进行显示 x,y,w,h = track_window img2 = cv.rectangle(frame, (x,y), (x+w,y+h), 255,2) cv.imshow(&#x27;frame&#x27;,img2) if cv.waitKey(60) &amp; 0xFF == ord(&#x27;q&#x27;): break else: break# 5. 资源释放 cap.release()cv.destroyAllWindows() Camshift算法 检测的窗口的大小是固定的，而狗狗由近及远是一个逐渐变小的过程，固定的窗口是不合适的。所以需要根据目标的大小和角度来对窗口的大小和角度进行修正。 连续自适应MeanShift(Continuously Adaptive Mean-Shift，Camshift)算法是对MeanShift算法的改进算法，可随着跟踪目标的大小变化实时调整搜索窗口的大小，具有较好的跟踪效果。 首先应用meanshift，一旦meanshift收敛，它就会更新窗口的大小，还计算最佳拟合椭圆的方向，从而根据目标的位置和大小更新搜索窗口。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import numpy as npimport cv2 as cv# 1.获取图像cap = cv.VideoCapture(&#x27;DOG.wmv&#x27;)# 2.获取第一帧图像，并指定目标位置ret,frame = cap.read()# 2.1 目标位置（行，高，列，宽）r,h,c,w = 197,141,0,208 track_window = (c,r,w,h)# 2.2 指定目标的感兴趣区域roi = frame[r:r+h, c:c+w]# 3. 计算直方图# 3.1 转换色彩空间（HSV）hsv_roi = cv.cvtColor(roi, cv.COLOR_BGR2HSV)# 3.2 去除低亮度的值# mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))# 3.3 计算直方图roi_hist = cv.calcHist([hsv_roi],[0],None,[180],[0,180])# 3.4 归一化cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)# 4. 目标追踪# 4.1 设置窗口搜索终止条件：最大迭代次数，窗口中心漂移最小值term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )while(True): # 4.2 获取每一帧图像 ret ,frame = cap.read() if ret == True: # 4.3 计算直方图的反向投影 hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV) dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1) # 4.4 进行camshift追踪 ret, track_window = cv.CamShift(dst, track_window, term_crit) # 绘制追踪结果 pts = cv.boxPoints(ret) pts = np.int0(pts) img2 = cv.polylines(frame,[pts],True, 255,2) cv.imshow(&#x27;frame&#x27;,img2) if cv.waitKey(60) &amp; 0xFF == ord(&#x27;q&#x27;): break else: break# 5. 资源释放 cap.release()cv.destroyAllWindows() 总结 Meanshift和camshift算法都各有优势，自然也有劣势： Meanshift算法：简单，迭代次数少，但无法解决目标的遮挡问题并且不能适应运动目标的的形状和大小变化。 camshift算法：可适应运动目标的大小形状的改变，具有较好的跟踪效果，但当背景色和目标颜色接近时，容易使目标的区域变大，最终有可能导致目标跟踪丢失。","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"https://liujk6525.github.io/categories/OpenCV/"}],"tags":[{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"图像特征提取与描述","slug":"图像特征提取与描述","date":"2023-05-19T15:38:12.000Z","updated":"2023-05-26T05:22:33.647Z","comments":true,"path":"OpenCV/图像特征提取与描述/","link":"","permalink":"https://liujk6525.github.io/OpenCV/%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%B8%8E%E6%8F%8F%E8%BF%B0/","excerpt":"角点特征 如下图所示，蓝色框中的区域是一个平面，无论向哪个方向移动蓝色框，都是一样的。对于黑色框中的区域，它是一个边缘。如果沿垂直方向移动，它会改变。但是如果沿水平方向移动就不会改变。而红色框中的角点，无论你向那个方向移动，得到的结果都不同，这说明它是唯一的。 所以说，角点是一个好的图像特征。","text":"角点特征 如下图所示，蓝色框中的区域是一个平面，无论向哪个方向移动蓝色框，都是一样的。对于黑色框中的区域，它是一个边缘。如果沿垂直方向移动，它会改变。但是如果沿水平方向移动就不会改变。而红色框中的角点，无论你向那个方向移动，得到的结果都不同，这说明它是唯一的。 所以说，角点是一个好的图像特征。 Harris和Shi-Tomas算法 Harris角点检测 Harris角点检测的思想是通过图像的局部的小窗口观察图像，角点的特征是窗口沿任意方向移动都会导致图像灰度的明显变化，如下图所示： 将局部窗口向各个方向移动\\((u,v)\\)，并计算所有灰度差异的总和，表达式如下： \\[ E(u,v)=\\sum_{x,y}w(x,y)[I(x+u,y+v)-I(x,y)]^2 \\] 其中\\(E(u,v)\\)是局部窗口的图像灰度，\\(I(x+u,y+v)\\)是平移后的图像灰度，\\(w(x,y)\\)是窗口函数，该可以是矩形窗口，也可以是对每一个像素赋予不同权重的高斯窗口，如下所示： 角点检测中使\\(E(u,v)\\)的值最大。利用一阶泰勒展开有： \\[ I(x+u,y+v)=I(x,y)+I_xu+I_yv \\] 其中\\(I_x\\)和\\(I_y\\)是沿\\(x\\)和\\(y\\)方向的导数，可用sobel算子计算 \\[ E(u,v)=\\sum_{x,y}w(x,y)[I(x+u,y+v)-I(x,y)]^2 \\] \\[ =\\sum_{x,y}w(x,y)[I(x,y)+I_xu+I_yv-I(x,y)]^2 \\] \\[ =\\sum_{x,y}w(x,y)[I_x^2u^2+2I_xI_yuv+I_y^2v^2] \\] \\[ =\\sum_{x,y}w(x,y)\\left[\\begin{matrix}u&amp;v\\end{matrix}\\right] \\left[\\begin{matrix}I_x^2&amp;I_xI_y\\\\I_xI_y&amp;I_y^2\\end{matrix}\\right] \\left[\\begin{matrix}u\\\\v\\end{matrix}\\right] \\] \\[ =\\left[\\begin{matrix}u&amp;v\\end{matrix}\\right]\\underbrace{\\sum_{x,y}w(x,y) \\left[\\begin{matrix}I_x^2&amp;I_xI_y\\\\I_xI_y&amp;I_y^2\\end{matrix}\\right]}_M \\left[\\begin{matrix}u\\\\v\\end{matrix}\\right]=\\left[\\begin{matrix}u&amp;v\\end{matrix}\\right]M \\left[\\begin{matrix}u\\\\v\\end{matrix}\\right] \\] \\(M\\)矩阵决定了\\(E(u,v)\\)的取值，下面我们利用\\(M\\)来求角点，\\(M\\)是\\(I_x\\)和\\(I_y\\)的二次项函数，可以表示成椭圆的形状，椭圆的长短半轴由\\(M\\)的特征值\\(\\lambda_1\\)和\\(\\lambda_2\\)决定，方向由特征矢量决定，如下图所示： 椭圆函数特征值与图像中的角点、直线（边缘）和平面之间的关系如下图所示。 共可分为三种情况： 图像中的直线。一个特征值大，另一个特征值小，\\(\\lambda_1&gt;&gt;\\lambda_2\\)或 \\(\\lambda_2&gt;&gt;\\lambda_1\\)。椭圆函数值在某一方向上大，在其他方向上小。 图像中的平面。两个特征值都小，且近似相等；椭圆函数数值在各个方向上都小。 图像中的角点。两个特征值都大，且近似相等，椭圆函数在所有方向都增大 Harris给出的角点计算方法并不需要计算具体的特征值，而是计算一个角点响应值\\(R\\)来判断角点。\\(R\\)的计算公式是 \\[ R=detM-\\alpha(traceM)^2\\\\ detM=\\lambda_1\\lambda_2\\\\ traceM=\\lambda_1+\\lambda_2 \\] 式中，\\(detM\\)为矩阵\\(M\\)的行列式；\\(traceM\\)为矩阵\\(M\\)的迹；\\(\\alpha\\)为常数，取值范围为0.04~0.06。 如下图所示： 当R为大数值的正数时是角点 当R为大数值的负数时是边界 当R为小数是认为是平坦区域 1dst=cv.cornerHarris(src, blockSize, ksize, k) 参数： img：数据类型为 ﬂoat32 的输入图像。 blockSize：角点检测中要考虑的邻域大小。 ksize：sobel算子求导使用的核大小。 k：角点检测方程中的自由参数，取值参数为 [0.04，0.06]。 示例代码 12345678910111213141516171819import cv2 as cvimport numpy as np import matplotlib.pyplot as plt# 1 读取图像，并转换成灰度图像img = cv.imread(&#x27;./image/chessboard.jpg&#x27;)gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)# 2 角点检测# 2.1 输入图像必须是 float32gray = np.float32(gray)# 2.2 最后一个参数在 0.04 到 0.05 之间dst = cv.cornerHarris(gray,2,3,0.04)# 3 设置阈值，将角点绘制出来，阈值根据图像进行选择img[dst&gt;0.001*dst.max()] = [0,0,255]# 4 图像显示plt.figure(figsize=(10,8),dpi=100)plt.imshow(img[:,:,::-1]),plt.title(&#x27;Harris角点检测&#x27;)plt.xticks([]), plt.yticks([])plt.show() Harris角点检测的优缺点： 优点： 旋转不变性，椭圆转过一定角度但是其形状保持不变（特征值保持不变） 对于图像灰度的仿射变化具有部分的不变性，由于仅仅使用了图像的一介导数，对于图像灰度平移变化不变；对于图像灰度尺度变化不变 缺点： 对尺度很敏感，不具备几何尺度不变性。 提取的角点是像素级的 Shi-Tomasi角点检测 Shi-Tomasi算法是对Harris算法的改进，具体地：若矩阵M的两个特征值\\(\\lambda_1,\\lambda_2\\)中较小的一个大于阈值，则认为他是角点，即： \\[ R=min(\\lambda_1,\\lambda_2) \\] 1corners = cv2.goodFeaturesToTrack ( image, maxcorners, qualityLevel, minDistance ) 参数： Image：输入灰度图像 maxCorners：获取角点数的数目。 qualityLevel：指出最低可接受的角点质量水平，在0-1之间。 minDistance：角点之间最小的欧式距离，避免得到相邻特征点。 返回： Corners: 搜索到的角点，在这里所有低于质量水平的角点被排除掉，然后把合格的角点按质量排序，然后将质量较好的角点附近（小于最小欧式距离）的角点删掉，最后找到maxCorners个角点返回。 示例代码 1234567891011121314151617import numpy as np import cv2 as cvimport matplotlib.pyplot as plt# 1 读取图像img = cv.imread(&#x27;./image/tv.jpg&#x27;) gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)# 2 角点检测corners = cv.goodFeaturesToTrack(gray,1000,0.01,10) # 3 绘制角点for i in corners: x,y = i.ravel() cv.circle(img,(x,y),2,(0,0,255),-1)# 4 图像展示plt.figure(figsize=(10,8),dpi=100)plt.imshow(img[:,:,::-1]),plt.title(&#x27;shi-tomasi角点检测&#x27;)plt.xticks([]), plt.yticks([])plt.show() SIFT和SURF算法 SIFT算法 Harris和Shi-Tomasi角点检测算法具有旋转不变性，但不具有尺度不变性，以下图为例，在左侧小图中可以检测到角点，但是图像被放大后，在使用同样的窗口，就检测不到角点了。 尺度不变特征转换（Scale-invariant feature transform，SIFT）。此算法由 David Lowe在1999年所发表，2004年完善总结。它的实质是在不同的尺度空间上查找关键点(特征点)，并计算出关键点的方向。SIFT所查找到的关键点是一些十分突出，不会因光照，仿射变换和噪音等因素而变化的点，如角点、边缘点、暗区的亮点及亮区的暗点等。 尺度空间极值检测：搜索所有尺度上的图像位置。通过高斯差分函数来识别潜在的对于尺度和旋转不变的关键点。 关键点定位：在每个候选的位置上，通过一个拟合精细的模型来确定位置和尺度。关键点的选择依据于它们的稳定程度。 关键点方向确定：基于图像局部的梯度方向，分配给每个关键点位置一个或多个方向。所有后面的对图像数据的操作都相对于关键点的方向、尺度和位置进行变换，从而保证了对于这些变换的不变性。 关键点描述：在每个关键点周围的邻域内，在选定的尺度上测量图像局部的梯度。这些梯度作为关键点的描述符，它允许比较大的局部形状的变形或光照变化。 尺度空间极值检测 在不同的尺度空间是不能使用相同的窗口检测极值点，对小的关键点使用小的窗口，对大的关键点使用大的窗口，为了达到上述目的，使用尺度空间滤波器。（高斯核是唯一可以产生多尺度空间的核函数） 一个图像的尺度空间\\(L(x,y,\\sigma)\\)定义为原始图像\\(I(x,y)\\)与一个可变尺度的2维高斯函数\\(G(x,y,\\sigma)\\)卷积运算 ，即： \\[ L(x,y,\\sigma)=G(x,y,\\sigma)*I(x,y) \\] 其中\\(\\sigma\\)是尺度空间因子，它决定图像的模糊程度。在大尺度下(\\(\\sigma\\)值大)表现的是图像的概貌信息，在小尺度下(\\(\\sigma\\)值小)表现的是图像的细节信息。 在计算高斯函数的离散近似时，在大概\\(3\\sigma\\)距离之外的像素都可以看作不起作用，这些像素的计算也就可以忽略。所以，在实际应用中，只计算\\((6\\sigma+1)\\times(6\\sigma+1)\\)的高斯卷积核就可以保证相关像素影响。 下面构建图像的高斯金字塔，它采用高斯函数对图像进行模糊以及降采样处理得到的， 1. 将图像扩大一倍，在扩大的图像的基础之上构建高斯金字塔， 2. 对该尺寸下图像进行高斯模糊，几幅模糊之后的图像集合构成了一个Octave， 3. 对该Octave下选择一幅图像进行下采样，长和宽分别缩短一倍，图像面积变为原来四分之一。这幅图像就是下一个Octave的初始图像，在初始图像的基础上完成属于这个Octave的高斯模糊处理， 4. 以此类推，完成整个算法。 利用高斯拉普拉斯算子(Laplacian of Gaussian, LoG)，即图像的二阶导数，可以在不同的尺度下检测图像的关键点信息，从而确定图像的特征点。但LoG的计算量大，效率低。所以通过两个相邻高斯尺度空间的图像相减，得到高斯差分(Difference of Gaussians，DOG)来近似LoG。 构建高斯差分金字塔 将高斯金字塔中每个Octave中相邻两层相减就构成了高斯差分金字塔。 高斯差分金字塔的第o组第i层图像是由高斯金字塔的第o组第i+1层减第o组第i层得到的。 在不同的尺度空间中搜索局部最大值 对于图像中的每一个像素点而言，它需要与自己周围的\\(8\\)邻域，以及尺度空间中上下两层中的相邻的\\(18(2\\times9)\\)个点相比。 如果是局部最大值，它就可能是一个关键点。 搜索过程从每组的第二层开始，以第二层为当前层，对第二层的DoG图像中的每个点取一个\\(3\\times3\\)的立方体，立方体上下层为第一层与第三层。搜索得到的极值点既有位置坐标(DoG的图像坐标)，又有空间尺度坐标(层坐标)。 当第二层搜索完成后，再以第三层作为当前层，其过程与第二层的搜索类似。 当\\(S=3\\)时，每组里面要搜索3层，所以在高斯差分金字塔中就有\\(S+2\\)层，在高斯金字塔中每组有\\(S+3\\)层。 关键点定位 由于DoG对噪声和边缘比较敏感，因此在高斯差分金字塔中检测到的局部极值点需经过进一步的检验才能精确定位为特征点。 使用尺度空间的泰勒级数展开来获得极值的准确位置， 如果极值点的灰度值小于阈值（一般为0.03或0.04）就会被忽略掉。 在 OpenCV 中这种阈值被称为 contrastThreshold。 欠佳的关键点在平行边缘的方向有较大的主曲率，而在垂直于边缘的方向有较小的曲率，两者的比值如果高于某个阈值（在OpenCV中叫做边界阈值），就认为该关键点为边界，将被忽略，一般该阈值为10。 将低对比度和边界的关键点去除，得到的就是我们感兴趣的关键点。 关键点方向确定 为了实现旋转不变性，还需要为每个关键点分配一个方向角度，也就是在高斯尺度图像的邻域结构中求得一个方向基准。 对于任一关键点，采集其所在高斯金字塔图像以\\(r\\)为半径的区域内所有像素的梯度特征（幅值和幅角），\\(r=3\\times1.5\\sigma\\)，其中\\(\\sigma\\)是关键点所在octave的图像的尺度，可以得到对应的尺度图像。 梯度的幅值和方向的计算公式为： \\[ m(x,y)=\\sqrt{(L(x+1,y)-L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2} \\] \\[ \\theta(x,y)=\\arctan(\\frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)} \\] 邻域像素梯度的计算结果如下图所示： 使用直方图统计关键点邻域内像素的梯度幅值和方向。 将\\(360^\\circ\\)分为\\(36\\)柱，每\\(10^\\circ\\)为一柱，然后在以\\(r\\)为半径的区域内，将梯度方向在某一个柱内的像素找出来。 将他们的幅值相加在一起作为柱的高度。因为在r为半径的区域内像素的梯度幅值对中心像素的贡献是不同的，因此还需要对幅值进行加权处理，采用高斯加权，方差为\\(1.5\\sigma\\)。 每个特征点必须分配一个主方向，还需要一个或多个辅方向，增加辅方向的目的是为了增强图像匹配的鲁棒性。辅方向的定义是，当一个柱体的高度大于主方向柱体高度的\\(80\\%\\)时，则该柱体所代表的的方向就是给特征点的辅方向。 直方图的峰值，即最高的柱代表的方向是特征点邻域范围内图像梯度的主方向，但该柱体代表的角度是一个范围，所以我们还要对离散的直方图进行插值拟合，以得到更精确的方向角度值。利用抛物线对离散的直方图进行拟合。 获得图像关键点主方向后，使用一个带箭头的圆或直接使用箭头表示SIFT区域的三个值：中心表示特征点位置\\((x,y)\\)，半径表示关键点尺度\\((\\sigma)\\)，箭头表示方向\\((\\theta)\\)。 关键点描述 为每个关键点建立一个描述符，该描述符既具有可区分性，又具有对某些变量的不变性，如光照，视角等。而且描述符不仅仅包含关键点，也包括关键点周围对其有贡献的的像素点。 在关键点所在的高斯尺度图像上生成对应的描述符。以特征点为中心，将其附近邻域划分为\\(d\\times d\\)个子区域（一般取\\(d=4\\))，每个子区域都是一个正方形，边长为\\(3\\sigma\\)，考虑到实际计算时，需进行三次线性插值，所以特征点邻域的为\\(3\\sigma(d+1)\\times3\\sigma(d+1)\\)的范围，如下图所示： 为了保证特征点的旋转不变性，以特征点为中心，将坐标轴旋转为关键点的主方向，如下图所示： 计算子区域内的像素的梯度，并按照\\(\\sigma=0.5d\\)进行高斯加权，然后插值计算得到每个种子点的八个方向的梯度，插值方法如下图所示： 每个种子点的梯度都是由覆盖其的\\(4\\)个子区域插值而得的。如图中的红色点，落在第\\(0\\)行和第\\(1\\)行之间，对这两行都有贡献。 对第\\(0\\)行第\\(3\\)列种子点的贡献因子为\\(dr\\)，对第\\(1\\)行第\\(3\\)列的贡献因子为\\(1-dr\\)， 对邻近两列的贡献因子为\\(dc\\)和\\(1-dc\\) 对邻近两个方向的贡献因子为\\(do\\)和\\(1-do\\)。 最终累加在每个方向上的梯度大小为： \\[ weight=w*dr^k(1-dr)^{(1-k)}dc^m(1-dc)^{1-m}do^n(1-do^{1-n}) \\] 其中\\(k,m,n\\)为0或为1。 如上统计\\(4\\times4\\times8=128\\)个梯度信息即为该关键点的特征向量，按照特征点的对每个关键点的特征向量进行排序，就得到了SIFT特征描述向量。 实例化sift 1sift = cv.xfeatures2d.SIFT_create() 利用sift.detectAndCompute()检测关键点并计算 1kp,des = sift.detectAndCompute(gray,None) 参数： gray：进行关键点检测的图像，注意是灰度图像 返回： kp：关键点信息，包括位置，尺度，方向信息 des：关键点描述符，每个关键点对应128个梯度信息的特征向量 将关键点检测结果绘制在图像上 1cv.drawKeypoints(image, keypoints, outputimage, color, flags) 参数： image: 原始图像 keypoints：关键点信息，将其绘制在图像上 outputimage：输出图片，可以是原始图像 color：颜色设置，通过修改b、g、r的值,更改画笔的颜色 flags：绘图功能的标识设置 cv2.DRAW_MATCHES_FLAGS_DEFAULT：创建输出图像矩阵，使用现存的输出图像绘制匹配对和特征点，对每一个关键点只绘制中间点 cv2.DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG：不创建输出图像矩阵，而是在输出图像上绘制匹配对 cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS：对每一个特征点绘制带大小和方向的关键点图形 cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS：单点的特征点不被绘制 示例代码： 利用SIFT算法在中央电视台的图片上检测关键点，并将其绘制出来： 12345678910111213141516171819import cv2 as cv import numpy as npimport matplotlib.pyplot as plt# 1 读取图像img = cv.imread(&#x27;./image/tv.jpg&#x27;)gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)# 2 sift关键点检测# 2.1 实例化sift对象sift = cv.xfeatures2d.SIFT_create()# 2.2 关键点检测：kp关键点信息包括方向，尺度，位置信息，des是关键点的描述符kp,des=sift.detectAndCompute(gray,None)# 2.3 在图像上绘制关键点的检测结果cv.drawKeypoints(img,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)# 3 图像显示plt.figure(figsize=(8,6),dpi=100)plt.imshow(img[:,:,::-1]),plt.title(&#x27;sift检测&#x27;)plt.xticks([]), plt.yticks([])plt.show() SURF算法 使用 SIFT 算法进行关键点检测和描述的执行速度比较慢， 需要速度更快的算法。 2006 年 Bay提出了 SURF 算法，是SIFT算法的增强版，它的计算量小，运算速度快，提取的特征与SIFT几乎相同，将其与SIFT算法对比如下： Fast和ORB算法 Fast算法 Fast(Features from accelerated segment test)是一种角点检测算法，Edward Rosten和Tom Drummond在2006年提出了FAST算法，并在2010年对其进行了修正。该算法的原理是取图像中检测点，以该点为圆心的周围邻域内像素点判断检测点是否为角点，通俗的讲就是若一个像素周围有一定数量的像素与该点像素值不同，则认为其为角点。 在图像中选取一个像素点\\(p\\)，来判断它是不是关键点。\\[I_p\\]等于像素点\\(p\\)的灰度值。 以\\(r\\)为半径画圆，覆盖\\(p\\)点周围的\\(M\\)个像素，通常情况设置\\(r=3\\)，则\\(M=16\\)。 设置阈值\\(t\\)，如果在这\\(16\\)个像素点中存在\\(n\\)个连续像素点的灰度值都高于\\(I_p+t\\)，或者低于\\(I_p-t\\)，那么像素点\\(p\\)就被认为是一个角点。如上图中的虚线所示，一般取值为\\(n=12\\)。 采用一种非特征点判别的方法：首先对候选点的周围每个\\(90^\\circ\\)的点（\\(1,9,5,13\\)）进行测试(先测试\\(1\\)和\\(9\\)，如果它们符合阈值要求再测试\\(5\\)和\\(13\\))。如果\\(p\\)是角点，那么这四个点中至少有 3 个要符合阈值要求，否则直接剔除。对保留下来的点再继续进行测试。 机器学习的角点检测器 选择一组训练图片 使用FAST算法找出每幅图像的特征点，对图像中的每一个特征点，将其周围的\\(16\\)个像素存储构成一个向量\\(P\\)。 每一个特征点的 16 像素点都属于下列三类中的一种 $$ S_{px}= \\[\\begin{cases} d\\quad I_{p\\rightarrow x}\\leq I_{p}-t\\quad (darker)\\\\ s\\quad I_{p}-t\\leq I_{p\\rightarrow x}\\leq I_{p}+t\\quad (similar)\\\\ b\\quad I_{p}+t\\leq I_{p\\rightarrow x}\\quad (brighter)\\\\ \\end{cases}\\] $$ 根据这些像素点的分类，特征向量\\(P\\)也被分为\\(3\\)个子集(\\(P_d,P_s,P_b\\))， 定义一个新的布尔变量\\(K_p\\)，如果\\(p\\)是角点就设置为\\(True\\)，如果不是就设置为\\(False\\)。 利用特征值向量\\(p\\)，目标值是\\(K_p\\)，训练\\(ID3\\)树（决策树分类器）。 将构建好的决策树运用于其他图像的快速检测。 非极大值抑制 在筛选出来的候选角点中有很多是紧挨在一起的，需要通过非极大值抑制来消除这种影响。 为所有的候选角点确定一个打分函数\\(V\\) 分别计算\\(I_p\\)与圆上\\(16\\)个点的像素值差值，取绝对值， 将这16个绝对值相加，就得到了\\(V\\)的值 \\[ V = \\sum_{i}^{16}|I_p-I_i| \\] 比较毗邻候选角点的\\(V\\)值，把\\(V\\)值较小的候选角点去除掉。 实例化Fast 1fast = =cv.FastFeatureDetector_create( threshold, nonmaxSuppression) 参数： threshold：阈值t，默认值10 nonmaxSuppression：是否进行非极大值抑制，默认值True 返回： Fast：创建的FastFeatureDetector对象 利用fast.detect()检测关键点，没有对应的关键点描述 1kp = fast.detect(grayImg, None) 参数： gray: 进行关键点检测的图像，注意是灰度图像 返回： kp: 关键点信息，包括位置，尺度，方向信息 将关键点检测结果绘制在图像上 1cv.drawKeypoints(image, keypoints, outputimage, color, flags) 示例代码： 1234567891011121314151617181920212223242526272829303132333435import numpy as npimport cv2 as cvfrom matplotlib import pyplot as plt# 1 读取图像img = cv.imread(&#x27;./image/tv.jpg&#x27;)# 2 Fast角点检测# 2.1 创建一个Fast对象，传入阈值，注意：可以处理彩色空间图像fast = cv.FastFeatureDetector_create(threshold=30)# 2.2 检测图像上的关键点kp = fast.detect(img,None)# 2.3 在图像上绘制关键点img2 = cv.drawKeypoints(img, kp, None, color=(0,0,255))# 2.4 输出默认参数print( &quot;Threshold: &#123;&#125;&quot;.format(fast.getThreshold()) )print( &quot;nonmaxSuppression:&#123;&#125;&quot;.format(fast.getNonmaxSuppression()) )print( &quot;neighborhood: &#123;&#125;&quot;.format(fast.getType()) )print( &quot;Total Keypoints with nonmaxSuppression: &#123;&#125;&quot;.format(len(kp)) )# 2.5 关闭非极大值抑制fast.setNonmaxSuppression(0)kp = fast.detect(img,None)print( &quot;Total Keypoints without nonmaxSuppression: &#123;&#125;&quot;.format(len(kp)) )# 2.6 绘制为进行非极大值抑制的结果img3 = cv.drawKeypoints(img, kp, None, color=(0,0,255))# 3 绘制图像fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,8),dpi=100)axes[0].imshow(img2[:,:,::-1])axes[0].set_title(&quot;加入非极大值抑制&quot;)axes[1].imshow(img3[:,:,::-1])axes[1].set_title(&quot;未加入非极大值抑制&quot;)plt.show() ORB 算法 ORB（Oriented Fast and Rotated Brief）可以用来对图像中的关键点快速创建特征向量，并用这些特征向量来识别图像中的对象。 ORB算法结合了Fast和Brief算法，提出了构造金字塔，为Fast特征点添加了方向，从而使得关键点具有了尺度不变性和旋转不变性。 构造尺度金字塔 金字塔共有\\(n\\)层，与SIFT不同的是，每一层仅有一幅图像。第\\(s\\)层的尺度为\\(\\sigma_s=\\sigma_0^s\\)， \\(\\sigma_0\\)是初始尺度，默认为\\(1.2\\)，原图在第\\(0\\)层。第\\(s\\)层图像的大小\\(Size = (H*\\frac{1}{\\sigma_s})\\times(W*\\frac{1}{\\sigma_s})\\) 在不同的尺度上利用Fast算法检测特征点 采用Harris角点响应函数，根据角点的响应值排序，选取前\\(N\\)个特征点，作为本尺度的特征点。 计算特征点的主方向 计算以特征点为圆心，半径为\\(r\\)的圆形邻域内的灰度质心位置，将从特征点位置到质心位置的方向做特征点的主方向。 \\[ m_{pq}=\\sum_{x,y}x^py^qI(x,y) \\] 质心位置： \\(C=(\\frac{m_{10}}{m_{00}},\\frac{m_{01}}{m_{10}})\\) 主方向： \\(\\theta = arctan(m_{01},m_{10})\\) BRIEF算法 了解决旋转不变性，将特征点的邻域旋转到主方向上利用Brief算法构建特征描述符，至此就得到了ORB的特征描述向量。 Brief算法是一种特征描述子提取算法，并非特征点的提取算法，匹配只需要使用简单的汉明距离(Hamming Distance)利用比特之间的异或操作就可以完成。 图像滤波 原始图像中存在噪声时，会对结果产生影响，所以需要对图像进行滤波，去除部分噪声。 选取点对 以特征点为中心，取\\(S\\times S\\)的邻域窗口，在窗口内随机选取\\(N\\)组点对，一般\\(N=128,256,512\\)，默认是\\(256\\)，关于选取随机点对，提供了五种形式 \\(x,y\\)方向平均分布采样 \\(x,y\\)均服从\\(Gauss(0,\\frac{S^2}{25})\\)各向同性采样 \\(x\\)服从\\(Gauss(0,\\frac{S^2}{25})\\)，\\(y\\)服从\\(Gauss(0,\\frac{S^2}{100})\\)采样 \\(x,y\\)从网格中随机获取 \\(x\\)一直在\\((0,0)\\)，\\(y\\)从网格中随机选取 图中一条线段的两个端点就是一组点对，其中第二种方法的结果比较好。 构建描述符 假设\\(x,y\\)是某个点对的两个端点，\\(p(x),p(y)\\)是两点对应的像素值， \\[ t(x,y)=\\begin{cases}1 &amp;if&amp;p(x)&gt;p(y)\\\\ 0&amp; else\\end{cases} \\] 对每一个点对都进行上述的二进制赋值，形成Brief的关键点的描述特征向量，该向量一般为\\(128-512\\)位的字符串，其中仅包含\\(1\\)和\\(0\\) 实例化ORB 1orb = cv.xfeatures2d.orb_create(nfeatures) 参数： nfeatures: 特征点的最大数量 利用orb.detectAndCompute()检测关键点并计算 1kp,des = orb.detectAndCompute(gray,None) 参数： gray: 进行关键点检测的图像，注意是灰度图像 返回： kp: 关键点信息，包括位置，尺度，方向信息 des: 关键点描述符，每个关键点BRIEF特征向量，二进制字符串， 将关键点检测结果绘制在图像上 1cv.drawKeypoints(image, keypoints, outputimage, color, flags) 示例代码： 12345678910111213141516171819202122import numpy as npimport cv2 as cvfrom matplotlib import pyplot as plt# 1 图像读取img = cv.imread(&#x27;./image/tv.jpg&#x27;)# 2 ORB角点检测# 2.1 实例化ORB对象orb = cv.ORB_create(nfeatures=500)# 2.2 检测关键点,并计算特征描述符kp,des = orb.detectAndCompute(img,None)print(des.shape)# 3 将关键点绘制在图像上img2 = cv.drawKeypoints(img, kp, None, color=(0,0,255), flags=0)# 4. 绘制图像plt.figure(figsize=(10,8),dpi=100)plt.imshow(img2[:,:,::-1])plt.xticks([]), plt.yticks([])plt.show()","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"https://liujk6525.github.io/categories/OpenCV/"}],"tags":[{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"OpenCV图像处理(下)","slug":"OpenCV图像处理-下","date":"2023-05-19T00:30:52.000Z","updated":"2023-05-26T05:32:41.512Z","comments":true,"path":"OpenCV/OpenCV图像处理-下/","link":"","permalink":"https://liujk6525.github.io/OpenCV/OpenCV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E4%B8%8B/","excerpt":"直方图 图像直方图 在统计学中，直方图是一种对数据分布情况的图形表示，是一种二维统计图表，它的两个 坐标分别是统计样本和该样本对应的某个属性的度量，以长条图(bar)的形式具体表现。因为直方图的长度及宽度很适合用来表现数量上的变化，所以较容易解读差异小的数值。","text":"直方图 图像直方图 在统计学中，直方图是一种对数据分布情况的图形表示，是一种二维统计图表，它的两个 坐标分别是统计样本和该样本对应的某个属性的度量，以长条图(bar)的形式具体表现。因为直方图的长度及宽度很适合用来表现数量上的变化，所以较容易解读差异小的数值。 图像直方图（Image Histogram）是用以表示数字图像中亮度分布的直方图，标绘了图像中每个亮度值的像素个数。这种直方图中，横坐标的左侧为较暗的区域，而右侧为较亮的区域。因此一张较暗图片的直方图中的数据多集中于左侧和中间部分，而整体明亮、只有少量阴影的图像则相反。 假设有一张图像的信息（灰度值\\(0-255\\)），按一定规律将这个范围分割成子区域（也就是 bins）。如下按\\(bin=16\\)分割 \\[ [0,255]=\\underbrace{[0,15]}_{b_{1}}\\cup\\underbrace{[16,30]}_{b_{2}}\\cdots\\cup\\underbrace{[240,255]}_{b_{16}} \\] 再统计\\(bin(i)\\) 的像素数目。得到以\\(x\\)轴表示\\(bin\\)，\\(y\\) 轴表示各个\\(bin\\)中的像素个数的图像直方图 注意： 直方图是根据灰度图进行绘制的，而不是彩色图像。 直方图是图像中像素强度分布的图形表达方式。 它统计了每一个强度值所具有的像素个数。 不同的图像的直方图可能是相同的 直方图的计算和绘制 1cv2.calcHist(images,channels,mask,histSize,ranges[,hist[,accumulate]]) 参数： images：原图像。当传入函数时应该用中括号[]括起来，例如：[img]。 channels：如果输入图像是灰度图，它的值就是[0]；如果是彩色图像的话，传入的参数可以是[0]，[1]，[2]。它们分别对应着B，G，R通道。 mask: 掩模图像。要统计整幅图像的直方图就把它设为 None。但是如果你想统计图像某一部分的直方图的话，你就需要制作一个掩模图像，并使用它。 histsize：\\(bin\\)的数目。也应该用中括号括起来，例如：[256]。 ranges：像素值范围，通常为[0，256] 示例代码 绘制直方图 123456789101112import numpy as npimport cv2 as cvfrom matplotlib import pyplot as plt# 1 直接以灰度图的方式读入img = cv.imread(&#x27;./image/cat.jpeg&#x27;,0)# 2 统计灰度图histr = cv.calcHist([img],[0],None,[256],[0,256])# 3 绘制灰度图plt.figure(figsize=(10,6),dpi=100)plt.plot(histr)plt.grid()plt.show() 掩膜 掩膜是用选定的图像、图形或物体，对要处理的图像进行遮挡，来控制图像处理的区域。 在数字图像处理中，通常使用二维矩阵数组进行掩膜。掩膜是由0和1组成一个二进制图像，利用该掩膜图像要处理的图像进行掩膜，其中1值的区域被处理，0 值区域被屏蔽，不会处理。 使用cv.calcHist()来查找完整图像的直方图。 如果要查找图像某些区域的直方图， 只需在要查找直方图的区域上创建一个白色的掩膜图像，否则创建黑色， 然后将其作为掩码mask传递即可。 示例代码： 123456789101112131415161718192021222324import numpy as npimport cv2 as cvfrom matplotlib import pyplot as plt# 1. 直接以灰度图的方式读入img = cv.imread(&#x27;./image/cat.jpeg&#x27;,0)# 2. 创建蒙版mask = np.zeros(img.shape[:2], np.uint8)mask[400:650, 200:500] = 255# 3.掩模masked_img = cv.bitwise_and(img,img,mask = mask)# 4. 统计掩膜后图像的灰度图mask_histr = cv.calcHist([img],[0],mask,[256],[1,256])# 5. 图像展示fig,axes=plt.subplots(nrows=2,ncols=2,figsize=(10,8))axes[0,0].imshow(img,cmap=plt.cm.gray)axes[0,0].set_title(&quot;原图&quot;)axes[0,1].imshow(mask,cmap=plt.cm.gray)axes[0,1].set_title(&quot;蒙版数据&quot;)axes[1,0].imshow(masked_img,cmap=plt.cm.gray)axes[1,0].set_title(&quot;掩膜后数据&quot;)axes[1,1].plot(mask_histr)axes[1,1].grid()axes[1,1].set_title(&quot;灰度直方图&quot;)plt.show() 直方图均衡化 直方图均衡化是把原始图像的灰度直方图从比较集中的某个灰度区间变成在更广泛灰度范围内的分布。 直方图均衡化就是对图像进行非线性拉伸，重新分配图像像素值，使一定灰度范围内的像素数量大致相同。 通过这种方法，亮度可以更好地在直方图上分布。这样可以用于增强局部的对比度而不影响整体的对比度 1dst = cv.equalizeHist(img) 参数： img: 灰度图像 返回： dst : 均衡化后的结果 示例代码： 1234567891011121314import numpy as npimport cv2 as cvfrom matplotlib import pyplot as plt# 1. 直接以灰度图的方式读入img = cv.imread(&#x27;./image/cat.jpeg&#x27;,0)# 2. 均衡化处理dst = cv.equalizeHist(img)# 3. 结果展示fig,axes=plt.subplots(nrows=2,ncols=2,figsize=(10,8),dpi=100)axes[0].imshow(img,cmap=plt.cm.gray)axes[0].set_title(&quot;原图&quot;)axes[1].imshow(dst,cmap=plt.cm.gray)axes[1].set_title(&quot;均衡化后结果&quot;)plt.show() 自适应的直方图均衡化 上述的直方图均衡，我们考虑的是图像的全局对比度。在许多情况下，这样做的效果并不好，但，会丢失了很多信息。 为了解决这个问题， 需要使用自适应的直方图均衡化。 整幅图像会被分成很多小块，这些小块被称为tiles 然后再分别对每个小块进行直方图均衡化。 所以在每个区域中， 直方图会集中在某一个小的区域中。如果有噪声的话，噪声会被放大。为了避免这种情况的出现要使用对比度限制。对于每个小块来说，如果直方图中的 \\(bin\\)超过对比度的上限的话，就把其中的像素点均匀分散到其他\\(bins\\)中，然后在进行直方图均衡化。 最后，为了去除每一个小块之间的边界，再使用双线性差值，对每一小块进行拼接。 1cv.createCLAHE(clipLimit, tileGridSize) 参数： clipLimit：对比度限制，默认是40 tileGridSize：分块的大小，默认为\\(8\\times8\\) 示例代码： 1234567891011121314import numpy as npimport cv2 as cv# 1. 以灰度图形式读取图像img = cv.imread(&#x27;./image/cat.jpeg&#x27;,0)# 2. 创建一个自适应均衡化的对象，并应用于图像clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))cl1 = clahe.apply(img)# 3. 图像展示fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,8),dpi=100)axes[0].imshow(img,cmap=plt.cm.gray)axes[0].set_title(&quot;原图&quot;)axes[1].imshow(cl1,cmap=plt.cm.gray)axes[1].set_title(&quot;自适应均衡化后的结果&quot;)plt.show() 与均衡化相比，可以看到在猫腿处不再显得暗黑。 边缘检测 边缘检测是图像处理和计算机视觉中的基本问题，边缘检测的目的是标识数字图像中亮度变化明显的点。 边缘检测的方法绝大部分可以划分为两类 基于搜索：通过寻找图像一阶导数中的最大值来检测边界，然后利用计算结果估计边缘的局部方向，通常采用梯度的方向，并利用此方向找到局部梯度模的最大值，代表算法是Sobel算子和Scharr算子。 基于零穿越：通过寻找图像二阶导数零穿越来寻找边界，代表算法是Laplacian算子 Sobel算子-基于搜索 对于不连续的函数，一阶导数可以写作\\(f&#39;(x)=f(x)-f(x-1)\\)或者\\(f&#39;(x)=f(x+1)-f(x)\\)，所以有 \\[ f&#39;(x)=\\frac{f(x+1)-f(x-1)}{2} \\] 假设要处理的图像为\\(I\\)，在两个方向求导 水平变化：将图像\\(I\\)与奇数大小的模版进行卷积，结果为\\(G_x\\)。 比如，当模板大小为\\(3\\times3\\)时, \\[ G_x=\\left[\\begin{matrix}-1&amp;0&amp;+1\\\\-2&amp;0&amp;+2\\\\-1&amp;0&amp;+1\\end{matrix}\\right]*I \\] 垂直变化：将图像\\(I\\)与奇数大小的模板进行卷积，结果为\\(G_y\\)。 比如，当模板大小为\\(3\\times3\\)时, \\[ G_y=\\left[\\begin{matrix}-1&amp;-2&amp;-1\\\\0&amp;0&amp;0\\\\+1&amp;+2&amp;+1\\end{matrix}\\right]*I \\] 在图像的每一点，通过公式求出： \\[ G=\\sqrt{G_x^2+G_y^2} \\] 统计极大值所在的位置，就是图像的边缘。 注意： 当核大小为\\(3\\times3\\)时, 以上Sobel卷积核可能产生比较明显的误差， 为解决这一问题，我们使用Scharr函数，但该函数仅作用于大小为\\(3\\times3\\)的卷积核。该函数的运算与Sobel函数一样快，但结果却更加精确，其计算方法为: \\[ G_x=\\left[\\begin{matrix}-3&amp;0&amp;+3\\\\-10&amp;0&amp;+10\\\\-3&amp;0&amp;+3\\end{matrix}\\right]*I \\] \\[ G_y=\\left[\\begin{matrix}-3&amp;-10&amp;-3\\\\0&amp;0&amp;0\\\\+3&amp;+10&amp;+3\\end{matrix}\\right]*I \\] 1Sobel_x_or_y = cv2.Sobel(src, ddepth, dx, dy, dst, ksize, scale, delta, borderType) 参数： src：传入的图像 ddepth：图像的深度 dx和dy：指求导的阶数，0表示这个方向上没有求导，取值为0、1。 ksize：是Sobel算子的大小，即卷积核的大小，默认为3。 注意：如果ksize=-1，就演变成为\\(3\\times3\\)的Scharr算子。 scale：缩放导数的比例常数，默认情况为没有伸缩系数。 borderType：图像边界的模式，默认值为cv2.BORDER_DEFAULT。 Sobel函数求导后会有负值，还有会大于255的值。而原图像是uint8，即8位无符号数，所以建立的图像位数不够，会有截断。 因此要使用16位有符号的数据类型，即cv2.CV_16S。处理完图像后，再使用cv2.convertScaleAbs()函数将其转回原来的uint8格式，否则图像无法显示。 最后还需要用cv2.addWeighted()函数将两个方向的Sobel算子计算结果组合起来 12Scale_abs = cv2.convertScaleAbs(x) # 格式转换函数result = cv2.addWeighted(src1, alpha, src2, beta) # 图像混合 示例代码： 1234567891011121314151617181920import cv2 as cvimport numpy as npfrom matplotlib import pyplot as plt# 1 读取图像img = cv.imread(&#x27;./image/horse.jpg&#x27;,0)# 2 计算Sobel卷积结果x = cv.Sobel(img, cv.CV_16S, 1, 0)y = cv.Sobel(img, cv.CV_16S, 0, 1)# 3 将数据进行转换Scale_absX = cv.convertScaleAbs(x) # convert 转换 scale 缩放Scale_absY = cv.convertScaleAbs(y)# 4 结果合成result = cv.addWeighted(Scale_absX, 0.5, Scale_absY, 0.5, 0)# 5 图像显示plt.figure(figsize=(10,8),dpi=100)plt.subplot(121),plt.imshow(img,cmap=plt.cm.gray),plt.title(&#x27;原图&#x27;)plt.xticks([]), plt.yticks([])plt.subplot(122),plt.imshow(result,cmap = plt.cm.gray),plt.title(&#x27;Sobel滤波后结果&#x27;)plt.xticks([]), plt.yticks([])plt.show() 将上述代码中计算sobel算子的部分中将ksize设为-1，就是利用Scharrs算子进行边缘检测。 12x = cv.Sobel(img, cv.CV_16S, 1, 0, ksize = -1)y = cv.Sobel(img, cv.CV_16S, 0, 1, ksize = -1) Laplacian算子-基于零穿越 Laplacian是利用二阶导数来检测边缘 。 因为图像是2维, 我们需要在两个方向求导，如下式所示： \\[ \\Delta src=\\frac{\\partial^2src}{\\partial x^2}+\\frac{\\partial^2src}{\\partial y^2} \\] 不连续函数的二阶导数是： \\[ f&#39;&#39;(x)=f&#39;(x+1)-f&#39;(x)=f(x+1)+f(x-1)-2f(x) \\] 使用的卷积核是： \\[ kernel=\\left[\\begin{matrix}0&amp;1&amp;0\\\\1&amp;-4&amp;1\\\\0&amp;1&amp;0\\\\\\end{matrix}\\right] \\] 1laplacian = cv2.Laplacian(src, ddepth[, dst[, ksize[, scale[, delta[, borderType]]]]]) 参数： src：需要处理的图像， ddepth：图像的深度，-1表示采用的是原图像相同的深度，目标图像的深度必须大于等于原图像的深度； ksize：算子的大小，即卷积核的大小 示例代码： 123456789101112131415import cv2 as cvimport numpy as npfrom matplotlib import pyplot as plt# 1 读取图像img = cv.imread(&#x27;./image/horse.jpg&#x27;,0)# 2 laplacian转换result = cv.Laplacian(img,cv.CV_16S)Scale_abs = cv.convertScaleAbs(result)# 3 图像展示plt.figure(figsize=(10,8),dpi=100)plt.subplot(121),plt.imshow(img,cmap=plt.cm.gray),plt.title(&#x27;原图&#x27;)plt.xticks([]), plt.yticks([])plt.subplot(122),plt.imshow(Scale_abs,cmap = plt.cm.gray),plt.title(&#x27;Laplacian检测后结果&#x27;)plt.xticks([]), plt.yticks([])plt.show() Canny算子 Canny 边缘检测算法是 John F. Canny 于 1986年提出的，被认为是最优的边缘检测算法。 去除噪声 由于边缘检测很容易受到噪声的影响，所以首先使用\\(5\\times5\\)高斯平滑滤波器去除噪声， 计算图像梯度 对平滑后的图像使用Sobel算子计算水平方向和竖直方向的一阶导数\\(G_x,G_y\\)。 根据这两幅梯度图找到边界的梯度和方向，公式如下: \\[ Edge_Gradient(G)=\\sqrt{G_x^2+G_y^2} \\] \\[ Angle(\\theta)=\\tan^{-1}(\\frac{G_y}{G_x}) \\] 如果某个像素点是边缘，则其梯度方向总是垂直于边缘。梯度方向被归为四类：垂直，水平，和两个对角线方向。 非极大值抑制 在获得梯度的方向和大小之后，对整幅图像进行扫描，去除那些非边界上的点。对每一个像素进行检查，看这个点的梯度是不是周围具有相同梯度方向的点中最大的。 A点位于图像的边缘，在其梯度变化方向，选择像素点B和C，用来检验A点的梯度是否为极大值，若为极大值，则进行保留，否则A点被抑制，最终的结果是具有细边的二进制图像。如下图所示： 滞后阈值 现在要确定真正的边界。 我们设置两个阈值： minVal和maxVal。 当图像的灰度梯度高于maxVal时被认为是真的边界， 低于minVal的边界会被抛弃。如果介于两者之间的话，就要看这个点是否与某个被确定为真正的边界点相连，如果是就认为它也是边界点，如果不是就抛弃。 如上图所示，A高于阈值maxVal所以是真正的边界点，C虽然低于maxVal但高于minVal并且与A相连，所以也被认为是真正的边界点。而B就会被抛弃，因为低于maxVal而且不与真正的边界点相连。 1canny = cv2.Canny(image, threshold1, threshold2) 参数： image：灰度图， threshold1: minval，较小的阈值将间断的边缘连接起来 threshold2: maxval，较大的阈值检测图像中明显的边缘 示例代码： 12345678910111213141516import cv2 as cvimport numpy as npfrom matplotlib import pyplot as plt# 1 图像读取img = cv.imread(&#x27;./image/horse.jpg&#x27;,0)# 2 Canny边缘检测lowThreshold = 0max_lowThreshold = 100canny = cv.Canny(img, lowThreshold, max_lowThreshold) # 3 图像展示plt.figure(figsize=(10,8),dpi=100)plt.subplot(121),plt.imshow(img,cmap=plt.cm.gray),plt.title(&#x27;原图&#x27;)plt.xticks([]), plt.yticks([])plt.subplot(122),plt.imshow(canny,cmap = plt.cm.gray),plt.title(&#x27;Canny检测后结果&#x27;)plt.xticks([]), plt.yticks([])plt.show() 模版匹配和霍夫变换 模板匹配 所谓的模板匹配，就是在给定的图片中查找和模板最相似的区域，该算法的输入包括模板和图片，然后按照滑窗的思路不断的移动模板图片，计算其与图像中对应区域的匹配度，最终将匹配度最高的区域选择为最终的结果。 准备两幅图像 原图像\\(I\\)：在这幅图中，找到与模板相匹配的区域 模板\\(T\\)：与原图像\\(I\\)进行比对的图像块 滑动模板图像和原图像进行比对 将模板块每次移动一个像素 (从左往右，从上往下)，在每一个位置，都计算与模板图像的相似程度。 对于每一个位置将计算的相似结果保存在结果矩阵\\(R\\)中。 如果输入图像的大小为\\((W\\times H)\\)且模板图像的大小为\\((w\\times h)\\)，则输出矩阵\\(R\\)的大小为\\((W-w+1,H-h+1)\\)，将\\(R\\)显示为图像。 获得上述图像后，查找最大值所在的位置，那么该位置对应的区域就被认为是最匹配的。对应的区域就是以该点为顶点，长宽和模板图像一样大小的矩阵。 1res = cv.matchTemplate(img,template,method) 参数： img：要进行模板匹配的图像 Template：模板 method：实现模板匹配的算法，主要有： 平方差匹配(CV_TM_SQDIFF)：利用模板与图像之间的平方差进行匹配，最好的匹配是0，匹配越差，匹配的值越大。 相关匹配(CV_TM_CCORR)：利用模板与图像间的乘法进行匹配，数值越大表示匹配程度较高，越小表示匹配效果差。 利用相关系数匹配(CV_TM_CCOEFF)：利用模板与图像间的相关系数匹配，1表示完美的匹配，-1表示最差的匹配。 完成匹配后，使用cv.minMaxLoc()方法查找最大值所在的位置即可。如果使用平方差作为比较方法，则最小值位置是最佳匹配位置。 示例代码： 载入要搜索的图像和模板，图像如下所示： 模板如下所示： 通过matchTemplate实现模板匹配，使用minMaxLoc定位最匹配的区域，并用矩形标注最匹配的区域。 123456789101112131415161718192021import cv2 as cvimport numpy as npfrom matplotlib import pyplot as plt# 1 图像和模板读取img = cv.imread(&#x27;./image/wulin2.jpeg&#x27;)template = cv.imread(&#x27;./image/wulin.jpeg&#x27;)h,w,l = template.shape# 2 模板匹配# 2.1 模板匹配res = cv.matchTemplate(img, template, cv.TM_CCORR)# 2.2 返回图像中最匹配的位置，确定左上角的坐标，并将匹配位置绘制在图像上min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)# 使用平方差时最小值为最佳匹配位置# top_left = min_loctop_left = max_locbottom_right = (top_left[0] + w, top_left[1] + h)cv.rectangle(img, top_left, bottom_right, (0,255,0), 2)# 3 图像显示plt.imshow(img[:,:,::-1])plt.title(&#x27;匹配结果&#x27;), plt.xticks([]), plt.yticks([])plt.show() 拓展：模板匹配不适用于尺度变换，视角变换后的图像，这时我们就要使用关键点匹配算法，比较经典的关键点检测算法包括SIFT和SURF等，主要的思路是首先通过关键点检测算法获取模板和测试图片中的关键点；然后使用关键点匹配算法处理即可，这些关键点可以很好的处理尺度变化、视角变换、旋转变化、光照变化等，具有很好的不变性。 霍夫变换 霍夫变换常用来提取图像中的直线和圆等几何形状。在笛卡尔坐标系中，一条直线由两个点\\(A=(x_1,y_1)\\)和\\(B(x2，y_2)\\)确定，如下图所示： 将直线\\(y=kx+q\\)可写成关于\\((k,q)\\)的函数表达式： \\[ \\begin{cases} q=-kx_1+y_1\\\\ q=-kx_2+y_2 \\end{cases} \\] 对应的变换通过图形直观的表示如下： 变换后的空间我们叫做霍夫空间。即：笛卡尔坐标系中的一条直线，对应于霍夫空间中的一个点。反过来，同样成立，霍夫空间中的一条线，对应于笛卡尔坐标系中一个点，如下所示： 我们再来看下\\(A\\)、\\(B\\)两个点，对应于霍夫空间的情形： 在看下三点共线的情况： 可以看出如果在笛卡尔坐标系的点共线，那么这些点在霍夫空间中对应的直线交于一点。 如果不止存在一条直线时，如下所示： 我们选择尽可能多的直线汇成的点，上图中三条直线汇成的\\(A\\)、\\(B\\)两点，将其对应回笛卡尔坐标系中的直线： 到这里我们似乎已经完成了霍夫变换的求解。但如果像下图这种情况时： 上图中的直线是\\(x=2\\)，那\\((k,q)\\)怎么确定呢？为了解决这个问题，考虑将笛卡尔坐标系转换为极坐标。 在极坐标下是一样的，极坐标中的点对应于霍夫空间的线，这时的霍夫空间不在是参数\\((k,q)\\)的空间，而是\\((\\rho,\\theta)\\)的空间，\\(\\rho\\)是原点到直线的垂直距离，\\(\\theta\\)表示直线的垂线与横轴顺时针方向的夹角，垂直线的角度为\\(0^\\circ\\)，水平线的角度是\\(180^\\circ\\)。 只要求得霍夫空间中的交点的位置，即可得到原坐标系下的直线。 假设有一个大小为\\(100\\times100\\)的图片，首先创建一个\\(2D\\)数组(累加器)，初始化所有值为0，行表示\\(\\rho\\)，列表示$$。若角度的精度为\\(1^\\circ\\)，那就需要180列。对于\\(\\rho\\)，最大值为图片对角线的距离，如果精度要达到像素级别，行数应该与图像的对角线的距离相等。 取直线上的第一个点\\((x,y)\\)，将其带入直线在极坐标中的公式中，然后遍历\\(\\theta\\)的取值\\((0,1,2,\\cdots,180)\\)，分别求出对应的\\(\\rho\\)值，如果这个数值在累加器中存在相应的位置，则在该位置上加1。 取直线上的第二个点，重复上述步骤，更新累加器中的值。对图像中的直线上的每个点都直线以上步骤，每次更新累加器中的值。 搜索累加器中的最大值，并找到其对应的\\((\\rho,\\theta)\\)，就可将图像中的直线表示出来。 霍夫线检测 1cv.HoughLines(img, rho, theta, threshold) 参数： img：检测的图像要求是二值化的图像，所以在调用霍夫变换之前首先要进行二值化，或者进行Canny边缘检测。 rho、theta：\\(\\rho\\) 和\\(\\theta\\)的精确度。 threshold：阈值，只有累加器中的值高于该阈值时才被认为是直线。 示例代码 检测下述图像中的直线： 1234567891011121314151617181920212223242526272829import numpy as npimport randomimport cv2 as cvimport matplotlib.pyplot as plt# 1.加载图片，转为二值图img = cv.imread(&#x27;./image/rili.jpg&#x27;)gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)edges = cv.Canny(gray, 50, 150)# 2.霍夫直线变换lines = cv.HoughLines(edges, 0.8, np.pi / 180, 150)# 3.将检测的线绘制在图像上（注意是极坐标噢）for line in lines: rho, theta = line[0] a = np.cos(theta) b = np.sin(theta) x0 = a * rho y0 = b * rho x1 = int(x0 + 1000 * (-b)) y1 = int(y0 + 1000 * (a)) x2 = int(x0 - 1000 * (-b)) y2 = int(y0 - 1000 * (a)) cv.line(img, (x1, y1), (x2, y2), (0, 255, 0))# 4. 图像显示plt.figure(figsize=(10,8),dpi=100)plt.imshow(img[:,:,::-1]),plt.title(&#x27;霍夫变换线检测&#x27;)plt.xticks([]), plt.yticks([])plt.show() 霍夫圆检测 圆的表示式是：\\((x-a)^2+(y-b)^2=r\\)，其中圆心坐标为\\((a,b)\\)，半径为\\(r\\)，因此标准的霍夫圆检测就是在这三个参数组成的三维空间累加器上进行圆形检测，此时的效率很低。 所以OpenCV中使用霍夫梯度法进行圆形的检测，霍夫梯度法是霍夫变换的改进，它的目的是减小霍夫空间的维度，提高效率。 霍夫梯度法将霍夫圆检测范围两个阶段，第一阶段检测圆心，第二阶段利用圆心推导出圆半径。 圆心检测的原理：圆心是圆周法线的交汇处，设置一个阈值，在某点的相交的直线的条数大于这个阈值就认为该交汇点为圆心。 圆半径确定原理：圆心到圆周上的距离（半径）是相同的，确定一个阈值，只要相同距离的数量大于该阈值，就认为该距离是该圆心的半径。 1circles = cv.HoughCircles(image, method, dp, minDist, param1=100, param2=100, minRadius=0,maxRadius=0 ) 参数： image：输入图像，应输入灰度图像 method：使用霍夫变换圆检测的算法，它的参数是CV_HOUGH_GRADIENT dp：霍夫空间的分辨率，dp=1时表示霍夫空间与输入图像空间的大小一致，dp=2时霍夫空间是输入图像空间的一半，以此类推。 minDist：为圆心之间的最小距离，如果检测到的两个圆心之间距离小于该值，则认为它们是同一个圆心。 param1：边缘检测时使用Canny算子的高阈值，低阈值是高阈值的一半。 param2：检测圆心和确定半径时所共有的阈值。 minRadius：所检测到的圆半径的最小值。 maxRadius：所检测到的圆半径的最大值。 返回： circles：输出圆向量，包括三个浮点型的元素（圆心横坐标，圆心纵坐标和圆半径） 示例代码 由于霍夫圆检测对噪声比较敏感，所以首先对图像进行中值滤波。 123456789101112131415161718192021import cv2 as cvimport numpy as npimport matplotlib.pyplot as plt# 1 读取图像，并转换为灰度图planets = cv.imread(&quot;./image/star.jpeg&quot;)gay_img = cv.cvtColor(planets, cv.COLOR_BGRA2GRAY)# 2 进行中值模糊，去噪点img = cv.medianBlur(gay_img, 7) # 3 霍夫圆检测circles = cv.HoughCircles(img, cv.HOUGH_GRADIENT, 1, 200, param1=100, param2=30, minRadius=0, maxRadius=100)# 4 将检测结果绘制在图像上for i in circles[0, :]: # 遍历矩阵每一行的数据 # 绘制圆形 cv.circle(planets, (i[0], i[1]), i[2], (0, 255, 0), 2) # 绘制圆心 cv.circle(planets, (i[0], i[1]), 2, (0, 0, 255), 3)# 5 图像显示plt.figure(figsize=(10,8),dpi=100)plt.imshow(planets[:,:,::-1]),plt.title(&#x27;霍夫变换圆检测&#x27;)plt.xticks([]), plt.yticks([])plt.show()","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"https://liujk6525.github.io/categories/OpenCV/"}],"tags":[{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"OpenCV图像处理(上)","slug":"OpenCV图像处理-上","date":"2023-05-17T13:19:42.000Z","updated":"2023-05-26T05:28:41.483Z","comments":true,"path":"OpenCV/OpenCV图像处理-上/","link":"","permalink":"https://liujk6525.github.io/OpenCV/OpenCV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86-%E4%B8%8A/","excerpt":"几何变换 图像缩放 缩放是对图像的大小进行调整，即使图像放大或缩小。 1cv2.resize(src,dsize,fx=0,fy=0,interpolation=cv2.INTER_LINEAR) 参数： src : 输入图像 dsize: 绝对尺寸，直接指定调整后图像的大小 fx,fy: 相对尺寸，将dsize设置为None，然后将fx和fy设置为比例因子即可 interpolation：插值方法，","text":"几何变换 图像缩放 缩放是对图像的大小进行调整，即使图像放大或缩小。 1cv2.resize(src,dsize,fx=0,fy=0,interpolation=cv2.INTER_LINEAR) 参数： src : 输入图像 dsize: 绝对尺寸，直接指定调整后图像的大小 fx,fy: 相对尺寸，将dsize设置为None，然后将fx和fy设置为比例因子即可 interpolation：插值方法， 示例代码 将图像分别以绝对尺度的方式放大，以相对尺寸的方式缩小。 123456789101112131415161718192021222324252627import cv2 as cv# 1. 读取图片img1 = cv.imread(&quot;./image/dog.jpeg&quot;)# 2.图像缩放# 2.1 绝对尺寸rows,cols = img1.shape[:2]res = cv.resize(img1,(2*cols,2*rows),interpolation=cv.INTER_CUBIC)# 2.2 相对尺寸res1 = cv.resize(img1,None,fx=0.5,fy=0.5)# 3 图像显示# 3.1 使用opencv显示图像(不推荐)cv.imshow(&quot;orignal&quot;,img1)cv.imshow(&quot;enlarge&quot;,res)cv.imshow(&quot;shrink）&quot;,res1)cv.waitKey(0)# 3.2 使用matplotlib显示图像fig,axes=plt.subplots(nrows=1,ncols=3,figsize=(10,8),dpi=100)axes[0].imshow(res[:,:,::-1])axes[0].set_title(&quot;绝对尺度（放大）&quot;)axes[1].imshow(img1[:,:,::-1])axes[1].set_title(&quot;原图&quot;)axes[2].imshow(res1[:,:,::-1])axes[2].set_title(&quot;相对尺度（缩小）&quot;)plt.show() 图像平移 图像平移将图像按照指定方向和距离，移动到相应的位置。 1cv.warpAffine(img,M,dsize) 参数： img: 输入图像 M： 2∗3的移动矩阵 对于(x,y)处的像素点，要把它移动到\\((x+t_x,y+t_y)\\)处时，M矩阵应如下设置： \\(M=\\left[\\begin{matrix}1&amp;0&amp;t_x\\\\0&amp;1&amp;t_y\\\\&amp;&amp;\\end{matrix}\\right]\\) 注意：将\\(M\\)设置为np.float32类型的Numpy数组。 dsize: 输出图像的大小 注意：输出图像的大小，它应该是(宽度，高度)的形式。请记住,width=列数，height=行数。 示例代码 将图像的像素点移动(50,100)的距离。 123456789101112131415161718import numpy as npimport cv2 as cvimport matplotlib.pyplot as plt# 1. 读取图像img1 = cv.imread(&quot;./image/image2.jpg&quot;)# 2. 图像平移rows,cols = img1.shape[:2]M = M = np.float32([[1,0,100],[0,1,50]])# 平移矩阵dst = cv.warpAffine(img1,M,(cols,rows))# 3. 图像显示fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,8),dpi=100)axes[0].imshow(img1[:,:,::-1])axes[0].set_title(&quot;原图&quot;)axes[1].imshow(dst[:,:,::-1])axes[1].set_title(&quot;平移后结果&quot;)plt.show() 图像旋转 图像旋转是指图像按照某个位置转动一定角度的过程，旋转中图像仍保持这原始尺寸。 假设图像逆时针旋转\\(\\theta\\)，则根据坐标转换可得: \\[ \\left[\\begin{matrix}x&#39;&amp;y&#39;&amp;1\\end{matrix}\\right]=\\left[\\begin{matrix}x&amp;y&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}\\cos\\theta&amp;-\\sin\\theta&amp;0\\\\\\sin\\theta&amp;\\cos\\theta&amp;0\\\\0&amp;0&amp;1\\end{matrix}\\right] \\] 假设在旋转的时候是以旋转中心为坐标原点的，旋转结束后还需要将坐标原点移到图像左上角，也就是还要进行一次变换。 \\[ \\left[\\begin{matrix}x&#39;&#39;&amp;y&#39;&#39;&amp;1\\end{matrix}\\right]=\\left[\\begin{matrix}x&#39;&amp;y&#39;&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}1&amp;0&amp;0\\\\0&amp;-1&amp;0\\\\left&amp;top&amp;1\\end{matrix}\\right]\\\\ =\\left[\\begin{matrix}x&#39;&amp;y&#39;&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}\\cos\\theta&amp;-\\sin\\theta&amp;0\\\\\\sin\\theta&amp;\\cos\\theta&amp;0\\\\0&amp;0&amp;1\\end{matrix}\\right]\\left[\\begin{matrix}1&amp;0&amp;0\\\\0&amp;-1&amp;0\\\\left&amp;top&amp;1\\end{matrix}\\right] \\] 在OpenCV中图像旋转首先根据旋转角度和旋转中心获取旋转矩阵，然后根据旋转矩阵进行变换，即可实现任意角度和任意中心的旋转效果。 1cv2.getRotationMatrix2D(center, angle, scale) 参数： center：旋转中心 angle：旋转角度 scale：缩放比例 返回： M：旋转矩阵 调用cv.warpAffine完成图像的旋转 示例代码 将图像以中心点旋转\\(90^\\circ\\) 1234567891011121314151617181920import numpy as npimport cv2 as cvimport matplotlib.pyplot as plt# 1 读取图像img = cv.imread(&quot;./image/image2.jpg&quot;)# 2 图像旋转rows,cols = img.shape[:2]# 2.1 生成旋转矩阵M = cv.getRotationMatrix2D((cols/2,rows/2),90,1)# 2.2 进行旋转变换dst = cv.warpAffine(img,M,(cols,rows))# 3 图像展示fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,8),dpi=100)axes[0].imshow(img1[:,:,::-1])axes[0].set_title(&quot;原图&quot;)axes[1].imshow(dst[:,:,::-1])axes[1].set_title(&quot;旋转后结果&quot;)plt.show() 仿射变换 仿射变换是指在几何中，一个向量空间进行一次线性变换并接上一个平移，变换为另一个向量空间。 图像的仿射变换，如下图所示，原始图像的点A，B和C与仿射图像三个点一一映射, 仍然形成三角形, 但形状已经大大改变，通过这样两组三点（感兴趣点）求出仿射变换， 接下来我们就能把仿射变换应用到图像中所有的点中，就完成了图像的仿射变换。 在OpenCV中，仿射变换的矩阵是一个2×3的矩阵 \\[ M= \\left[\\begin{matrix}A&amp;B\\end{matrix}\\right]= \\left[\\begin{matrix}a_{00}\\quad a_{01}\\quad b_0\\\\\\underbrace{a_{10}\\quad a_{11}}_A\\quad b_1\\end{matrix}\\right] \\] 其中子矩阵\\(A\\)是线性变换矩阵，子矩阵\\(B\\)是平移项，对于图像上的任一位置\\((x,y)\\)，仿射变换执行的是如下的操作： \\[ T_{affine}=A \\left[\\begin{matrix}x\\\\y\\end{matrix}\\right]+B=M \\left[\\begin{matrix}x\\\\y\\\\1\\end{matrix}\\right] \\] 注意：对于图像而言，宽度方向是x，高度方向是y，坐标的顺序和图像像素对应下标一致。所以原点的位置不是左下角而是左上角，y的方向也不是向上，而是向下。 在仿射变换中，原图中所有的平行线在结果图像中同样平行。为了创建这个矩阵我们需要从原图像中找到三个点以及他们在输出图像中的位置。然后cv2.getAffineTransform 会创建一个$ 2$ 的矩阵，最后这个矩阵会被传给函数cv2.warpAffine。 示例代码 12345678910111213141516171819202122import numpy as npimport cv2 as cvimport matplotlib.pyplot as plt# 1 图像读取img = cv.imread(&quot;./image/image2.jpg&quot;)# 2 仿射变换rows,cols = img.shape[:2]# 2.1 创建变换矩阵pts1 = np.float32([[50,50],[200,50],[50,200]])pts2 = np.float32([[100,100],[200,50],[100,250]])M = cv.getAffineTransform(pts1,pts2)# 2.2 完成仿射变换dst = cv.warpAffine(img,M,(cols,rows))# 3 图像显示fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,8),dpi=100)axes[0].imshow(img[:,:,::-1])axes[0].set_title(&quot;原图&quot;)axes[1].imshow(dst[:,:,::-1])axes[1].set_title(&quot;仿射后结果&quot;)plt.show() 透射变换 透射变换是视角变化的结果，是指利用透视中心、像点、目标点三点共线的条件，按透视旋转定律使承影面（透视面）绕迹线（透视轴）旋转某一角度，破坏原有的投影光线束，仍能保持承影面上投影几何图形不变的变换。 它的本质是将图像投影到一个新的视平面，其通用变换公式为： \\[ \\left[\\begin{matrix}x&#39;&amp;y&#39;&amp;z&#39;\\end{matrix}\\right]=\\left[\\begin{matrix}u&amp;v&amp;w\\end{matrix}\\right]\\left[\\begin{matrix}a_{00}\\quad a_{01}\\quad a_{02}\\\\a_{10}\\quad a_{11}\\quad a_{12}\\\\\\underbrace{a_{20}\\quad a_{21}\\quad a_{22}}_T\\end{matrix}\\right] \\] 其中\\((u,v)\\)是原始图像的像素坐标，\\(w\\)取值为1，\\((x=x&#39;/z&#39;,y=y&#39;/z&#39;)\\)是透射变换后的结果。\\(T\\)矩阵称为透视变换矩阵， \\[ T= \\left[\\begin{matrix}a_{00}&amp;a_{01}&amp;a_{02}\\\\a_{10}&amp;a_{11}&amp;a_{12}\\\\a_{20}&amp; a_{21}&amp; a_{22}\\end{matrix}\\right]= \\left[\\begin{matrix}T_{1}&amp;T_{2}\\\\T_{3}&amp;a_{22}\\end{matrix}\\right] \\] 其中：\\(T1\\)是图像进行线性变换，\\(T2\\)对图像进行平移，\\(T3\\)表示对图像进行投射变换，一般\\(a_{22}\\)取为1。 在opencv中，先找到四个点(其中任意三个点不共线)，然后获取透射变换矩阵\\(T\\)，再进行透射变换。通过函数cv.getPerspectiveTransform找到透射变换矩阵，将cv.warpPerspective应用于此3x3变换矩阵。 示例代码 12345678910111213141516171819202122import numpy as npimport cv2 as cvimport matplotlib.pyplot as plt# 1 读取图像img = cv.imread(&quot;./image/image2.jpg&quot;)# 2 透射变换rows,cols = img.shape[:2]# 2.1 创建变换矩阵pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])pts2 = np.float32([[100,145],[300,100],[80,290],[310,300]])T = cv.getPerspectiveTransform(pts1,pts2)# 2.2 进行变换dst = cv.warpPerspective(img,T,(cols,rows))# 3 图像显示fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,8),dpi=100)axes[0].imshow(img[:,:,::-1])axes[0].set_title(&quot;原图&quot;)axes[1].imshow(dst[:,:,::-1])axes[1].set_title(&quot;透射后结果&quot;)plt.show() 图像金字塔 图像金字塔是图像多尺度表达的一种，是一种以多分辨率来解释图像的有效但概念简单的结构。一幅图像的图像金字塔是一系列以金字塔形状（自下而上）逐步降低，且来源于同一张原始图的图像分辨率集合。其通过梯次向下采样获得，直到达到某个终止条件才停止采样。我们将一层一层的图像比喻成金字塔，层级越高，则图像越小，分辨率越低。 12cv.pyrUp(img) #对图像进行上采样cv.pyrDown(img) #对图像进行下采样 示例代码 1234567891011121314import numpy as npimport cv2 as cvimport matplotlib.pyplot as plt# 1 图像读取img = cv.imread(&quot;./image/image2.jpg&quot;)# 2 进行图像采样up_img = cv.pyrUp(img) # 上采样操作img_1 = cv.pyrDown(img) # 下采样操作# 3 图像显示cv.imshow(&#x27;enlarge&#x27;, up_img)cv.imshow(&#x27;original&#x27;, img)cv.imshow(&#x27;shrink&#x27;, img_1)cv.waitKey(0)cv.destroyAllWindows() 形态学操作 形态学转换是基于图像形状的一些简单操作。它通常在二进制图像上执行。腐蚀和膨胀是两个基本的形态学运算符。然后它的变体形式如开运算，闭运算，礼帽黑帽等。 连通性 在图像中，最小的单位是像素，每个像素周围有8个邻接像素，常见的邻接关系有3种：4邻接、8邻接和D邻接。分别如下图所示： 4邻接：像素\\(p(x,y)\\)的4邻域是(x+1,y);(x-1,y);(x,y+1);(x,y-1)，用\\(N_4(p)\\)表示像素p的4邻接 D邻接：像素\\(p(x,y)\\)的D邻域是(x+1,y+1);(x+1,y-1);(x-1,y+1);(x-1,y-1)，用\\(N_D(p)\\)表示像素p的D邻域 8邻接：像素\\(p(x,y)\\)的8邻域是4邻域的点+D邻域的点，用\\(N_8(p)\\)表示像素p的8邻域 连通性是描述区域和边界的重要概念，两个像素连通的两个必要条件是： 两个像素的位置是否相邻 两个像素的灰度值是否满足特定的相似性准则(或者是否相等) 根据连通性的定义，有4连通、8连通和m连通三种。 4连通：对于具有值V的像素p和q，如果q在集合\\(N_4(p)\\)中，则称这两个像素是4连通。 8连通：对于具有值V的像素p和q，如果q在集合\\(N_8(p)\\)中，则称这两个像素是8连通。 m连通：对于具有值V的像素p和q，如果q在集合\\(N_4(p)\\)中或q在集合\\(N_D(p)\\)中，并且\\(N_4(p)\\)与\\(N_4(q)\\)的交集为空(没有值V的像素)，则称这两个像素是m连通。 腐蚀和膨胀 腐蚀和膨胀都是针对白色部分（高亮部分）而言的。 腐蚀是原图中的高亮区域被蚕食，效果图拥有比原图更小的高亮区域；腐蚀是求局部最小值的操作，作用是消除物体边界点，使目标缩小，可以消除小于结构元素的噪声点。 膨胀是使图像中高亮部分扩张，效果图拥有比原图更大的高亮区域；膨胀是求局部最大值的操作，作用是将与物体接触的所有背景点合并到物体中，使目标增大，可添补目标中的孔洞。 腐蚀的具体操作是：用结构元素中的每一个像素与其覆盖的像素做“与”操作，如果都为1，则该像素为1，否则为0。如下图所示，结构A被结构B腐蚀后 1cv.erode(img,kernel,iterations) 参数： img：要处理的图像 kernel：核结构 iterations：腐蚀的次数，默认是1 膨胀的具体操作是：用结构元素中的每一个像素与其覆盖的像素做“与”操作，如果都为0，则该像素为0，否则为1。如下图所示，结构A被结构B腐蚀后 1cv.dilate(img,kernel,iterations) 参数： img：要处理的图像 kernel：核结构 iterations：腐蚀的次数，默认是1 示例代码 使用一个\\(5\\times5\\)的卷积核实现腐蚀和膨胀的运算 123456789101112131415161718192021import numpy as npimport cv2 as cvimport matplotlib.pyplot as plt# 1 读取图像img = cv.imread(&quot;./image/image3.png&quot;)# 2 创建核结构kernel = np.ones((5, 5), np.uint8)# 3 图像腐蚀和膨胀erosion = cv.erode(img, kernel) # 腐蚀dilate = cv.dilate(img,kernel) # 膨胀# 4 图像展示fig,axes=plt.subplots(nrows=1,ncols=3,figsize=(10,8),dpi=100)axes[0].imshow(img)axes[0].set_title(&quot;原图&quot;)axes[1].imshow(erosion)axes[1].set_title(&quot;腐蚀后结果&quot;)axes[2].imshow(dilate)axes[2].set_title(&quot;膨胀后结果&quot;)plt.show() 开、闭运算 开运算和闭运算是将腐蚀和膨胀按照一定的次序进行处理。 但这两者并不是可逆的，即先开后闭并不能得到原来的图像。 开运算是先腐蚀后膨胀，作用是消除噪点，去除小的干扰块，而不影响原来的图像。 闭运算是先膨胀后腐蚀，作用是消除闭合物体里面的孔洞，填充闭合区域。 1cv.morphologyEx(img, op, kernel) 参数： img：要处理的图像 op: 处理方式：若进行开运算，则设为cv.MORPH_OPEN，若进行闭运算，则设为cv.MORPH_CLOSE Kernel：核结构 示例代码 使用\\(10\\times10\\)的卷积核实现开、闭运算。 12345678910111213141516171819202122import numpy as npimport cv2 as cvimport matplotlib.pyplot as plt# 1 读取图像img1 = cv.imread(&quot;./image/image5.png&quot;)img2 = cv.imread(&quot;./image/image6.png&quot;)# 2 创建核结构kernel = np.ones((10, 10), np.uint8)# 3 图像的开闭运算cvOpen = cv.morphologyEx(img1,cv.MORPH_OPEN,kernel) # 开运算cvClose = cv.morphologyEx(img2,cv.MORPH_CLOSE,kernel)# 闭运算# 4 图像展示fig,axes=plt.subplots(nrows=2,ncols=2,figsize=(10,8))axes[0,0].imshow(img1)axes[0,0].set_title(&quot;原图&quot;)axes[0,1].imshow(cvOpen)axes[0,1].set_title(&quot;开运算结果&quot;)axes[1,0].imshow(img2)axes[1,0].set_title(&quot;原图&quot;)axes[1,1].imshow(cvClose)axes[1,1].set_title(&quot;闭运算结果&quot;)plt.show() 礼帽和黑帽 礼帽运算是原图像与开运算的结果图之差\\(dst=tophat(src,element)=src-open(src,element)\\)， 因为开运算带来的结果是放大了裂缝或者局部低亮度的区域。 礼帽运算后的效果图突出了比原图轮廓周围的区域更明亮的区域，这一操作和选择的核的大小相关。 作用：用来分离比邻近点亮一些的斑块。当一幅图像具有大幅的背景的时候，而微小物品比较有规律的情况下，可以使用礼帽运算进行背景提取。 黑帽运算是闭运算的结果图与原图像之差\\(dst=blackhat(src,element)=close(src,element)-src\\)， 黑帽运算后的效果图突出了比原图轮廓周围的区域更暗的区域， 作用：用来分离比邻近点暗一些的斑块。 1cv.morphologyEx(img, op, kernel) 参数： img：要处理的图像 op：处理方式： Kernel：核结构 示例代码 12345678910111213141516171819202122import numpy as npimport cv2 as cvimport matplotlib.pyplot as plt# 1 读取图像img1 = cv.imread(&quot;./image/image5.png&quot;)img2 = cv.imread(&quot;./image/image6.png&quot;)# 2 创建核结构kernel = np.ones((10, 10), np.uint8)# 3 图像的礼帽和黑帽运算cvOpen = cv.morphologyEx(img1,cv.MORPH_TOPHAT,kernel) # 礼帽运算cvClose = cv.morphologyEx(img2,cv.MORPH_BLACKHAT,kernel)# 黑帽运算# 4 图像显示fig,axes=plt.subplots(nrows=2,ncols=2,figsize=(10,8))axes[0,0].imshow(img1)axes[0,0].set_title(&quot;原图&quot;)axes[0,1].imshow(cvOpen)axes[0,1].set_title(&quot;礼帽运算结果&quot;)axes[1,0].imshow(img2)axes[1,0].set_title(&quot;原图&quot;)axes[1,1].imshow(cvClose)axes[1,1].set_title(&quot;黑帽运算结果&quot;)plt.show() 图像平滑 图像平滑从信号处理的角度看就是去除其中的高频信息，保留低频信息。因此可以对图像实施低通滤波。低通滤波可以去除图像中的噪声，对图像进行平滑。根据滤波器的不同可分为均值滤波，高斯滤波，中值滤波， 双边滤波。 图像噪声 由于图像采集、处理、传输等过程不可避免的会受到噪声的污染，妨碍人们对图像理解及分析处理。常见的图像噪声有高斯噪声、椒盐噪声等。 椒盐噪声 椒盐噪声也称为脉冲噪声，是图像中经常见到的一种噪声，它是一种随机出现的白点或者黑点，可能是亮的区域有黑色像素或是在暗的区域有白色像素。 椒盐噪声的成因可能是影像讯号受到突如其来的强烈干扰而产生、类比数位转换器或位元传输错误等。例如失效的感应器导致像素值为最小值，饱和的感应器导致像素值为最大值。 高斯噪声 高斯噪声是指噪声密度函数服从高斯分布的一类噪声。在数字图像中的高斯噪声的主要来源出现在采集期间， 由于不良照明和/或高温引起的传感器噪声。 高斯随机变量\\(x\\)的概率密度函数 \\[ p(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\] 其中\\(z\\)表示灰度值，\\(\\mu\\)表示\\(x\\)的平均值或期望值，\\(\\sigma\\)表示\\(x\\)的标准差。标准差的平方\\(\\sigma^2\\)称为\\(x\\)的方差。高斯函数的曲线如下图所示。 均值滤波 采用均值滤波模板对图像噪声进行滤除。令\\(S_{xy}\\)表示中心在\\((x, y)\\)点，尺寸为\\(m\\times n\\) 的矩形子图像窗口的坐标组。 均值滤波器可表示为 \\[ \\hat{f}=\\frac{1}{mn}\\sum_{(s,t)\\in S_{xy}}g(s,t) \\] 由一个归一化卷积框完成的。它只是用卷积框覆盖区域所有像素的平均值来代替中心元素。 例如，\\(3\\times3\\)标准化的均值滤波如下所示： \\[ K=\\frac{1}{9}\\left[\\begin{matrix}1&amp;1&amp;1\\\\1&amp;1&amp;1\\\\1&amp;1&amp;1\\end{matrix}\\right] \\] 均值滤波的优点是算法简单，计算速度较快，缺点是在去噪的同时去除了很多细节部分，将图像变得模糊。 1cv.blur(src, ksize, anchor, borderType) 参数: src：输入图像 ksize：卷积核的大小 anchor：默认值 (-1,-1) ，表示核中心 borderType：边界类型 示例代码 1234567891011121314import cv2 as cvimport numpy as npfrom matplotlib import pyplot as plt# 1 图像读取img = cv.imread(&#x27;./image/dogsp.jpeg&#x27;)# 2 均值滤波blur = cv.blur(img,(5,5))# 3 图像显示plt.figure(figsize=(10,8),dpi=100)plt.subplot(121),plt.imshow(img[:,:,::-1]),plt.title(&#x27;原图&#x27;)plt.xticks([]), plt.yticks([])plt.subplot(122),plt.imshow(blur[:,:,::-1]),plt.title(&#x27;均值滤波后结果&#x27;)plt.xticks([]), plt.yticks([])plt.show() 高斯滤波 二维高斯是构建高斯滤波器的基础，其概率分布函数为 \\[ G(x,y) = \\frac{1}{\\sigma_x\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma_y^2}}\\frac{1}{\\sigma_y\\sqrt{2\\pi}}e^{-\\frac{(y-\\mu)^2}{2\\sigma_y^2}}= \\frac{1}{2\\pi\\sigma^2}e^{-\\frac{(x^2+y^2)}{2\\sigma^2}} \\] 上述公式做了一些取值的处理：我们令\\(\\sigma_x=\\sigma_y\\)，越接近中心，取值越大，越远离中心，取值越小。计算平滑结果时，将“中心点”作为原点（\\(\\mu=0\\)），其他点按照其在正态曲线上的位置，分配权重，就可以得到一个加权平均值。 高斯平滑的流程： 确定权重矩阵 假定中心点的坐标是（0,0），距离它最近的8个点的坐标（\\(3\\times3\\)的卷积核） 计算权重矩阵， 设定\\(\\sigma\\)的值，根据高斯概率分布函数\\(G(x,y)\\)计算这9个点， 计算这9个点的总和， 将9个值分别除以权重总和，得到最终的权重矩阵。 计算高斯模糊 假设现有9个像素点，灰度值（0-255） 每个点乘以对应的权重值 将这9个值加起来，就是中心点的高斯模糊的值。 对所有点重复这个过程，就得到了高斯模糊后的图像。 如果原图是彩色图片，对RGB三个通道分别做高斯平滑。 1cv2.GaussianBlur(src,ksize,sigmaX,sigmay,borderType) 参数： src：输入图像 ksize：高斯卷积核的大小 sigmaX：水平方向的标准差 sigmaY：垂直方向的标准差，默认值为0，表示与sigmaX相同 borderType：填充边界类型 示例代码 1234567891011121314import cv2 as cvimport numpy as npfrom matplotlib import pyplot as plt# 1 图像读取img = cv.imread(&#x27;./image/dogGasuss.jpeg&#x27;)# 2 高斯滤波blur = cv.GaussianBlur(img,(3,3),1)# 3 图像显示plt.figure(figsize=(10,8),dpi=100)plt.subplot(121),plt.imshow(img[:,:,::-1]),plt.title(&#x27;原图&#x27;)plt.xticks([]), plt.yticks([])plt.subplot(122),plt.imshow(blur[:,:,::-1]),plt.title(&#x27;高斯滤波后结果&#x27;)plt.xticks([]), plt.yticks([])plt.show() 中值滤波 中值滤波是一种典型的非线性滤波技术，基本思想是用像素点邻域灰度值的中值来代替该像素点的灰度值。它对椒盐噪声（salt-and-pepper noise）来说尤其有用，因为它不依赖于邻域内那些与典型值差别很大的值。 1cv.medianBlur(src, ksize ) 参数： src：输入图像 ksize：卷积核的大小 示例代码 1234567891011121314import cv2 as cvimport numpy as npfrom matplotlib import pyplot as plt# 1 图像读取img = cv.imread(&#x27;./image/dogsp.jpeg&#x27;)# 2 中值滤波blur = cv.medianBlur(img,5)# 3 图像展示plt.figure(figsize=(10,8),dpi=100)plt.subplot(121),plt.imshow(img[:,:,::-1]),plt.title(&#x27;原图&#x27;)plt.xticks([]), plt.yticks([])plt.subplot(122),plt.imshow(blur[:,:,::-1]),plt.title(&#x27;中值滤波后结果&#x27;)plt.xticks([]), plt.yticks([])plt.show()","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"https://liujk6525.github.io/categories/OpenCV/"}],"tags":[{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"OpenCV基本操作","slug":"OpenCV基本操作","date":"2023-05-17T12:09:11.000Z","updated":"2023-05-26T05:35:00.558Z","comments":true,"path":"OpenCV/OpenCV基本操作/","link":"","permalink":"https://liujk6525.github.io/OpenCV/OpenCV%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","excerpt":"Imgproc（图像处理模块） 图像处理模块包括：图像的读取、显示、保存、几何运算等。","text":"Imgproc（图像处理模块） 图像处理模块包括：图像的读取、显示、保存、几何运算等。 图像的基础操作 12import numpy as npimport cv2 as cv 图像读取、显示、保存 读取图像 12# 以灰度图的形式读取图像，可以使用1、0或者-1来替代下面三个标志img = cv.imread(&#x27;./messi5.jpg&#x27;,0) 参数： 要读取的图像，./表示当前文件夹 读取方式的标志 cv.IMREAD*COLOR：以彩色模式加载图像，任何图像的透明度都将被忽略。这是默认参数。 cv.IMREAD*GRAYSCALE：以灰度模式加载图像 cv.IMREAD_UNCHANGED：包括alpha通道的加载图像模式。 显示图像 12345# opencv中显示cv.imshow(&#x27;./image&#x27;,img)cv.waitKey(0)# matplotlib中展示plt.imshow(img[:,:,::-1]) # matplotlib中rgb和opencv是正好反着的 参数： 显示图像的窗口名称，以字符串类型表示 要加载的图像 注意：在调用显示图像的API后，要调用cv.waitKey()给图像绘制留下时间，否则窗口会出现无响应情况，并且图像无法显示出来。 保存图像 1cv.imwrite(&#x27;./messigray.png&#x27;,img) 参数： 文件名，保存位置，./表示当前文件夹 要保存的图像 绘制几何图形 绘制直线 1cv.line(img,start,end,color,thickness) 参数： img:要绘制直线的图像 start,end: 直线的起点和终点 color: 线条的颜色 thickness: 线条宽度 绘制圆形 1cv.circle(img,centerpoint, r, color, thickness) 参数： img:要绘制圆形的图像 centerpoint, r: 圆心和半径 color: 线条的颜色 thickness: 线条宽度，为-1时生成闭合图案并填充颜色 绘制矩形 1cv.rectangle(img,leftupper,rightdown,color,thickness) 参数： img:要绘制矩形的图像 leftupper, rightdown: 矩形的左上角和右下角坐标 color: 线条的颜色 thickness: 线条宽度 添加文字 1cv.putText(img,text,station, font, fontsize,color,thickness,cv.LINE_AA) 参数： img: 图像 text：要写入的文本数据 station：文本的放置位置 font：字体 fontsize :字体大小 效果展示 生成一个全黑的图像，然后在里面绘制图像并添加文字 123456789101112131415import numpy as npimport cv2 as cvimport matplotlib.pyplot as plt# 1 创建一个空白的图像img = np.zeros((512,512,3), np.uint8)# 2 绘制图形cv.line(img,(0,0),(511,511),(255,0,0),5)cv.rectangle(img,(384,0),(510,128),(0,255,0),3)cv.circle(img,(447,63), 63, (0,0,255), -1)font = cv.FONT_HERSHEY_SIMPLEXcv.putText(img,&#x27;OpenCV&#x27;,(10,500), font, 4,(255,255,255),2,cv.LINE_AA)# 3 图像展示plt.imshow(img[:,:,::-1])plt.title(&#x27;匹配结果&#x27;), plt.xticks([]), plt.yticks([])plt.show() 获取并修改像素点 可以通过行和列的坐标值获取该像素点的像素值。对于BGR图像，它返回一个蓝，绿，红值的数组。对于灰度图像，仅返回相应的强度值。使用相同的方法对像素值进行修改。 123456# 获取某个像素点的值px = img[100,100]# 仅获取蓝色通道的强度值blue = img[100,100,0]# 修改某个位置的像素值img[100,100] = [255,255,255] 图像的属性 图像属性包括行数，列数和通道数，图像数据类型，像素数等。 图像通道的拆分与合并 有时需要在B，G，R通道图像上单独工作,此时需要将BGR图像分割为单个通道。或者可能需要将这些单独的通道合并到BGR图像。可以通过以下方式完成。 1234# 通道拆分b,g,r = cv.split(img)# 通道合并img = cv.merge((b,g,r)) 色彩空间的改变 OpenCV中有150多种颜色空间转换方法。最广泛使用的转换方法有两种，\\(BGR \\leftrightarrow Gray\\)和\\(BGR \\leftrightarrow HSV\\)。 1cv.cvtColor(input_image，flag) 参数： input_image: 进行颜色空间转换的图像 flag: 转换类型 cv.COLOR_BGR2GRAY : \\(BGR \\leftrightarrow Gray\\) cv.COLOR_BGR2HSV: \\(BGR \\leftrightarrow HSV\\) 算数操作 图像加法 使用OpenCV的cv.add()函数把两幅图像相加，或者可以简单地通过numpy操作添加两个图像，如\\(res = img_1 + img_2\\)。两个图像应该具有相同的大小和类型，或者第二个图像可以是标量值。 123456x = np.uint8([250])y = np.uint8([10])print( cv.add(x,y) ) # 250+10 = 260 =&gt; 255[[255]]print( x+y ) # 250+10 = 260 % 256 = 4[4] **注意：OpenCV的加法是饱和操作，而Numpy添加是模运算。这种区别在对两幅图像进行加法时会很明显。OpenCV 的结果会更好一点。所以我们尽量使用 OpenCV中的函数。 将两幅图像进行加法操作来比较其中的区别： 12345678910111213141516171819import numpy as npimport cv2 as cvimport matplotlib.pyplot as plt# 1 读取图像img1 = cv.imread(&quot;./view.jpg&quot;)img2 = cv.imread(&quot;./rain.jpg&quot;)# 2 加法操作img3 = cv.add(img1,img2) # cv中的加法img4 = img1+img2 # 直接相加# 3 图像显示fig,axes=plt.subplots(nrows=1,ncols=2,figsize=(10,8),dpi=100)axes[0].imshow(img3[:,:,::-1])axes[0].set_title(&quot;cv中的加法&quot;)axes[1].imshow(img4[:,:,::-1])axes[1].set_title(&quot;直接相加&quot;)plt.show() 结果如下所示： 图像融合 这其实也是加法，但是不同的是两幅图像的权重不同，这就会给人一种混合或者透明的感觉。图像混合的计算公式如下： \\[ g(x)=(1−\\alpha)f_0(x)+\\alpha f_1(x)+\\gamma \\] 通过修改\\(\\alpha\\)的值\\((0\\rightarrow1)\\)，可以实现非常炫酷的混合。 现在我们把两幅图混合在一起。第一幅图的权重是0.7，第二幅图的权重是0.3。函数cv2.addWeighted()可以按下面的公式对图片进行混合操作。 \\[ dst = (1-\\alpha)\\cdot img_1 + \\alpha\\cdot img_2 + \\gamma \\] 这里\\(\\gamma\\)取为0。 123456789101112131415import numpy as npimport cv2 as cvimport matplotlib.pyplot as plt# 1 读取图像img1 = cv.imread(&quot;view.jpg&quot;)img2 = cv.imread(&quot;rain.jpg&quot;)# 2 图像混合img3 = cv.addWeighted(img1,0.7,img2,0.3,0)# 3 图像显示plt.figure(figsize=(8,8))plt.imshow(img3[:,:,::-1])plt.show() 注意：这里都要求两幅图像是相同大小的。 参考 黑马程序员人工智能教程_10小时学会图像处理OpenCV入门教程","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"https://liujk6525.github.io/categories/OpenCV/"}],"tags":[{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"OpenCV简介","slug":"OpenCV简介","date":"2023-05-17T10:59:27.000Z","updated":"2023-05-26T05:22:33.644Z","comments":true,"path":"OpenCV/OpenCV简介/","link":"","permalink":"https://liujk6525.github.io/OpenCV/OpenCV%E7%AE%80%E4%BB%8B/","excerpt":"图像处理简介 图像 图像是人类视觉的基础，是自然景物的客观反映，是人类认识世界和人类本身的重要源泉。“图”是物体反射或透射光的分布，“像“是人的视觉系统所接受的图在人脑中所形版的印象或认识，照片、绘画、剪贴画、地图、书法作品、手写汉学、传真、卫星云图、影视画面、X光片、脑电图、心电图等都是图像","text":"图像处理简介 图像 图像是人类视觉的基础，是自然景物的客观反映，是人类认识世界和人类本身的重要源泉。“图”是物体反射或透射光的分布，“像“是人的视觉系统所接受的图在人脑中所形版的印象或认识，照片、绘画、剪贴画、地图、书法作品、手写汉学、传真、卫星云图、影视画面、X光片、脑电图、心电图等都是图像 模拟图像和数字图像 图像起源于1826年前后法国科学家Joseph Nicéphore Niépce发明的第一张可永久保存的照片，属于模拟图像。模拟图像又称连续图像，它通过某种物理量（如光、电等）的强弱变化来记录图像亮度信息，所以是连续变换的。模拟信号的特点是容易受干扰，如今已经基本全面被数字图像替代。 在第一次世界大战后，1921年美国科学家发明了Bartlane System，并从伦敦传到纽约传输了第一幅数字图像，其亮度用离散数值表示，将图片编码成5个灰度级，如下图所示，通过海底电缆进行传输。在发送端图片被编码并使用打孔带记录，通过系统传输后在接收方使用特殊的打印机恢复成图像。 1950年左右，计算机被发明，数字图像处理学科正式诞生。 计算机采用0/1编码的系统，数字图像是利用0/1来记录信息，我们平常接触的图像都是8位数图像，包含0～255灰度，其中0代表最黑，1代表最白。如下展现的是一个灰度图。 图像的分类 二值图像： 一幅二值图像的二维矩阵仅由0、1两个值构成，0代表黑色，1代白色。由于每一像素（矩阵中每一元素）取值仅有0、1两种可能，所以计算机中二值图像的数据类型通常为1个二进制位。二值图像通常用于文字、线条图的扫描识别（OCR）和掩膜图像的存储。 灰度图： 每个像素只有一个采样颜色的图像，这类图像通常显示为从最暗黑色到最亮的白色的灰度，尽管理论上这个采样可以任何颜色的不同深浅，甚至可以是不同亮度上的不同颜色。灰度图像与黑白图像不同，在计算机图像领域中黑白图像只有黑色与白色两种颜色；但是，灰度图像在黑色与白色之间还有许多级的颜色深度。灰度图像经常是在单个电磁波频谱如可见光内测量每个像素的亮度得到的，用于显示的灰度图像通常用每个采样像素8位的非线性尺度来保存，这样可以有\\(2^8=256\\)级灰度（如果用\\(16\\)位，则有\\(2^16=65536\\)级）。 彩色图： 每个像素通常是由红（R）、绿（G）、蓝（B）三个分量来表示的，分量介于（0~255）。RGB图像与索引图像一样都可以用来表示彩色图像。与索引图像一样，它分别用红（R）、绿（G）、蓝（B）三原色的组合来表示每个像素的颜色。但与索引图像不同的是，RGB图像每一个像素的颜色值（由RGB三原色表示）直接存放在图像矩阵中，由于每一像素的颜色需由R、G、B三个分量来表示，M、N分别表示图像的行列数，三个M x N的二维矩阵分别表示各个像素的R、G、B三个颜色分量。RGB图像的数据类型一般为8位无符号整形，通常用于表示和存放真彩色图像。 OpenCV简介 OpenCV是一款由Intel公司俄罗斯团队发起并参与和维护的一个计算机视觉处理开源软件库，支持与计算机视觉和机器学习相关的众多算法，并且正在日益扩展。 OpenCV-Python OpenCV-Python是原始OpenCV C++实现的Python包装器。同时它使用Numpy，这是一个高度优化的数据库操作库，具有MATLAB风格的语法。所有OpenCV数组结构都转换为Numpy数组。这也使得与使用Numpy的其他库（如SciPy和Matplotlib）集成更容易。 OpenCV部署 安装OpenCV之前需要先安装numpy, matplotlib。 创建Python虚拟环境 安装OpenCV-Python, 由于一些经典的算法被申请了版权，新版本有很大的限制，所以选用3.4.3以下的版本 1pip install opencv-python==3.4.2.17 测试是否安装成功，运行以下代码无报错，则说明安装成功。 12345import cv2# 读一个图片并进行显示(图片路径需自己指定)lena=cv2.imread(&quot;1.jpg&quot;)cv2.imshow(&quot;image&quot;,lena)cv2.waitKey(0) 需要利用SIFT和SURF等进行特征提取时，还需要安装： 1pip install opencv-contrib-python==3.4.2.17 OpenCV的模块 模块 功能 描述 Core 核心模块，包含最基础的操作 绘图函数、数组操作相关函数 HighGUI 高层图像用户界面 视频与图像的读取、显示、存储等接口 Imgproc 图像处理模块 图像处理的基础方法：包括图像滤波、图像的几何变换、平滑、阈值分割、形态学处理、边缘检测、目标检测、运动分析和对象跟踪等 Featured2d 2D特征检测模块 用于提取图像特征以及特征匹配，nonfree模块实现了一些专利算法，如sift特征。 Objdectect 目标检测模块 基于Haar、LBP特征的人脸检测，基于HOG的行人、汽车等目标检测，分类器使用Cascade Classification（级联分类）和Latent SVM等 Video 视频处理模块 针对视频处理，如背景分离，前景检测、对象跟踪等 Calib3d 3D重建模块 主要是相机校准和三维重建相关的内容。包含了基本的多视角几何算法，单个立体摄像头标定，物体姿态估计，立体相似性算法，3D信息的重建等。 ML 机器学习模块 SVM，决策树，Boosting等 FLANN 最近邻搜索模块 包含快速近似最近邻搜索FLANN 和聚类Clustering算法 Stitching 图像拼接模块 实现了图像拼接功能 Photo 计算图像学 包含图像修复和图像去噪两部分 G-API G-API模块 包含超高效的图像处理pipeline引擎 参考 黑马程序员人工智能教程_10小时学会图像处理OpenCV入门教程","categories":[{"name":"OpenCV","slug":"OpenCV","permalink":"https://liujk6525.github.io/categories/OpenCV/"}],"tags":[{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"}]},{"title":"轨迹优化-闭式求解","slug":"轨迹优化-闭式求解","date":"2023-05-16T02:20:21.000Z","updated":"2023-05-26T05:22:33.654Z","comments":true,"path":"轨迹优化/轨迹优化-闭式求解/","link":"","permalink":"https://liujk6525.github.io/%E8%BD%A8%E8%BF%B9%E4%BC%98%E5%8C%96/%E8%BD%A8%E8%BF%B9%E4%BC%98%E5%8C%96-%E9%97%AD%E5%BC%8F%E6%B1%82%E8%A7%A3/","excerpt":"如果QP问题只有等式约束，没有不等式约束，可以采用闭式求解的方式。","text":"如果QP问题只有等式约束，没有不等式约束，可以采用闭式求解的方式。 构建等式约束方程 还是一段复杂的轨迹按照时间划分成\\(m\\)段，一共有\\(m+1\\)个点，其中\\(0\\)是起点，\\(m\\)是目标点，\\(m-1\\)个中间点。每段多项式轨迹都构成 \\[ A_ip_i=d_i,\\quad A_i=\\left[\\begin{matrix} A_0\\\\A_T \\end{matrix}\\right]_i,\\quad d_i=\\left[\\begin{matrix} d_0\\\\d_T \\end{matrix}\\right]_i \\] 其中，\\(d_o,d_T\\)是第\\(i\\)段多项式轨迹的起点和终点的各阶导数组成的向量。这里只考虑了位置速度和加速度。 \\[ \\underbrace{A_{total}}_{6m \\times m(n+1)} \\underbrace{ \\left[ \\begin{matrix} p_1 \\\\ \\vdots \\\\ p_m \\\\ \\end{matrix} \\right]}_{m(n+1) \\times 1} = \\left[ \\begin{matrix} d_1 \\\\ \\vdots \\\\ d_m \\\\ \\end{matrix} \\right] =\\underbrace{ \\left[ \\begin{matrix} p_1(t_0)\\\\ v_1(t_0)\\\\ a_1(t_0)\\\\ p_1(t_1)\\\\ v_1(t_1)\\\\ a_1(t_1)\\\\ \\vdots \\\\ p_m(t_{m-1})\\\\ v_m(t_{m-1})\\\\ a_m(t_{m-1})\\\\ p_m(t_m)\\\\ v_m(t_m)\\\\ a_m(t_m)\\\\ \\end{matrix} \\right]}_{6m \\times 1} \\] 目标是要求解参数\\(p\\) \\[ p=A^{-1}d \\] 消除重复变量 考虑到连续性(这里假设P、V、A连续)，向量中很多变量重复了 \\[ p_i(t_i)=p_{i+1}(t_i),~~v_i(t_i)=v_{i+1}(t_i),~~a_i(t_i)=a_{i+1}(t_i) \\] 连续性约束不是直接加到等式约束方程中。而是通过一个映射矩阵\\(M\\)将一个变量映射到两个重复的变量上。 \\[ \\underbrace{ \\left[ \\begin{matrix} d_1 \\\\ \\vdots \\\\ d_k \\\\ \\end{matrix} \\right]}_{6m\\times1}= \\underbrace{ \\left[ \\begin{matrix} 1\\\\ &amp;1\\\\ &amp;&amp;1\\\\ &amp;&amp;&amp;1\\\\ &amp;&amp;&amp;&amp;1\\\\ &amp;&amp;&amp;&amp;&amp;1\\\\ &amp;&amp;&amp;1\\\\ &amp;&amp;&amp;&amp;1\\\\ &amp;&amp;&amp;&amp;&amp;1\\\\ &amp;&amp;&amp;&amp;&amp;&amp;1\\\\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;1\\\\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;1\\\\ &amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;\\ddots \\end{matrix} \\right]}_{M} \\underbrace{ \\left[\\begin{matrix} p(t_0)\\\\ v(t_0)\\\\ a(t_0)\\\\ p(t_1)\\\\ v(t_1)\\\\ a(t_1)\\\\ p(t_2)\\\\ v(t_2)\\\\ a(t_2)\\\\ \\vdots\\\\ p(t_m)\\\\ v(t_m)\\\\ a(t_m)\\\\ \\end{matrix} \\right]}_{3(m+1)\\times 1} \\] 即\\(d=Md&#39;\\) 向量元素置换 接着把已知参数 \\(d_F\\)和未知参数\\(d_P\\)重新排列，可以左乘一个置换矩阵\\(C\\)，使得\\(d&#39;=C\\left[\\begin{matrix}d_F\\\\d_P\\end{matrix}\\right]\\) 转成无约束优化问题 所以 \\(d=MC\\left[\\begin{matrix}d_F\\\\d_P\\end{matrix}\\right]\\) \\[ p=A^{-1}d=\\underbrace{A^{-1}MC}_K\\left[\\begin{matrix}d_F\\\\d_P\\end{matrix}\\right] = K\\left[\\begin{matrix}d_F\\\\d_P\\end{matrix}\\right] \\] 将\\(p\\)代入优化函数 \\[ \\min p^TQp\\\\ \\] \\[ =\\left[\\begin{matrix}d_F\\\\d_P\\end{matrix}\\right]^T\\underbrace{K^TQK}_R\\left[\\begin{matrix}d_F\\\\d_P\\end{matrix}\\right] \\] \\[ =\\left[\\begin{matrix}d_F\\\\d_P\\end{matrix}\\right]^T \\left[\\begin{matrix}R_{FF} &amp; R_{FP}\\\\R_{PF}&amp;R_{PP}\\end{matrix}\\right] \\left[\\begin{matrix}d_F\\\\d_P\\end{matrix}\\right] \\] \\[ =d_F^TR_{FF}d_F+d_F^TR_{FP}d_P+d_P^TR_{PF}d_F+d_P^TR_{PP}d_P \\] \\[ =d_F^TR_{FF}d_F+2d_F^TR_{FP}d_P+d_P^TR_{PP}d_P \\] 令优化函数\\(mibn\\)对\\(d_P\\)求导，并且令其导数等于0 \\[ \\rightarrow 2d_F^TR_{FP}+2R_{PP}d_P=0\\quad(R_{PP}^T=R_{PP})\\\\ \\rightarrow d^*_p = -R_{PP}^{-1}R_{FP}^Td_F \\] 总结 先确定轨迹阶数(这里是用的5阶，因为A矩阵要为方形阵，所以\\(6m=m(n+1)\\rightarrow n=5\\))，再确定\\(d\\)中的约束量(p、v、a)，进而根据各段的时间分配求得\\(A_{total}\\) 根据连续性约束构造映射矩阵\\(M\\)，并确定\\(d\\)中哪些量是已知的(fix/specified)，哪些量是未知的(free/unspecified)，进而构造置换矩阵\\(C\\)，并求得\\(K=A^{-1}MC\\)。 计算目标函数中的Q矩阵，并计算\\(R=K^TQK\\)，根据已知参数(fix)的长度将\\(R\\)拆分成\\(R_{FF},R_{FR},R_{FR},R_{PP}\\)四小块。 根据\\(d^*_p = -R_{PP}^{-1}R_{FP}^Td_F\\)计算\\(d^*_p\\) 根据\\(p=K\\left[\\begin{matrix}d_F\\\\d_p\\end{matrix}\\right]\\)计算得到轨迹参数\\(p\\) 参考 Richter C, Bry A, Roy N. Polynomial trajectory planning for aggressive quadrotor flight in dense indoor environments[C]//Robotics Research: The 16th International Symposium ISRR. Springer International Publishing, 2016: 649-666. Minimum Snap轨迹规划详解（3）闭式求解 机器人路径规划、轨迹优化系列课程","categories":[{"name":"轨迹优化","slug":"轨迹优化","permalink":"https://liujk6525.github.io/categories/%E8%BD%A8%E8%BF%B9%E4%BC%98%E5%8C%96/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://liujk6525.github.io/tags/Matlab/"}]},{"title":"轨迹优化-MinimumSnap","slug":"轨迹优化-MinimumSnap","date":"2023-05-15T06:16:00.000Z","updated":"2023-05-26T05:22:33.655Z","comments":true,"path":"轨迹优化/轨迹优化-MinimumSnap/","link":"","permalink":"https://liujk6525.github.io/%E8%BD%A8%E8%BF%B9%E4%BC%98%E5%8C%96/%E8%BD%A8%E8%BF%B9%E4%BC%98%E5%8C%96-MinimumSnap/","excerpt":"基础知识 二次型 含有n个变量\\(x=x_1,x_2,\\cdots,x_{n-1},x_{n}\\)的二次齐次函数 \\[ f(x_1,x_2,...,x_n)=a11x_1^2+a22x_2^2+\\cdots+a_{nn}x_n^2 \\] 称为二次型。取\\(a_{ij}=a_{ji}\\)，则有\\(2a_{ij}x_ix_j=a_{ij}x_ix_j+a_{ji}x_jx_i\\)，上式可表示为\\(f(x)=\\sum_{i,j=1}^{n}a_{ij}x_ix_j\\)。矩阵表示为\\(f=x^TAx\\)","text":"基础知识 二次型 含有n个变量\\(x=x_1,x_2,\\cdots,x_{n-1},x_{n}\\)的二次齐次函数 \\[ f(x_1,x_2,...,x_n)=a11x_1^2+a22x_2^2+\\cdots+a_{nn}x_n^2 \\] 称为二次型。取\\(a_{ij}=a_{ji}\\)，则有\\(2a_{ij}x_ix_j=a_{ij}x_ix_j+a_{ji}x_jx_i\\)，上式可表示为\\(f(x)=\\sum_{i,j=1}^{n}a_{ij}x_ix_j\\)。矩阵表示为\\(f=x^TAx\\) 二次规划(Quadratic Programming, QP) 当目标函数\\(f\\)为二次型，且约束为线性约束时，该优化问题就是二次规划问题，一般形式表述如下： \\[ \\underset {x}{min}f(x)=\\frac{x^TQx}{2}+q^Tx \\] \\[ s.t.Ax=b \\] \\[ Gx\\leq h \\] 二次规划是一类凸优化问题，目前有很多商业或者开源的求解器来求解这类问题。 多项式轨迹 使用路径规划可以得到一系列的路径点，但这些路径点是不带时间\\(t\\)的，轨迹函数是以自变量为时间\\(t\\)的函数，一般用\\(n\\)阶多项式表示 \\[ p(t)=p_0t^0+p_1t^1+p_2t^2+\\cdots+p_nt^n=\\sum_{i=0}^{n}p_it^i \\] 向量形式 \\[ p(t)=\\left[\\begin{matrix} 1&amp;t&amp;\\cdots&amp;t^n \\end{matrix}\\right] \\left[\\begin{matrix} p_0\\\\p_1\\\\\\vdots\\\\p_n \\end{matrix}\\right] \\] 其中\\(p_0,p_1,\\cdots,p_n\\)是轨迹参数(n次多项式，有n+1个参数)，也是我们的优化参数。 对轨迹函数进行求导，可以写出它的速度\\(v\\)、加速度\\(a\\)、jerk、snap等参数随时间变化的函数 \\[ v(t)=p^{1}(t)=\\left[\\begin{matrix} 0&amp;1&amp;2t&amp;3t^2&amp;4t^3\\cdots&amp;\\frac{n!}{(n-1)!}t^{n-1} \\end{matrix}\\right]\\cdot p \\] \\[ a(t)=p^{(2)}(t)=\\left[\\begin{matrix} 0&amp;0&amp;2&amp;6t&amp;12t^2&amp;\\cdots&amp;\\frac{n!}{(n-2)!}t^{n-2} \\end{matrix}\\right]\\cdot p \\] \\[ jerk(t)=p^{(3)}(t)=\\left[\\begin{matrix} 0&amp;0&amp;0&amp;6&amp;24t&amp;\\cdots&amp;\\frac{n!}{(n-3)!}t^{n-3} \\end{matrix}\\right]\\cdot p \\] \\[ snap(t)=p^{(4)}(t)=\\left[\\begin{matrix} 0&amp;0&amp;0&amp;0&amp;24&amp;\\cdots&amp;\\frac{n!}{(n-4)!}t^{n-4} \\end{matrix}\\right]\\cdot p \\] 其中\\(p=\\left[\\begin{matrix} p_0&amp;p_1&amp;\\cdots&amp;p_n \\end{matrix}\\right]^T\\)，轨迹函数\\(p(t)\\)的导数通式为 \\[ p^{(k)}(t)=\\left[\\begin{matrix} \\overset{k}{\\overbrace{0\\cdots0}}&amp;\\overset{n-k+1}{\\overbrace{\\frac{(k+0)!}{(0)!}t^{0}\\quad \\frac{(k+1)!}{(1)!}t^{1}\\quad\\cdots\\quad \\frac{n!}{(n-k)!}t^{n-k} }} \\end{matrix}\\right]\\cdot p \\] 我们将一段复杂的轨迹按时间划分成\\(m\\)段，\\(p_i=[p_{i_0},p_{i_1},\\cdots,p_{i_n}]^T\\)为第\\(i\\)段轨迹的参数向量。 \\[ \\begin{equation} p(t) = \\begin{cases} [1,t,t^2,...,t^n]\\cdot p_1~~~t_0\\leq t&lt;t_1\\\\ [1,t,t^2,...,t^n]\\cdot p_2~~~t_1\\leq t&lt;t_2\\\\ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\vdots\\\\ [1,t,t^2,...,t^n]\\cdot p_m~~~t_{m-1}\\leq t&lt;t_m\\\\ \\end{cases} \\end{equation} \\] Minimum Snap轨迹规划 轨迹规划的目的：求轨迹的多项式参数\\(p_1,\\cdots,p_m\\) 约束条件 基本要求： 两段轨迹之间连续 轨迹经过固定点 轨迹无碰撞 高级要求： 轨迹最顺滑、能量最优等 构建优化函数 通常满足约束条件的轨迹有无数条，而实际问题中，往往只需要特定的一条轨迹，所以还需要构建一个最优函数，方便在可行的轨迹中找出最优的轨迹。 这是一个约束优化问题，形如： \\[ \\min f(p) \\] \\[ s.t.~~A_{eq}p = b_{eq}, \\] \\[ A_{ieq}p \\leq b_{ieq} \\] Minimum Snap顾名思义，最小化目标函数是\\(Snap\\)，当然也可以最小化Acceleration(加速度)或者Jerk，一般不会最小化速度。 \\[ minimum~snap:~\\min f(p)=\\min (p^{(4)}(t))^2 \\] \\[ minimum~jerk:~\\min f(p)=\\min (p^{(3)}(t))^2 \\] \\[ minimum~a:~\\min f(p)=\\min (p^{(2)}(t))^2 \\\\ \\] Minimum Snap的优化函数为 \\[ \\min \\int _0^T(p^{(4)}(t))^2 {\\rm d}t \\] \\[ =\\min \\sum_{i=1}^m \\int _{t_{i-1}}^{t_i}(p^{(4)}(t))^2 {\\rm d}t \\] \\[ =\\min \\sum_{i=1}^m \\int _{t_{i-1}}^{t_i} ([0,0,0,0,24,\\cdots,\\frac{n!}{(n-4!)}t^{n-4}]\\cdot p)^T[0,0,0,0,24,\\cdots,\\frac{n!}{(n-4!)}t^{n-4}]\\cdot p~{\\rm d}t \\] \\[ =\\min \\sum_{i=1}^m p^T\\int _{t_{i-1}}^{t_i}[0,0,0,0,24,\\cdots,\\frac{n!}{(n-4!)}t^{n-4}]^T[0,0,0,0,24,\\cdots,\\frac{n!}{(n-4!)}t^{n-4}]~{\\rm d}t~p \\] \\[ =\\min \\sum_{i=1}^m p^TQ_ip \\] \\[ =\\min p^TQp \\] \\[ Q_i = \\int _{t_{i-1}}^{t_i}[0,0,0,0,24,\\cdots,\\frac{n!}{(n-4!)}t^{n-4}]^T[0,0,0,0,24,\\cdots,\\frac{n!}{(n-4!)}t^{n-4}]~{\\rm d}t \\] \\[ =\\left[\\begin{matrix} 0_{4\\times 4} &amp; 0_{4\\times (n-3)}\\\\ 0_{(n-3) \\times 4} &amp; \\frac{r!}{(r-4)!}\\frac{c!}{(c-4)!}\\frac{1}{(r-4)+(c-4)+1}(t_{i}^{(r+c-7)}-t_{i-1}^{(r+c-7)}) \\end{matrix}\\right] \\] 注意：r,c为矩阵的行索引和列索引， 索引从0开始，即第一行r=0。这个Qi矩阵计算可太厉害了 \\[ Q = \\left[\\begin{matrix} Q_1 &amp;&amp;&amp;\\\\ &amp;Q_2&amp;&amp;\\\\ &amp;&amp;\\ddots &amp;\\\\ &amp;&amp;&amp;Q_m \\end{matrix}\\right] \\] 构建等式约束方程 1、设定某一个点的位置、速度、加速度为一个特定的值,可以构成一个等式约束。 位置约束： \\([1,t_0,t_0^2,\\cdots,t_0^n,\\underbrace{0\\cdots0}_{(m-1)(n+1)}]\\cdot p = p_0\\) 速度约束： \\([0,1,2t_0,\\cdots,nt_0^{n-1},\\underbrace{0\\cdots0}_{(m-1)(n+1)}]\\cdot p = v_0\\) 加速度约束：\\([0,0,2,\\cdots,n(n-1)t_0^{n-2},\\underbrace{0\\cdots0}_{(m-1)(n+1)}]\\cdot p = a_0\\) 2、相邻段之间的位置、速度、加速度连续可以构成一个等式约束。对于有m+1个路径点的轨迹，一共有m段多项式轨迹， 连续性约束：\\([\\underbrace{0\\cdots0}_{(i-1)(n+1)},1,t_i,t_i^2,\\cdots,t_i^n,-1,-t_i,-t_i^2,\\cdots,-t_i^n,\\underbrace{0\\cdots0}_{(m-i-1)(n+1)}]\\cdot p=0\\) 3、合并所有等式约束， \\[ \\begin{equation} \\left[\\begin{matrix} 1,t_0,t_0^2,\\cdots,t_0^n,\\underbrace{0\\cdots0}_{(m-1)(n+1)}\\\\ 0,1,2t_0,\\cdots,nt_0^{n-1},\\underbrace{0\\cdots0}_{(m-1)(n+1)}\\\\ 0,0,2,\\cdots,n(n-1)t_0^{n-2},\\underbrace{0\\cdots0}_{(m-1)(n+1)}\\\\ \\vdots\\\\ \\underbrace{0\\cdots0}_{(i-1)(n+1)} ,1,t_i,t_i^2,\\cdots,t_i^n,\\underbrace{0\\cdots0}_{(m-i)(n+1)}\\\\ \\vdots\\\\ \\underbrace{0\\cdots0}_{(m-1)(n+1)},1,t_m,t_m^2,\\cdots,t_m^n\\\\ \\underbrace{0\\cdots0}_{(m-1)(n+1)},0,1,2t_m,\\cdots,nt_m^{n-1}\\\\ \\underbrace{0\\cdots0}_{(m-1)(n+1)},0,0,2,\\cdots,n(n-1)t_m^{n-2}\\\\ \\underbrace{0\\cdots0}_{(i-1)(n+1)} ,1,t_i,t_i^2,\\cdots,t_i^n,-1,-t_i,-t_i^2,\\cdots,-t_i^n,\\underbrace{0\\cdots0}_{(m-i-1)(n+1)}\\\\ \\underbrace{0\\cdots0}_{(i-1)(n+1)} ,0,1,2t_i,\\cdots,nt_i^{n-1},-0,-1,-2t_i,\\cdots,-nt_i^{n-1},\\underbrace{0\\cdots0}_{(m-i-1)(n+1)}\\\\ \\underbrace{0\\cdots0}_{(i-1)(n+1)} ,0,0,2,\\cdots,\\frac{n!}{(n-2)!}t_i^{n-2},-0,-0,-2,\\cdots,-\\frac{n!}{(n-2)!}t_i^{n-2},\\underbrace{0\\cdots0}_{(m-i-1)(n+1)}\\\\ \\end{matrix}\\right]_{(4m+2)\\times (n+1)m} \\end{equation}p \\] \\[ = \\left[\\begin{matrix} p_0\\\\ v_0\\\\ a_0\\\\ \\vdots\\\\ p_i\\\\ \\vdots\\\\ p_m\\\\ v_m\\\\ a_m\\\\ 0\\\\ \\vdots\\\\ 0 \\end{matrix}\\right] \\] 等式约束个数=3{起点p0、v0、a0}+m-1{中间点的pi}+3{目标点pm、vm、am}+3(m-1){中间点pi、vi、ai连续=0}=4m+2 代码实现 生成x、y两个维度的轨迹，合并后如下图所示。包含起始终止共7个点，用6段多项式轨迹来描述，中间点也就是多项式轨迹之间的交界点。 参考 Mellinger D, Kumar V. Minimum snap trajectory generation and control for quadrotors[C]//2011 IEEE international conference on robotics and automation. IEEE, 2011: 2520-2525. 机器人路径规划、轨迹优化系列课程 Minimum Snap轨迹规划详解（1）轨迹规划入门","categories":[{"name":"轨迹优化","slug":"轨迹优化","permalink":"https://liujk6525.github.io/categories/%E8%BD%A8%E8%BF%B9%E4%BC%98%E5%8C%96/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://liujk6525.github.io/tags/Matlab/"}]},{"title":"基于智能算法的路径规划","slug":"基于智能算法的路径规划","date":"2023-05-15T00:38:42.000Z","updated":"2023-05-26T05:22:33.649Z","comments":true,"path":"路径规划/基于智能算法的路径规划/","link":"","permalink":"https://liujk6525.github.io/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/%E5%9F%BA%E4%BA%8E%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95%E7%9A%84%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/","excerpt":"基础知识 遗传算法 遗传算法(Genetic Algorithm,GA)是一种智能优化算法，主要用来解决优化问题，其主要步骤为种群初始化、适应度函数计算、选择、交叉和变异。应用于移动机器人路径规划时其主要步骤相同。","text":"基础知识 遗传算法 遗传算法(Genetic Algorithm,GA)是一种智能优化算法，主要用来解决优化问题，其主要步骤为种群初始化、适应度函数计算、选择、交叉和变异。应用于移动机器人路径规划时其主要步骤相同。 算法步骤 选择初始生命种群 每行选择一个栅格 判断相邻栅格是否连续 不连续时选择栅格进行插入，直到连续 循环 评价种群中的个体适应度fitness 以比例原则(分数高的挑中几率也较高)选择产生下一个种群(轮盘法、竞争法及等级轮盘法)。 选择 是按照轮盘法来选择的个体 \\[ d =\\sum_{i=1}^{end-1}{\\sqrt{(x_{i+1}-x{i})^{2}+(y_{i+1}-y_{i})^{2}}} \\] \\[ fit_1=1/d \\] \\[ fit_2=acrccos(\\frac{(b^2+c^2-a^2)}{2bc}) \\] \\[ fit=fit_1+fit_2 \\] \\[ p_i=\\frac{fit_i}{\\sum_{i=1}^{end}fit_i} \\] 改变该种群(选择、交叉和变异) 交叉 如下图所示，当两个个体{0|6|7|13|19|24}和{0|1|2|3|8|13|18|24}在栅格13处交叉，经过交叉操作后会生成新的个体{0|6|7|13|18|24}和{0|1|2|3|8|13|19|24} 变异 如下图所示，当个体{0|1|2|3|8|13|18|24}经过变异操作后会随机生成新的个体{0|1|7|13|18|24} 直到停止循环的条件满足 代码实现 参考 机器人路径规划、轨迹优化课程","categories":[{"name":"路径规划","slug":"路径规划","permalink":"https://liujk6525.github.io/categories/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://liujk6525.github.io/tags/Matlab/"}]},{"title":"基于采样的路径规划","slug":"基于采样的路径规划","date":"2023-05-13T13:41:15.000Z","updated":"2023-05-26T05:30:08.574Z","comments":true,"path":"路径规划/基于采样的路径规划/","link":"","permalink":"https://liujk6525.github.io/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/%E5%9F%BA%E4%BA%8E%E9%87%87%E6%A0%B7%E7%9A%84%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/","excerpt":"基础知识 虽然基于图搜索的路径规划算法能够给出一个全局范围内的最优解，但是当地图过大，空间维度过高时，它的搜索效率就会变得很慢。主要用于低维空间的路径规划问题。","text":"基础知识 虽然基于图搜索的路径规划算法能够给出一个全局范围内的最优解，但是当地图过大，空间维度过高时，它的搜索效率就会变得很慢。主要用于低维空间的路径规划问题。 概率路图算法(Probabilistic Road Map, PRM) PRM算法首先使用随机采样的方式在环境中建立路径网络图，将连续的空间转换为离散的空间，然后在路径网络图上进行路径规划，解决在高维空间中搜索效率低的问题 算法流程 ​ 采样点的数量和采样点间存在通道的最大距离是关键参数，具体的 采样点的数量太少，可能会导致路径规划失败，因为生成的概率路线少了。 随着采样点数量增加，结果会越来越接近最短路径，但同时搜索效率会降低 快速扩展随机树(Rapidly-exploring Random Tree, RRT)算法 RRT算法是一种单查询(single-query)算法，搜索过程就像一棵树不断向周围扩展生长。它的复杂度不受地图的离散程度影响，在高维空间中具有很高的搜索效率。 ​ 缺点：只管尽快地找到可行路径，所以最终路径并不是最优的，甚至会非常“绕”。 双向快速扩展随机树(RRT-Connect)算法 在RRT的基础上引入了双向扩展环节，分别以起点和目标点为根节点生成两棵树进行双向扩展，加快了搜索速度，当两棵树建立连接时被认为路径规划成功。 缺点：但是RRT-Connect和RRT一样，都是单查询算法，最终路径并不是最优的。 RRT*算法 RRT*算法是一种渐近最优算法。在RRT算法的基础上，增加了将\\(X_{rand}\\)加入搜索树 T 时父节点的选择策略。 RRT*算法在选择父节点时会有一个重连(Rewire)过程，也就是在以\\(X_{rand}\\)为圆心、半径为\\(r\\)的邻域内，找到与\\(X_{new}\\)连接后移动代价(从起点移动到\\(X_{new}\\)的路径长度)最小的节点，并重新选择\\(X_{min}\\)作为\\(X_{new}\\)的父节点，而不是\\(X_{near}\\)。 简单理解就是\\(Xnear\\)产生了\\(Xnew\\),然而\\(Xnew\\)抛弃了\\(Xnear\\)，选择了移动代价最小的\\(Xmin\\)作为父节点。 缺点：RRT**是对自由空间进行均匀采样，搜索树上会生成很多冗余的分支，所以RRT*的收敛速度很慢。 Informed-RRT*算法 对RRT*的改进策略：采用椭圆采样来代替全局均匀采样 以起点 \\(X_{start}\\)和终点\\(X_{goal}\\)作为椭圆的焦点，令\\(a\\)等于初始路径长度\\(c_{best}\\)的一半，即\\(a=\\frac{c_{best}}{2}\\)，则$ c=\\(，\\)b=$，这样就可以得到椭圆方程的所有参数。 在之后的迭代中，如果没找到更短的路径，就用\\(c_{min}\\)作为新的\\(c_{best}\\)，然后在新的椭圆区域进行采样。 代码实现 参考 路径规划 | 随机采样算法：PRM、RRT、RRT-Connect、RRT* 路径规划 | 随机采样算法：Informed-RRT* 机器人路径规划、轨迹优化系列课程 [1] Lavalle S M . Rapidly-Exploring Random Trees: A New Tool for Path Planning[J]. Research Report, 1999. [2] Jr J , Lavalle S M . RRT-Connect: An Efficient Approach to Single-Query Path Planning[C]// Proceedings of the 2000 IEEE International Conference on Robotics and Automation, ICRA 2000, April 24-28, 2000, San Francisco, CA, USA. IEEE, 2000. [3] Karaman S , Frazzoli E . Sampling-based Algorithms for Optimal Motion Planning[J]. The International Journal of Robotics Research, 2011, 30(7):846-894. [4] Gammell J D , Srinivasa S S , Barfoot T D . Informed RRT*: Optimal Sampling-based Path Planning Focused via Direct Sampling of an Admissible Ellipsoidal Heuristic[J]. IEEE, 2014.","categories":[{"name":"路径规划","slug":"路径规划","permalink":"https://liujk6525.github.io/categories/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"}],"tags":[{"name":"python","slug":"python","permalink":"https://liujk6525.github.io/tags/python/"}]},{"title":"基于搜索的路径规划","slug":"基于搜索的路径规划","date":"2023-05-12T03:36:41.000Z","updated":"2023-05-26T05:22:33.650Z","comments":true,"path":"路径规划/基于搜索的路径规划/","link":"","permalink":"https://liujk6525.github.io/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/%E5%9F%BA%E4%BA%8E%E6%90%9C%E7%B4%A2%E7%9A%84%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/","excerpt":"基础知识 图搜索法是通过利用已有的环境地图和障碍物等数据信息，建立由起点至目标点的可行路线。 配置空间(Configuration Space) 在实际环境，要将工作空间转换到配置空间中，即将机器人转化为一个质点，同时将障碍物按照机器人的体积进行膨胀","text":"基础知识 图搜索法是通过利用已有的环境地图和障碍物等数据信息，建立由起点至目标点的可行路线。 配置空间(Configuration Space) 在实际环境，要将工作空间转换到配置空间中，即将机器人转化为一个质点，同时将障碍物按照机器人的体积进行膨胀 基本流程 在容器open list中存放将要访问的节点 将起点加入容器 While True： 弹出：从容器中取出一个节点 扩展：将该节点周围的其他节点放入open list 深度优先搜索(Depth First Search, DFS )算法 优先扩展搜索深度较大的节点，从起点开始，按照某个顺序一条路走下去，直至不能再继续为止，然后回到上一节点，再换另一条路走下去； 深度优先搜索的过程是一条路走到底后，最后访问的节点最先拿来处理，整个过程可以用栈(stack)来表示——后进先出。 深度优先算法优先扩展搜索深度较大的节点，因此能够更迅速的获得下一个可行路径，不过深度优先算法获取的第一个路径通常是比较长的路径。 在无权图中找到从节点a到节点j的路径为例 按照DFS的基本流程搜索a到j的路径： 从目标点开始回溯：a-&gt;b-&gt;f-&gt;j 广度优先搜索(Breadth First Search, BFS)算法 每一步都扩展同一层的所有可能节点，一层一层扩展下去，直到某一层搜索到终点为止。 广度优先搜索的过程是一层中先访问的节点拿来处理，可以用队列(queue)来表示——先进先出。 广度优先算法优先扩展深入较小的节点，呈波状推进的形式搜索。因此广度优先算法检索到的第一个路径通常是最短路径。 贪婪最佳优先搜索(Greedy Best First Search,GBFS )算法 使用的是优先队列(Priority Queue)，普通队列是一种先进先出的数据结构，而在优先队列中元素被赋予了优先级，最高优先级元素优先删除，也就是first in, largest out 在图搜索算法中，优先级判断的标准是代价函数 \\(f(n)\\) ， \\(f(n)\\) 越小，优先级越高。 \\[ f(n)=h(n) \\] \\(h(n)\\)是启发式函数，为节点\\(n\\)到目标节点之间所形成路径的最小代价值。一般为欧氏距离或者曼哈顿距离 遇到障碍物时，它很容易陷入局部最优的陷阱。 Dijkstra算法 Dijkstra算法是从一个顶点到其余各顶点的最短路径算法，其流程仍然与上述算法基本一致，它也是用优先队列作为open list的数据结构，它和GBFS的区别在于代价函数 \\(f(n)\\)的定义: \\[ f(n)=g(n) \\] \\(g(n)\\)表示从起始节点到当前节点\\(n\\)的移动代价函数。 计算起点v1到终点v6的最短路径，箭头上的数值表示两个节点间的距离 首先扩展第一个节点，计算其余邻近节点与第一个节点的距离，从未扩展的节点中选择代价函数最小的节点进行扩展，并更新其余节点的代价函数 重复进行上面的步骤，直到所有节点都已扩展。 最后标出起点到终点的最短路径 找到一条从1到6的最短路径 ​ open list: 4(1) 2(2) # 存储已经被搜索过但没有被访问过的节点，并对其进行排序 closed list:1(0) # 存储已经被访问过的节点 从open list中的节点中选择距离最小的节点作为扩展节点，显然是节点4。 ​ open list: 2(2) 3(3) 7(5) 6(9) # 遍历邻接节点，更新距离 closed list: 1(0) 4(1) 重复上述操作。选择新的扩展节点，即节点2 ​ open list: 3(3) 7(5) 6(9) 5(13) closed list: 1(0) 4(1) 2(2) 选择新的扩展节点，即节点3 ​ open list: 7(5) 6(8) 5(13) # 注意这里访问节点3，对它的领接节点6的距离进行了更新 closed list: 1(0) 4(1) 2(2) 3(3) 选择新的扩展节点，即节点7 ​ open list: 6(6) 5(13) # 注意这里访问节点7，对它的领接节点6的距离进行了更新 closed list: 1(0) 4(1) 2(2) 3(3) 7(5) ​ closed list: 1(0) 4(1) 2(2) 3(3) 7(5) 6(6) A*搜索(A* search)算法 GBFS用节点到目标点的距离作为代价函数，将搜索方向引向目标点，搜索效率高。 Dijkstra算法采用起点到当前扩展节点的移动代价作为代价函数，能够确保路径最优。 A*搜索算法在Dijkstra算法的基础上增加启发式函数\\(h(n)\\)，规定其代价函数为 \\[ f(n)=g(n)+h(n) \\] 代码实现 参考 路径规划 | 图搜索算法：DFS、BFS、GBFS、Dijkstra、A* 机器人路径规划、轨迹优化系列课程","categories":[{"name":"路径规划","slug":"路径规划","permalink":"https://liujk6525.github.io/categories/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://liujk6525.github.io/tags/Python/"}]},{"title":"NexT主题添加鼠标特效","slug":"NexT主题添加鼠标特效","date":"2023-05-11T11:46:09.000Z","updated":"2023-05-26T05:32:31.707Z","comments":true,"path":"踩坑记录/NexT主题添加鼠标特效/","link":"","permalink":"https://liujk6525.github.io/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/NexT%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E9%BC%A0%E6%A0%87%E7%89%B9%E6%95%88/","excerpt":"最近在b站无意间刷到搭建个人网站的视频，通过github+hexo的方式，期间踩得一些坑，因为现在NexT主题更新版本了，有许多美化主题的方法有所改动。 效果图","text":"最近在b站无意间刷到搭建个人网站的视频，通过github+hexo的方式，期间踩得一些坑，因为现在NexT主题更新版本了，有许多美化主题的方法有所改动。 效果图 1、创建_data/body-end.swig文件 然后将下面的代码放入其中 1234567891011121314# 鼠标点击特效 #&#123;% if theme.cursor_effect == &quot;fireworks&quot; %&#125; &lt;script async src=&quot;/js/cursor/fireworks.js&quot;&gt;&lt;/script&gt;&#123;% elseif theme.cursor_effect == &quot;text&quot; %&#125; &lt;script async src=&quot;/js/cursor/text.js&quot;&gt;&lt;/script&gt;&#123;% elseif theme.cursor_effect == &quot;cherry&quot; %&#125; &lt;script src=&quot;/js/cursor/cherry.js&quot;&gt;&lt;/script&gt;&#123;% elseif theme.cursor_effect == &quot;explosion&quot; %&#125; &lt;canvas class=&quot;fireworks&quot; style=&quot;position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;&quot; &gt;&lt;/canvas&gt; &lt;script src=&quot;//cdn.bootcss.com/animejs/2.2.0/anime.min.js&quot;&gt;&lt;/script&gt; &lt;script async src=&quot;/js/cursor/explosion.min.js&quot;&gt;&lt;/script&gt;&#123;% elseif theme.cursor_effect == &quot;love&quot; %&#125; &lt;script async src=&quot;/js/cursor/love.min.js&quot;&gt;&lt;/script&gt;&#123;% endif %&#125; 2、创建E:\\blog\\source\\js\\cursor文件夹 在这个文件夹下分别存放.js文件 创建cherry.js 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101(function cherry() &#123; var possibleColors = [&quot;#D61C59&quot;, &quot;#E7D84B&quot;, &quot;#1B8798&quot;] var width = window.innerWidth; var height = window.innerHeight; var cursor = &#123;x: width/2, y: width/2&#125;; var particles = []; function init() &#123; bindEvents(); loop(); &#125; // Bind events that are needed function bindEvents() &#123; document.addEventListener(&#x27;mousemove&#x27;, onMouseMove); document.addEventListener(&#x27;touchmove&#x27;, onTouchMove); document.addEventListener(&#x27;touchstart&#x27;, onTouchMove); window.addEventListener(&#x27;resize&#x27;, onWindowResize); &#125; function onWindowResize(e) &#123; width = window.innerWidth; height = window.innerHeight; &#125; function onTouchMove(e) &#123; if( e.touches.length &gt; 0 ) &#123; for( var i = 0; i &lt; e.touches.length; i++ ) &#123; addParticle( e.touches[i].clientX, e.touches[i].clientY, possibleColors[Math.floor(Math.random()*possibleColors.length)]); &#125; &#125; &#125; function onMouseMove(e) &#123; cursor.x = e.clientX; cursor.y = e.clientY; addParticle( cursor.x, cursor.y, possibleColors[Math.floor(Math.random()*possibleColors.length)]); &#125; function addParticle(x, y, color) &#123; var particle = new Particle(); particle.init(x, y, color); particles.push(particle); &#125; function updateParticles() &#123; for( var i = 0; i &lt; particles.length; i++ ) &#123; particles[i].update(); &#125; for( var i = particles.length -1; i &gt;= 0; i-- ) &#123; if( particles[i].lifeSpan &lt; 0 ) &#123; particles[i].die(); particles.splice(i, 1); &#125; &#125; &#125; function loop() &#123; requestAnimationFrame(loop); updateParticles(); &#125; function Particle() &#123; this.character = &quot;*&quot;; this.lifeSpan = 120; //ms this.initialStyles =&#123; &quot;position&quot;: &quot;fixed&quot;, &quot;top&quot;: &quot;0&quot;, //必须加 &quot;display&quot;: &quot;block&quot;, &quot;pointerEvents&quot;: &quot;none&quot;, &quot;z-index&quot;: &quot;10000000&quot;, &quot;fontSize&quot;: &quot;20px&quot;, &quot;will-change&quot;: &quot;transform&quot; &#125;; this.init = function(x, y, color) &#123; this.velocity = &#123; x: (Math.random() &lt; 0.5 ? -1 : 1) * (Math.random() / 2), y: 1 &#125;; this.position = &#123;x: x - 10, y: y - 20&#125;; this.initialStyles.color = color; console.log(color); this.element = document.createElement(&#x27;span&#x27;); this.element.innerHTML = this.character; applyProperties(this.element, this.initialStyles); this.update(); document.body.appendChild(this.element); &#125;; this.update = function() &#123; this.position.x += this.velocity.x; this.position.y += this.velocity.y; this.lifeSpan--; this.element.style.transform = &quot;translate3d(&quot; + this.position.x + &quot;px,&quot; + this.position.y + &quot;px,0) scale(&quot; + (this.lifeSpan / 120) + &quot;)&quot;; &#125; this.die = function() &#123; this.element.parentNode.removeChild(this.element); &#125; &#125; function applyProperties( target, properties ) &#123; for( var key in properties ) &#123; target.style[ key ] = properties[ key ]; &#125; &#125; init(); &#125;)(); 创建explosion.min.js 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186&quot;use strict&quot;;function updateCoords(e) &#123; pointerX = (e.clientX || e.touches[0].clientX) - canvasEl.getBoundingClientRect().left, pointerY = e.clientY || e.touches[0].clientY - canvasEl.getBoundingClientRect().top&#125;function setParticuleDirection(e) &#123; var t = anime.random(0, 360) * Math.PI / 180, a = anime.random(50, 180), n = [-1, 1][anime.random(0, 1)] * a; return &#123; x: e.x + n * Math.cos(t), y: e.y + n * Math.sin(t) &#125;&#125;function createParticule(e, t) &#123; var a = &#123;&#125;; return a.x = e, a.y = t, a.color = colors[anime.random(0, colors.length - 1)], a.radius = anime.random(16, 32), a.endPos = setParticuleDirection(a), a.draw = function() &#123; ctx.beginPath(), ctx.arc(a.x, a.y, a.radius, 0, 2 * Math.PI, !0), ctx.fillStyle = a.color, ctx.fill() &#125;, a&#125;function createCircle(e, t) &#123; var a = &#123;&#125;; return a.x = e, a.y = t, a.color = &quot;#F00&quot;, a.radius = 0.1, a.alpha = 0.5, a.lineWidth = 6, a.draw = function() &#123; ctx.globalAlpha = a.alpha, ctx.beginPath(), ctx.arc(a.x, a.y, a.radius, 0, 2 * Math.PI, !0), ctx.lineWidth = a.lineWidth, ctx.strokeStyle = a.color, ctx.stroke(), ctx.globalAlpha = 1 &#125;, a&#125;function renderParticule(e) &#123; for (var t = 0; t &lt; e.animatables.length; t++) &#123; e.animatables[t].target.draw() &#125;&#125;function animateParticules(e, t) &#123; for (var a = createCircle(e, t), n = [], i = 0; i &lt; numberOfParticules; i++) &#123; n.push(createParticule(e, t)) &#125; anime.timeline().add(&#123; targets: n, x: function(e) &#123; return e.endPos.x &#125;, y: function(e) &#123; return e.endPos.y &#125;, radius: 0.1, duration: anime.random(1200, 1800), easing: &quot;easeOutExpo&quot;, update: renderParticule &#125;).add(&#123; targets: a, radius: anime.random(80, 160), lineWidth: 0, alpha: &#123; value: 0, easing: &quot;linear&quot;, duration: anime.random(600, 800) &#125;, duration: anime.random(1200, 1800), easing: &quot;easeOutExpo&quot;, update: renderParticule, offset: 0 &#125;)&#125;function debounce(e, t) &#123; var a; return function() &#123; var n = this, i = arguments; clearTimeout(a), a = setTimeout(function() &#123; e.apply(n, i) &#125;, t) &#125;&#125;var canvasEl = document.querySelector(&quot;.fireworks&quot;);if (canvasEl) &#123; var ctx = canvasEl.getContext(&quot;2d&quot;), numberOfParticules = 30, pointerX = 0, pointerY = 0, tap = &quot;mousedown&quot;, colors = [&quot;#FF1461&quot;, &quot;#18FF92&quot;, &quot;#5A87FF&quot;, &quot;#FBF38C&quot;], setCanvasSize = debounce(function() &#123; canvasEl.width = 2 * window.innerWidth, canvasEl.height = 2 * window.innerHeight, canvasEl.style.width = window.innerWidth + &quot;px&quot;, canvasEl.style.height = window.innerHeight + &quot;px&quot;, canvasEl.getContext(&quot;2d&quot;).scale(2, 2) &#125;, 500), render = anime(&#123; duration: 1 / 0, update: function() &#123; ctx.clearRect(0, 0, canvasEl.width, canvasEl.height) &#125; &#125;); document.addEventListener(tap, function(e) &#123; &quot;sidebar&quot; !== e.target.id &amp;&amp; &quot;toggle-sidebar&quot; !== e.target.id &amp;&amp; &quot;A&quot; !== e.target.nodeName &amp;&amp; &quot;IMG&quot; !== e.target.nodeName &amp;&amp; (render.play(), updateCoords(e), animateParticules(pointerX, pointerY)) &#125;, !1), setCanvasSize(), window.addEventListener(&quot;resize&quot;, setCanvasSize, !1)&#125;&quot;use strict&quot;;function updateCoords(e) &#123; pointerX = (e.clientX || e.touches[0].clientX) - canvasEl.getBoundingClientRect().left, pointerY = e.clientY || e.touches[0].clientY - canvasEl.getBoundingClientRect().top&#125;function setParticuleDirection(e) &#123; var t = anime.random(0, 360) * Math.PI / 180, a = anime.random(50, 180), n = [-1, 1][anime.random(0, 1)] * a; return &#123; x: e.x + n * Math.cos(t), y: e.y + n * Math.sin(t) &#125;&#125;function createParticule(e, t) &#123; var a = &#123;&#125;; return a.x = e, a.y = t, a.color = colors[anime.random(0, colors.length - 1)], a.radius = anime.random(16, 32), a.endPos = setParticuleDirection(a), a.draw = function() &#123; ctx.beginPath(), ctx.arc(a.x, a.y, a.radius, 0, 2 * Math.PI, !0), ctx.fillStyle = a.color, ctx.fill() &#125;, a&#125;function createCircle(e, t) &#123; var a = &#123;&#125;; return a.x = e, a.y = t, a.color = &quot;#F00&quot;, a.radius = 0.1, a.alpha = 0.5, a.lineWidth = 6, a.draw = function() &#123; ctx.globalAlpha = a.alpha, ctx.beginPath(), ctx.arc(a.x, a.y, a.radius, 0, 2 * Math.PI, !0), ctx.lineWidth = a.lineWidth, ctx.strokeStyle = a.color, ctx.stroke(), ctx.globalAlpha = 1 &#125;, a&#125;function renderParticule(e) &#123; for (var t = 0; t &lt; e.animatables.length; t++) &#123; e.animatables[t].target.draw() &#125;&#125;function animateParticules(e, t) &#123; for (var a = createCircle(e, t), n = [], i = 0; i &lt; numberOfParticules; i++) &#123; n.push(createParticule(e, t)) &#125; anime.timeline().add(&#123; targets: n, x: function(e) &#123; return e.endPos.x &#125;, y: function(e) &#123; return e.endPos.y &#125;, radius: 0.1, duration: anime.random(1200, 1800), easing: &quot;easeOutExpo&quot;, update: renderParticule &#125;).add(&#123; targets: a, radius: anime.random(80, 160), lineWidth: 0, alpha: &#123; value: 0, easing: &quot;linear&quot;, duration: anime.random(600, 800) &#125;, duration: anime.random(1200, 1800), easing: &quot;easeOutExpo&quot;, update: renderParticule, offset: 0 &#125;)&#125;function debounce(e, t) &#123; var a; return function() &#123; var n = this, i = arguments; clearTimeout(a), a = setTimeout(function() &#123; e.apply(n, i) &#125;, t) &#125;&#125;var canvasEl = document.querySelector(&quot;.fireworks&quot;);if (canvasEl) &#123; var ctx = canvasEl.getContext(&quot;2d&quot;), numberOfParticules = 30, pointerX = 0, pointerY = 0, tap = &quot;mousedown&quot;, colors = [&quot;#FF1461&quot;, &quot;#18FF92&quot;, &quot;#5A87FF&quot;, &quot;#FBF38C&quot;], setCanvasSize = debounce(function() &#123; canvasEl.width = 2 * window.innerWidth, canvasEl.height = 2 * window.innerHeight, canvasEl.style.width = window.innerWidth + &quot;px&quot;, canvasEl.style.height = window.innerHeight + &quot;px&quot;, canvasEl.getContext(&quot;2d&quot;).scale(2, 2) &#125;, 500), render = anime(&#123; duration: 1 / 0, update: function() &#123; ctx.clearRect(0, 0, canvasEl.width, canvasEl.height) &#125; &#125;); document.addEventListener(tap, function(e) &#123; &quot;sidebar&quot; !== e.target.id &amp;&amp; &quot;toggle-sidebar&quot; !== e.target.id &amp;&amp; &quot;A&quot; !== e.target.nodeName &amp;&amp; &quot;IMG&quot; !== e.target.nodeName &amp;&amp; (render.play(), updateCoords(e), animateParticules(pointerX, pointerY)) &#125;, !1), setCanvasSize(), window.addEventListener(&quot;resize&quot;, setCanvasSize, !1)&#125;; 创建love.js文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152!function(e, t, a) &#123; function n() &#123; c(&quot;.heart&#123;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);&#125;.heart:after,.heart:before&#123;content: &#x27;&#x27;;width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;&#125;.heart:after&#123;top: -5px;&#125;.heart:before&#123;left: -5px;&#125;&quot;), o(), r() &#125; function r() &#123; for (var e = 0; e &lt; d.length; e++) d[e].alpha &lt;= 0 ? (t.body.removeChild(d[e].el), d.splice(e, 1)) : (d[e].y--, d[e].scale += .004, d[e].alpha -= .013, d[e].el.style.cssText = &quot;left:&quot; + d[e].x + &quot;px;top:&quot; + d[e].y + &quot;px;opacity:&quot; + d[e].alpha + &quot;;transform:scale(&quot; + d[e].scale + &quot;,&quot; + d[e].scale + &quot;) rotate(45deg);background:&quot; + d[e].color + &quot;;z-index:99999&quot;); requestAnimationFrame(r) &#125; function o() &#123; var t = &quot;function&quot; == typeof e.onclick &amp;&amp; e.onclick; e.onclick = function(e) &#123; t &amp;&amp; t(), i(e) &#125; &#125; function i(e) &#123; var a = t.createElement(&quot;div&quot;); a.className = &quot;heart&quot;, d.push(&#123; el: a, x: e.clientX - 5, y: e.clientY - 5, scale: 1, alpha: 1, color: s() &#125;), t.body.appendChild(a) &#125; function c(e) &#123; var a = t.createElement(&quot;style&quot;); a.type = &quot;text/css&quot;; try &#123; a.appendChild(t.createTextNode(e)) &#125; catch (t) &#123; a.styleSheet.cssText = e &#125; t.getElementsByTagName(&quot;head&quot;)[0].appendChild(a) &#125; function s() &#123; return &quot;rgb(&quot; + ~~ (255 * Math.random()) + &quot;,&quot; + ~~ (255 * Math.random()) + &quot;,&quot; + ~~ (255 * Math.random()) + &quot;)&quot; &#125; var d = []; e.requestAnimationFrame = function() &#123; return e.requestAnimationFrame || e.webkitRequestAnimationFrame || e.mozRequestAnimationFrame || e.oRequestAnimationFrame || e.msRequestAnimationFrame || function(e) &#123; setTimeout(e, 1e3 / 60) &#125; &#125;(), n()&#125;(window, document); 创建text.js文件 12345678910111213141516171819202122232425262728var a_idx = 0;jQuery(document).ready(function($) &#123; $(&quot;body&quot;).click(function(e) &#123; var a = new Array(&quot;富强&quot;, &quot;民主&quot;,&quot;文明&quot;,&quot;和谐&quot;,&quot;自由&quot;,&quot;平等&quot;,&quot;公正&quot;,&quot;法治&quot;,&quot;爱国&quot;,&quot;敬业&quot;,&quot;诚信&quot;,&quot;友善&quot;); var $i = $(&quot;&lt;span/&gt;&quot;).text(a[a_idx]); var x = e.pageX, y = e.pageY; $i.css(&#123; &quot;z-index&quot;: 99999, &quot;top&quot;: y - 28, &quot;left&quot;: x - a[a_idx].length * 8, &quot;position&quot;: &quot;absolute&quot;, &quot;color&quot;: s() &#125;); $(&quot;body&quot;).append($i); $i.animate(&#123; &quot;top&quot;: y - 180, &quot;opacity&quot;: 0 &#125;, 1500, function() &#123; $i.remove(); &#125;); a_idx = (a_idx + 1) % a.length; &#125;);&#125;);function s() &#123; return &quot;rgb(&quot; + ~~ (255 * Math.random()) + &quot;,&quot; + ~~ (255 * Math.random()) + &quot;,&quot; + ~~ (255 * Math.random()) + &quot;)&quot;&#125; 3、打开 E:\\blog\\themes\\next\\_config.yml 文件 然后取消 post-body-end.swig 的注释 4、打开主题配置文件E:\\blog\\themes\\next\\_config.yml 在文件中合适的位置添加下面的代码 123# 鼠标点击特效# mouse click effect: | cherry | explosion | fireworks | love | text cursor_effect: explosion 5、启动服务就可以看到特效了 1hexo clean &amp;&amp; hexo g -s","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://liujk6525.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://liujk6525.github.io/tags/Hexo/"}]},{"title":"基于混合粒子群算法的TSP算法","slug":"基于混合粒子群算法的TSP算法","date":"2023-05-10T13:10:59.000Z","updated":"2023-05-26T05:22:33.651Z","comments":true,"path":"TSP问题/基于混合粒子群算法的TSP算法/","link":"","permalink":"https://liujk6525.github.io/TSP%E9%97%AE%E9%A2%98/%E5%9F%BA%E4%BA%8E%E6%B7%B7%E5%90%88%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%95%E7%9A%84TSP%E7%AE%97%E6%B3%95/","excerpt":"理论基础 基本粒子群算法 粒子群算法，也称粒子群优化算法或鸟群觅食算法（Particle Swarm Optimization，PSO），它通过追随当前搜索到的最优值来寻找全局最优。这种算法以其实现容易、精度高、收敛快等优点引起了学术界的重视，并且在解决实际问题中展示了其优越性。","text":"理论基础 基本粒子群算法 粒子群算法，也称粒子群优化算法或鸟群觅食算法（Particle Swarm Optimization，PSO），它通过追随当前搜索到的最优值来寻找全局最优。这种算法以其实现容易、精度高、收敛快等优点引起了学术界的重视，并且在解决实际问题中展示了其优越性。 基本原理 PSO中，每个优化问题的解都是搜索空间中的一只鸟。我们称之为“粒子”。所有的粒子都有一个由被优化的函数决定的适应值(fitness value)，每个粒子还有一个速度决定他们飞翔的方向和距离。然后粒子们就追随当前的最优粒子在解空间中搜索。 粒子位置的更新方式如下所示 \\(PSO\\)初始化为一群随机粒子(随机解)。然后通过迭代找到最优解。在每一次迭代中，粒子通过跟踪两个“极值”来更新自己。第一个就是粒子本身所找到的最优解，这个解叫做个体极值Pbest。另一个极值是整个种群目前找到的最优解，这个极值是全局极值gbest。另外也可以不用整个种群而只是用其中一部分作为粒子的邻居，那么在所有邻居中的极值就是局部极值。 假设在一个D维的目标搜索空间中，有N个粒子组成一个种群，其中 第i个粒子为一个D维的向量 \\[ X_i = (x_{i1},x_{i2},x_{i3},...x_{iD}),\\quad i=1,2,3,...,N \\] 第i个粒子的“飞行”速度也是一个D维的向量 \\[ V_i = (v_{i1},v_{i2},v_{i3},...v_{iD}),\\quad i=1,2,3,...,N \\] 第i个粒子迄今为止搜索到的最优位置称为个体极值 \\[ P_{best}=(p_{i1},p_{i2},p_{i3},...p_{iD}),\\quad i=1,2,3,...,N \\] 整个粒子群迄今为止搜索到的最优位置称为全局极值 \\[ g_{best}=(p_{g1},p_{g2},p_{g3},...p_{gD}) \\] 在找到这两个最优值时，粒子根据如下公式更新自己的速度和位置 \\[ v_{id}=w*v_{id}+c_1r_1(p_{id}-x_{id})+c_2r_2(p_{gd}-x_{id})\\\\ x_{id}=x_{id}+v_{id} \\] 式中，w为惯性权重(inertia weight)，c1,c2为学习因子，也称为加速常量(acceleration constants)，r1r2为[0,1]范围内的均匀随机数 w*vid 为“惯性”或者”动量“部分，反映了粒子的运动习惯，代表粒子有维持自己先前速度的趋势。 c1r1(pid-xid)为“认知”部分，反映了粒子对自身历史经验的记忆或回忆，代表了粒子有向自身历史最佳位置逼近的趋势。 c2r2(pgd-xid)为“社会”部分，反映了粒子间协同合作与知识共享的群体历史经验，代表了粒子有向群体或邻域历史最佳位置逼近的趋势。 PSO算法的流程 初始化粒子群，包括群体规模N，每个粒子的位置xi和速度vi； 计算每个粒子的适应度Fitness(i)； 对每个粒子，将其适应值Fitness(i)与其经过的最优值Pbest(i)作比较，如果较好，则将其替换掉原来的Pbest(i)； 对每个粒子，将其适应值Fitness(i)与其经过的全局最优值gbest(i)作比较，如果较好，则将其替换掉原来的gbest(i)； 根据公式更新粒子的速度vi和位置xi； 如果满足结束条件退出，否则返回第2步。 混合粒子群算法 标准粒子群算法通过追随个体极值和群体极值完成极值寻优，虽然操作简单，且能够快速收敛，但是随着迭代次数的不断增加，在种群收敛集中的同时，各粒子也越来越相似，可能在局部最优解周边无法跳出。 混合粒子群算法摒弃了传统粒子群算法中的通过跟踪极值来更新粒子位置的方法，而是引入了遗传算法中的交叉和变异操作，通过粒子同个体极值和群体极值的交叉以及粒子自身变异的方式来搜索最优解。 问题描述 TSP问题，具体描述参考基于遗传算法的TSP算法，这边不在赘叙。 代码实现 适应值变化 苹果位置图 路径规划图 ​ 最优解 参考 [1]史峰. MATLAB智能算法30个案例分析[M]. 北京航空航天大学出版社, 2011.","categories":[{"name":"TSP问题","slug":"TSP问题","permalink":"https://liujk6525.github.io/categories/TSP%E9%97%AE%E9%A2%98/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://liujk6525.github.io/tags/Matlab/"},{"name":"路径规划","slug":"路径规划","permalink":"https://liujk6525.github.io/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"}]},{"title":"Hexo--数学公式渲染","slug":"Hexo-数学公式渲染","date":"2023-05-10T07:15:48.000Z","updated":"2023-05-26T05:22:33.641Z","comments":true,"path":"踩坑记录/Hexo-数学公式渲染/","link":"","permalink":"https://liujk6525.github.io/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/Hexo-%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E6%B8%B2%E6%9F%93/","excerpt":"Pandoc 进行数学公式渲染 主题是选择的NexT,下面是使用对应的Hexo渲染器在博客中显示出数学公式。","text":"Pandoc 进行数学公式渲染 主题是选择的NexT,下面是使用对应的Hexo渲染器在博客中显示出数学公式。 步骤 1、在next/_config.yml文件中将enable选项改为true 2、使用 hexo-renderer-pandoc 作为 Hexo 的 Markdown 渲染器。 12npm uninstall hexo-renderer-marked #卸载原有的渲染器npm install hexo-renderer-pandoc # 安装pandoc渲染器 3、执行 Hexo 生成，部署 1hexo clean &amp;&amp; hexo g -d 注意 a: 执行最后一步后出现如下的问题： ERROR:pandoc exited with code 9: pandoc: Unknown extension: smart 解决办法: 将node_modules\\hexo-renderer-pandoc\\index.js文件中的 1var args = [ &#x27;-f&#x27;, &#x27;markdown-smart&#x27;+extensions, &#x27;-t&#x27;, &#x27;html-smart&#x27;, math] 改为 1var args = [ &#x27;-f&#x27;, &#x27;markdown&#x27;+extensions, &#x27;-t&#x27;, &#x27;html&#x27;, math] b: 正常的文字后面如果跟的是 list, table 或者 quotation，文字后面需要空一行，如果不空行，这些环境将不能被 Pandoc renderer 正常渲染。 参考 数学公式 pandoc/issues Hexo 搭建个人博客指南","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://liujk6525.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://liujk6525.github.io/tags/Hexo/"}]},{"title":"Typora添加数学公式","slug":"Typora添加数学公式","date":"2023-05-10T01:35:30.000Z","updated":"2023-05-26T05:28:00.467Z","comments":true,"path":"工具速查/Typora添加数学公式/","link":"","permalink":"https://liujk6525.github.io/%E5%B7%A5%E5%85%B7%E9%80%9F%E6%9F%A5/Typora%E6%B7%BB%E5%8A%A0%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/","excerpt":"Typora是一款支持Markdown的编辑器，亲测非常好用，在此总结了常用的公式编辑方法，旨在文章更加的美观规范。","text":"Typora是一款支持Markdown的编辑器，亲测非常好用，在此总结了常用的公式编辑方法，旨在文章更加的美观规范。 补充 公式内部添加大括号 \\[ \\begin{cases} q=kx_1+y_1\\\\ q=kx_2+y_2 \\end{cases} \\] 1234\\begin&#123;cases&#125;q=kx_1+y_1\\\\q=kx_2+y_2\\end&#123;cases&#125; 字母上方添加横线 \\[ \\overline{F} \\] 1\\overline&#123;F&#125; 字母上方添加尖号 \\[ \\hat{f} \\] 1\\hat&#123;f&#125; \\[ \\widehat{F} \\] 1\\widehat&#123;F&#125; 字母上方添加点 \\[ \\dot{f} \\] 1\\dot&#123;f&#125; 字母上方添加点点 \\[ \\ddot{f} \\] 1\\ddot&#123;f&#125; 字母上方添加波浪号 \\[ \\tilde{f} \\] 1\\tilde&#123;f&#125; \\[ \\widetilde{F} \\] 1\\widetilde&#123;f&#125; 字母正上/下方插入下标 \\[ \\overset {*}{x} \\] 1\\overset &#123;*&#125;&#123;x&#125; \\[ \\underset {x}{min} \\] 1\\underset &#123;x&#125;&#123;min&#125; 字母正上/下方插入大括号 \\[ \\overbrace{} \\] 1\\overbrace&#123;&#125; \\[ \\underbrace{} \\] 1\\underbrace&#123;&#125; 矩阵 \\[ \\left[\\begin{matrix} 1&amp;2&amp;3\\\\ 4&amp;5&amp;6 \\end{matrix}\\right] \\] 1234\\left[\\begin&#123;matrix&#125;1&amp;2&amp;3\\\\4&amp;5&amp;6\\end&#123;matrix&#125;\\right] 常用公式的代码 梯度 \\[ \\nabla \\] 1\\nabla 度数的圆圈 \\[ 90^\\circ \\] 190^\\circ 分式 \\[ 1/2 \\] 11/2 \\[ \\frac{1}{2} \\] 1\\frac&#123;1&#125;&#123;2&#125; 水平省略号 \\[ ... \\] 1\\cdots 垂直省略号 \\[ \\vdots \\] 1\\vdots 开根号 \\[ \\sqrt{2} \\] 1\\sqrt&#123;2&#125; 矢量 \\[ \\vec{a} \\] 1\\vec&#123;a&#125; 积分 \\[ \\int{x}dx \\] 1\\int&#123;x&#125;dx \\[ \\int_{1}^{2}{x}dx \\] 1\\int_&#123;1&#125;^&#123;2&#125;&#123;x&#125;dx 微分 \\[ \\partial \\] 1\\partial \\[ \\frac{\\partial x}{\\partial y} \\] 1\\frac&#123;\\partial x&#125;&#123;\\partial y&#125; 极限 \\[ \\lim{a+b} \\] 1\\lim&#123;a+b&#125; \\[ \\lim_{n\\rightarrow+\\infty} \\] 1\\lim_&#123;n\\rightarrow+\\infty&#125; 累加 \\[ \\sum{a} \\] 1\\sum&#123;a&#125; \\[ \\sum_{n=1}^{100}{a_n} \\] 1\\sum_&#123;n=1&#125;^&#123;100&#125;&#123;a_n&#125; 累乘 \\[ \\prod{x} \\] 1\\prod_&#123;n=1&#125;^&#123;99&#125;&#123;x_n&#125; 空格 \\[ a\\quad b \\] 1a\\quad b 希腊字母 \\[ \\alpha \\] 1\\alpha \\[ \\beta \\] 1\\beta \\[ \\gamma \\] 1\\gamma \\[ \\Delta \\] 1\\Delta \\[ \\delta \\] 1\\delta \\[ \\varepsilon \\] 1\\varepsilon \\[ \\epsilon \\] 1\\epsilon \\[ \\zeta \\] 1\\zeta \\[ \\eta \\] 1\\eta \\[ \\theta \\] 1\\theta \\[ \\lambda \\] 1\\lambda \\[ \\mu \\] 1\\mu \\[ \\nu \\] 1\\nu \\[ \\pi \\] 1\\pi \\[ \\rho \\] 1\\rho \\[ \\sigma \\] 1\\sigma \\[ \\tau \\] 1\\tau \\[ \\varphi \\] 1\\varphi \\[ \\omega \\] 1\\omega 三角函数 \\[ \\sin \\] 1\\sin 对数函数 \\[ \\ln2 \\] 1\\ln2 \\[ log_28 \\] 1\\log_28 \\[ lg10 \\] 1\\lg10 关系运算符 \\[ \\pm \\] 1\\pm \\[ \\times \\] 1\\times \\[ \\cdot \\] 1\\cdot \\[ \\div \\] 1\\div \\[ \\approx \\] 1\\approx \\[ \\neq \\] 1\\neq \\[ \\leq \\] 1\\leq \\[ \\geq \\] 1\\geq \\[ \\in \\] 1\\in \\[ \\cap \\] 1\\cap \\[ \\cup \\] 1\\cup 参考 使用Typora添加数学公式：https://www.typora.net/1109.html","categories":[{"name":"工具速查","slug":"工具速查","permalink":"https://liujk6525.github.io/categories/%E5%B7%A5%E5%85%B7%E9%80%9F%E6%9F%A5/"}],"tags":[{"name":"Typora","slug":"Typora","permalink":"https://liujk6525.github.io/tags/Typora/"}]},{"title":"基于遗传算法的TSP算法","slug":"基于遗传算法的TSP算法","date":"2023-05-07T08:48:51.000Z","updated":"2023-05-26T05:30:40.766Z","comments":true,"path":"TSP问题/基于遗传算法的TSP算法/","link":"","permalink":"https://liujk6525.github.io/TSP%E9%97%AE%E9%A2%98/%E5%9F%BA%E4%BA%8E%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E7%9A%84TSP%E7%AE%97%E6%B3%95/","excerpt":"理论基础 遗传算法 遗传算法（Genetic Algorithm, GA）起源于对生物系统所进行的计算机模拟研究。它是模仿自然界生物进化机制发展起来的随机全局搜索和优化方法，借鉴了达尔文的进化论和孟德尔的遗传学说。其本质是一种高效、并行、全局搜索的方法。","text":"理论基础 遗传算法 遗传算法（Genetic Algorithm, GA）起源于对生物系统所进行的计算机模拟研究。它是模仿自然界生物进化机制发展起来的随机全局搜索和优化方法，借鉴了达尔文的进化论和孟德尔的遗传学说。其本质是一种高效、并行、全局搜索的方法。 TSP问题 TSP (traveling salesman problem,旅行商问题) 是典型的NP完全问题，即其最坏情况下的时间复杂度随着问题规模的增大按指数方式增长，到目前为止还未找到一个多项式时间的有效算法。 ​ TSP问题可描述为：已知n个城市相互之间的距离，某一旅行商从某个城市出发访问每个城市一次且仅一次，最后回到出发城市，如何安排才使其所走路线最短。简言之，就是寻找一条最短的遍历n个城市的路径，或者说搜索自然子集X={1,2,….n} ( X的元素表示对n个 城市的编号 ) 的一个排列π(X)={V1,V2,…,Vn},使 \\[ T_d = \\sum_{i=1}^{n-1}{d(V_i,V_(i+1))}+d(V_n,V_1) \\] 取最小值，其中 \\[ d(V_i,V_i+1) \\] 表示城市Vi到城市Vi+1的距离。 ## 问题描述 通过搭建的双目视觉检测系统将苹果的三维坐标获取到后，需要对其进行路径规划，即寻找出一条最短的遍历所有目标苹果的路径 表1 14个苹果的位置坐标 目标苹果编号 X坐标 Y坐标 Z坐标 目标苹果编号 X坐标 Y坐标 Z坐标 1 16.47 96.10 45.25 8 17.20 96.29 48.62 2 16.47 94.44 44.25 9 16.30 97.38, 42.98 3 20.09 92.54 45.63 10 14.05 98.12, 41.86 4 22.39 93.37 47.21 11 16.53 97.38 ,48.52 5 25.23 97.24 44.29 12 21.52 95.59 46.25 6 22.00 96.05 48.45 13 19.41 97.13 45.71 7 20.47 97.02 47.56 14 20.09 92.55 44.44 解决思路及步骤 遗传算法TSP问题的流程图 编码 ​ 对于n个苹果的TSP问题，染色体分为n段，例如检测到10个苹果{1,2,3,4,5,6,7,8,9,10}，则|1|0|2|4|5|6|8|7|9|3就是一个合法的染色体。 种群初始化 ​ 编码后，需要初始化一个种群作为起始解，初始化种群的数目一般根据经验得到，种群的数量按苹果的规模确定，参考的取值为50~200。 适应度函数 ​ 设k1|k2|ki|…|kn|为一个采用整数编码的染色体，d(ki,kj)为苹果ki到苹果kj的欧式距离，则该个体的适应度为 \\[ fitness = \\frac{1}{\\sum_{i=1}^{n-1}{d(K_i,K_(i+1))}+d(K_n,K_1)} \\] 即适应度函数恰好遍历了n个苹果，再回到第一个苹果的距离的倒数。优化的目标就是选择适应度函数值尽可能大的染色体。 选择操作 ​ 从旧群体中以一定概率选择个体到新群体中，个体被选中的概率跟适应度值有关，个体适应度值越大，被选中的概率越大。 交又操作 部分映射杂交，确定交叉操作的父代，将父代样本两两分组，每组重复以下过程。 ​ 假定城市数为10)，产生两个[1,10]区间内的随机整数和r1和r2，确定两个位置，对两位置的中间数据进行交叉，如r1=4,r2=7 (其实就是把四和七中间的位置给互换，包括四七位置本身) 1 2 3 4 5 6 7 8 9 10 9 5 1 3 7 4 2 10 8 6 10 5 4 6 3 8 7 2 1 9 交叉后为 1 2 3 4 5 6 7 8 9 10 9 5 1 6 3 8 7 10 * * 10 5 * 3 7 4 2 * 1 9 从表格中可以看到：同一个个体中有重复的编号，处理办法就是把不重复的数据保留，有重复的数据采用部分映射的方法消除冲突。就是利用四七段的映射关系来确定，比如第一个个体的九位置，它本来的数据是8的，现在这个数据8跑到六位置了，而原来的六位置的数据是4，所以现在的九位置变成4，最后在看这个个体缺少哪个数据，给补上就是了。 变异操作 ​ 随机选取两个点，将其对换位置。 ​ 产生两个[1,10]范围内的随机整数r1和r2，确定两个位置，将其对换位置，如r1=4,r2=7 1 2 3 4 5 6 7 8 9 10 9 5 1 3 7 4 2 10 8 6 变异后为 1 2 3 4 5 6 7 8 9 10 9 5 1 2 7 4 3 10 8 6 逆转操作 ​ 为改善遗传算法的局部搜索能力。这里的“进化”是指逆转算子的单方向性，即只有经逆转后，适应度值有提高的才接受下来，否则逆转无效。 ​ 产生两个[1,10]区间内的随机整数片r1和r2，确定两个位置，将其对换位置，如r1=4，r2=7 1 2 3 4 5 6 7 8 9 10 9 5 1 3 7 4 2 10 8 6 逆转后 1 2 3 4 5 6 7 8 9 10 9 5 1 4 7 3 2 10 8 6 ​ 对每个个体进行交叉变异，然后代人适应度函数进行评估，选择出适应值大的个体进行下一代的交叉和变异以及逆转操作。 循环操作：判断是否满足设定的最大遗传代数,不满足则跳入适应度值的计算；否则，结束遗传操作。 代码实现 适应值变化 苹果位置图 路径规划图 最优解 参考文献 [1]史峰. MATLAB智能算法30个案例分析[M]. 北京航空航天大学出版社, 2011.","categories":[{"name":"TSP问题","slug":"TSP问题","permalink":"https://liujk6525.github.io/categories/TSP%E9%97%AE%E9%A2%98/"}],"tags":[{"name":"Matlab","slug":"Matlab","permalink":"https://liujk6525.github.io/tags/Matlab/"},{"name":"路径规划","slug":"路径规划","permalink":"https://liujk6525.github.io/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"}]}],"categories":[{"name":"机器学习","slug":"机器学习","permalink":"https://liujk6525.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"目标检测","slug":"目标检测","permalink":"https://liujk6525.github.io/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"},{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://liujk6525.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"},{"name":"OpenCV","slug":"OpenCV","permalink":"https://liujk6525.github.io/categories/OpenCV/"},{"name":"轨迹优化","slug":"轨迹优化","permalink":"https://liujk6525.github.io/categories/%E8%BD%A8%E8%BF%B9%E4%BC%98%E5%8C%96/"},{"name":"路径规划","slug":"路径规划","permalink":"https://liujk6525.github.io/categories/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"},{"name":"TSP问题","slug":"TSP问题","permalink":"https://liujk6525.github.io/categories/TSP%E9%97%AE%E9%A2%98/"},{"name":"工具速查","slug":"工具速查","permalink":"https://liujk6525.github.io/categories/%E5%B7%A5%E5%85%B7%E9%80%9F%E6%9F%A5/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://liujk6525.github.io/tags/Python/"},{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","permalink":"https://liujk6525.github.io/tags/Jupyter-Notebook/"},{"name":"ssd.pytorch","slug":"ssd-pytorch","permalink":"https://liujk6525.github.io/tags/ssd-pytorch/"},{"name":"JupyterLab","slug":"JupyterLab","permalink":"https://liujk6525.github.io/tags/JupyterLab/"},{"name":"Jetson Nano","slug":"Jetson-Nano","permalink":"https://liujk6525.github.io/tags/Jetson-Nano/"},{"name":"Yolo-v5","slug":"Yolo-v5","permalink":"https://liujk6525.github.io/tags/Yolo-v5/"},{"name":"Yolov5","slug":"Yolov5","permalink":"https://liujk6525.github.io/tags/Yolov5/"},{"name":"Git","slug":"Git","permalink":"https://liujk6525.github.io/tags/Git/"},{"name":"Anaconda","slug":"Anaconda","permalink":"https://liujk6525.github.io/tags/Anaconda/"},{"name":"Matlab","slug":"Matlab","permalink":"https://liujk6525.github.io/tags/Matlab/"},{"name":"python","slug":"python","permalink":"https://liujk6525.github.io/tags/python/"},{"name":"Hexo","slug":"Hexo","permalink":"https://liujk6525.github.io/tags/Hexo/"},{"name":"路径规划","slug":"路径规划","permalink":"https://liujk6525.github.io/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"},{"name":"Typora","slug":"Typora","permalink":"https://liujk6525.github.io/tags/Typora/"}]}