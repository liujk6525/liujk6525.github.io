{
    "version": "https://jsonfeed.org/version/1",
    "title": "你不是单打独斗 • All posts by \"机器学习\" category",
    "description": "",
    "home_page_url": "https://liujk6525.github.io",
    "items": [
        {
            "id": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/",
            "url": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/",
            "title": "贝叶斯算法",
            "date_published": "2023-06-07T07:56:38.000Z",
            "content_html": "<h1 id=\"贝叶斯算法\">贝叶斯算法</h1>\r\n<ul>\r\n<li>总体信息：当前总体样本符合某种分布。比如抛硬币符合二项 分布；学生的某一科的成绩符合正态分布。</li>\r\n<li>样本信息：通过抽样得到的部分样本的某种分布。</li>\r\n<li>抽样信息=总体信息+样本信息</li>\r\n<li>先验信息：抽样之前，有关推断问题中未知参数的一些信息， 通常来自于经验或历史资料。</li>\r\n</ul>\r\n<p>基于抽样信息进行统计推断的理论和方法称为经典统计学。</p>\r\n<p>基于抽样信息+先验信息进行统计推断的方法和理 论，称为贝叶斯统计学。</p>\r\n<h2 id=\"贝叶斯定理\"><a href=\"https://baike.baidu.com/item/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F/9683982?fr=aladdin\">贝叶斯定理</a></h2>\r\n<p>已知<span class=\"math inline\">\\(P(X|H)\\)</span>，要求解<span class=\"math inline\">\\(P(H|X)\\)</span> <span class=\"math display\">\\[\r\nP(H|X)=\\frac{P(X|H)P(H)}{P(X)}\r\n\\]</span></p>\r\n<h2 id=\"示例代码\">示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入算法包以及数据集</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report,confusion_matrix</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> MultinomialNB,BernoulliNB,GaussianNB</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">x_train,x_test,y_train,y_test = train_test_split(iris.data, iris.target) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并拟合模型</span></span><br><span class=\"line\">mul_nb = GaussianNB()</span><br><span class=\"line\">mul_nb.fit(x_train,y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 评估</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(mul_nb.predict(x_test),y_test))</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607165131324.png\"  style=\"zoom: 67%;\" /></p>\r\n<h2 id=\"词袋模型bag-of-words\">词袋模型(Bag of Words)</h2>\r\n<p>Bag of words model（BoW）最早出现在自然语言处理（Natural Language Processing）和信息检索 （Information Retrieval）领域。</p>\r\n<p>该模型忽略掉文本的语法和语序等要素，将其仅仅看作是若干个词汇的集合，文档中每个单词的出现都是独立的。BoW使用一组无序的单词(words)来表达一段文字或一个文档。</p>\r\n<p>简单例子</p>\r\n<p>首先给出两个简单的文本文档如下：</p>\r\n<p>John likes to watch movies. Mary likes too.</p>\r\n<p>John also likes to watch football games.</p>\r\n<p>对于上述两个文档中出现的单词，构建如下一个词典 (dictionary)：</p>\r\n<p>{“John”: 1, “likes”: 2,“to”: 3, “watch”: 4, “movies”: 5,“also”: 6, “football”: 7, “games”: 8,“Mary”: 9, “too”: 10}</p>\r\n<p>上面的词典中包含10个单词, 每个单词有唯一的索引, 那么每个文本可以使用一个10维的向量来表示。</p>\r\n<p>[1, 2, 1, 1, 1, 0, 0, 0, 1, 1]</p>\r\n<p>[1, 1,1, 1, 0, 1, 1, 1, 0, 0]</p>\r\n<p>该向量与原来文本中单词出现的顺序没有关系，而是词典中每个单词在文本中出现的频率。</p>\r\n<h2 id=\"tf-idf\">TF-IDF</h2>\r\n<p>TF（Term Frequency） 词频</p>\r\n<p>IDF （Inverse Document Frequency）逆文档频率</p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://www.bilibili.com/video/BV1Rt411q7WJ?p=60\">贝叶斯算法</a></p>\r\n",
            "tags": [
                "Python",
                "Jupyter Notebook"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/",
            "url": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/",
            "title": "集成学习",
            "date_published": "2023-06-07T01:32:09.000Z",
            "content_html": "<h1 id=\"集成学习ensemble-learning\"><a href=\"https://baike.baidu.com/item/%E5%88%86%E7%B1%BB%E5%99%A8%E9%9B%86%E6%88%90/21512231?fromtitle=%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0&amp;fromid=3440721&amp;fr=aladdin\">集成学习（Ensemble Learning）</a></h1>\r\n<p>集成学习就是组合多个学习器，最后可以得到一个更 好的学习器。</p>\r\n<p>集成学习算法：</p>\r\n<ol type=\"1\">\r\n<li><p>个体学习器之间不存在强依赖关系，装袋（Bagging）</p></li>\r\n<li><p>随机森林（Random Forest）</p></li>\r\n<li><p>个体学习器之间存在强依赖关系，提升（Boosting）</p></li>\r\n<li><p>Stacking</p></li>\r\n</ol>\r\n<span id=\"more\"></span>\r\n<h2 id=\"bagging\">Bagging</h2>\r\n<p>Bagging也叫做Bootstrap Aggregating，是在原始 数据集选择S次后得到S个新数据集的一种技术。是一 种有放回抽样。</p>\r\n<p>原始训练数据集<span class=\"math inline\">\\(0,1,2,3,4,5,6,7,8,9\\)</span></p>\r\n<p>Bagging采样<span class=\"math inline\">\\(1,3,5,2,6,4,2,5,7,0——未采样8,9\\)</span></p>\r\n<h3 id=\"示例代码\">示例代码</h3>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入算法包以及数据集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> neighbors</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> BaggingClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">划分数据集</span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">x_data = iris.data[:,:<span class=\"number\">2</span>]</span><br><span class=\"line\">y_data = iris.target</span><br><span class=\"line\"></span><br><span class=\"line\">x_train,x_test,y_train,y_test = train_test_split(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并训练KNN模型</span></span><br><span class=\"line\">knn = neighbors.KNeighborsClassifier()</span><br><span class=\"line\">knn.fit(x_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot</span>(<span class=\"params\">model</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">    x_min, x_max = x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">    y_min, y_max = x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">    xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                         np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    z = model.predict(np.c_[xx.ravel(), yy.ravel()])<span class=\"comment\"># ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据</span></span><br><span class=\"line\">    z = z.reshape(xx.shape)</span><br><span class=\"line\">    <span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">    cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">plot(knn)</span><br><span class=\"line\"><span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;knn&quot;</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\">knn.score(x_test, y_test) <span class=\"comment\"># KNN模型准确率</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并训练bagging_knn模型</span></span><br><span class=\"line\">bagging_knn = BaggingClassifier(knn, n_estimators=<span class=\"number\">100</span>)</span><br><span class=\"line\">bagging_knn.fit(x_train, y_train)</span><br><span class=\"line\">plot(bagging_knn)</span><br><span class=\"line\"><span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;bagging_knn&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\">bagging_knn.score(x_test, y_test) <span class=\"comment\"># bagging_knn模型准确率</span></span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607113057905.png\"  style=\"zoom:50%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607113349947.png\"  style=\"zoom:50%;\" /></p>\r\n<h2 id=\"随机森林random-forest\"><a href=\"https://baike.baidu.com/item/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/1974765?fr=aladdin\">随机森林（Random Forest）</a></h2>\r\n<p>算法流程：</p>\r\n<ol type=\"1\">\r\n<li><p>随机选取样本：在样本集用<strong>bagging</strong>的方式随机选择n个样本。</p></li>\r\n<li><p>随机选取特征：从所有属性d中随机选择k个属性（k&lt;d），然后从k个属性中选择最佳分割属性作为节点建立 CART决策树。</p></li>\r\n<li><p>重复以上两个步骤m次，建立m棵CART决策树。</p></li>\r\n<li><p>这m棵CART决策树形成随机森林，通过投票表决结 果，决定数据属于哪一类。</p></li>\r\n</ol>\r\n<h3 id=\"示例代码-1\">示例代码</h3>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> RandomForestClassifier <span class=\"comment\"># 集成学习中的随机森林模块</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;LR-testSet2.txt&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[:,:-<span class=\"number\">1</span>]</span><br><span class=\"line\">y_data = data[:,-<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">plt.scatter(x_data[:,<span class=\"number\">0</span>],x_data[:,<span class=\"number\">1</span>],c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 划分数据集</span></span><br><span class=\"line\">x_train,x_test,y_train,y_test = train_test_split(x_data, y_data, test_size = <span class=\"number\">0.5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot</span>(<span class=\"params\">model</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">    x_min, x_max = x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">    y_min, y_max = x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">    xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                         np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    z = model.predict(np.c_[xx.ravel(), yy.ravel()])<span class=\"comment\"># ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据</span></span><br><span class=\"line\">    z = z.reshape(xx.shape)</span><br><span class=\"line\">    <span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">    cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\">    <span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">    plt.scatter(x_test[:, <span class=\"number\">0</span>], x_test[:, <span class=\"number\">1</span>], c=y_test)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并训练随机森林模型</span></span><br><span class=\"line\">RF = RandomForestClassifier(n_estimators=<span class=\"number\">50</span>)</span><br><span class=\"line\">RF.fit(x_train, y_train)</span><br><span class=\"line\">plot(RF)</span><br><span class=\"line\">RF.score(x_test, y_test)</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607114037530.png\"  style=\"zoom:50%;\" /></p>\r\n<h2 id=\"boosting\"><a href=\"https://baike.baidu.com/item/Boosting/1403912?fr=aladdin\">Boosting</a></h2>\r\n<p>AdaBoost （Adaptive Boosting）算法，它的自适应在于，前一个基本分类器被错误分类的样本的权值会增大，而正确分类的样本的权值会减小，并再次用来训练下一个基本分类器。同时，在每一轮迭代中，加入一个新的弱分类器，直到达到某个预定的足够小的错误率或达到预先指定的最大迭代次数才确定最终的强分类器。</p>\r\n<p>算法流程：</p>\r\n<ol type=\"1\">\r\n<li><p>初始化训练数据的权值分布<span class=\"math inline\">\\(D1\\)</span>。假设有<span class=\"math inline\">\\(N\\)</span>个训练样本数据，则每一个训练样本最开始时，都被赋予 相同的权值<span class=\"math inline\">\\(w~1~=1/N\\)</span>。</p></li>\r\n<li><p>训练弱分类器<span class=\"math inline\">\\(h_i\\)</span>。</p>\r\n<ul>\r\n<li><p>如果某个训练样本点，被弱分类器<span class=\"math inline\">\\(h_i\\)</span>准确地分类，那么在构造下一个训练集中，它对应的权值要减小；</p></li>\r\n<li><p>如果某个训练样本点，被弱分类器<span class=\"math inline\">\\(h_i\\)</span>错误分类，那么它的权值就应该增大。权值更新过的样本集被用于训练下一个分类器，整个训练过程如此迭代地进行下去。</p></li>\r\n</ul></li>\r\n<li><p>将各个训练得到的弱分类器组合成一个强分类器。各个弱分类器的训练过程结束后，</p>\r\n<ul>\r\n<li>加大分类误差率小的弱分类器的权重，使其在最终的分类函数中起着较大的决定作用，</li>\r\n<li>降低分类误差率大的弱分类器的权重，使其在最终的分类函数中起着较小的决定作用。</li>\r\n</ul></li>\r\n</ol>\r\n<h3 id=\"示例代码-2\">示例代码</h3>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> AdaBoostClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_gaussian_quantiles</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成2维正态分布，生成的数据按分位数分为两类，500个样本,2个样本特征</span></span><br><span class=\"line\">x1, y1 = make_gaussian_quantiles(n_samples=<span class=\"number\">500</span>, n_features=<span class=\"number\">2</span>,n_classes=<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"comment\"># 生成2维正态分布，生成的数据按分位数分为两类，400个样本,2个样本特征均值都为3</span></span><br><span class=\"line\">x2, y2 = make_gaussian_quantiles(mean=(<span class=\"number\">3</span>, <span class=\"number\">3</span>), n_samples=<span class=\"number\">500</span>, n_features=<span class=\"number\">2</span>, n_classes=<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"comment\"># 将两组数据合成一组数据</span></span><br><span class=\"line\">x_data = np.concatenate((x1, x2))</span><br><span class=\"line\">y_data = np.concatenate((y1, - y2 + <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># AdaBoost模型</span></span><br><span class=\"line\">model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=<span class=\"number\">3</span>),n_estimators=<span class=\"number\">10</span>)</span><br><span class=\"line\"><span class=\"comment\"># 训练模型</span></span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">x_min, x_max = x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">y_min, y_max = x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                     np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取预测值</span></span><br><span class=\"line\">z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class=\"line\">z = z.reshape(xx.shape)</span><br><span class=\"line\"><span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\"><span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 模型准确率</span></span><br><span class=\"line\">model.score(x_data,y_data)</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607153300730.png\"  style=\"zoom:50%;\" /></p>\r\n<h2 id=\"stacking\">Stacking</h2>\r\n<p>使用多个不同的分类器对训练集进预测，把预测 得到的结果作为一个次级分类器的输入。次级分 类器的输出是整个模型的预测结果。</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607153502918.png\"  style=\"zoom:67%;\" /></p>\r\n<h3 id=\"示例代码-3\">示例代码</h3>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets  </span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> model_selection  </span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LogisticRegression</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier  </span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> mlxtend.classifier <span class=\"keyword\">import</span> StackingClassifier</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据集</span></span><br><span class=\"line\">iris = datasets.load_iris()  </span><br><span class=\"line\"><span class=\"comment\"># 只要第1,2列的特征</span></span><br><span class=\"line\">x_data, y_data = iris.data[:, <span class=\"number\">1</span>:<span class=\"number\">3</span>], iris.target  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义三个不同的分类器</span></span><br><span class=\"line\">clf1 = KNeighborsClassifier(n_neighbors=<span class=\"number\">1</span>)  </span><br><span class=\"line\">clf2 = DecisionTreeClassifier() </span><br><span class=\"line\">clf3 = LogisticRegression()  </span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 定义一个次级分类器</span></span><br><span class=\"line\">lr = LogisticRegression()  </span><br><span class=\"line\">sclf = StackingClassifier(classifiers=[clf1, clf2, clf3],   </span><br><span class=\"line\">                          meta_classifier=lr)</span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"keyword\">for</span> clf,label <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>([clf1, clf2, clf3, sclf],</span><br><span class=\"line\">                      [<span class=\"string\">&#x27;KNN&#x27;</span>,<span class=\"string\">&#x27;Decision Tree&#x27;</span>,<span class=\"string\">&#x27;LogisticRegression&#x27;</span>,<span class=\"string\">&#x27;StackingClassifier&#x27;</span>]):  </span><br><span class=\"line\">    scores = model_selection.cross_val_score(clf, x_data, y_data, cv=<span class=\"number\">3</span>, scoring=<span class=\"string\">&#x27;accuracy&#x27;</span>)  </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Accuracy: %0.2f [%s]&quot;</span> % (scores.mean(), label)) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可视化   </span></span><br><span class=\"line\">sclf.fit(x_train,y_train)</span><br><span class=\"line\">plot(sclf)</span><br><span class=\"line\">plt.scatter(x_data[:,<span class=\"number\">0</span>],x_data[:,<span class=\"number\">1</span>],c=y_data)    </span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607155449811.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://www.bilibili.com/video/BV1Rt411q7WJ/?p=55&amp;spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=fe8e916be2bd597efffd8dfd95249141\">集成学习</a></p>\r\n",
            "tags": [
                "Python",
                "Jupyter Notebook"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/",
            "url": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/",
            "title": "决策树",
            "date_published": "2023-06-06T12:25:49.000Z",
            "content_html": "<h1 id=\"决策树-decision-tree\"><a href=\"https://baike.baidu.com/item/%E5%86%B3%E7%AD%96%E6%A0%91/10377049?fr=aladdin\">决策树 （Decision Tree）</a></h1>\r\n<p>比较适合分析离散数据。 如果是连续数据要先转成离散数据再做分析</p>\r\n<h2 id=\"熵entropy\">熵（entropy）</h2>\r\n<p>1948年，香浓提出了“<a href=\"https://baike.baidu.com/item/%E4%BF%A1%E6%81%AF%E7%86%B5/7302318?fr=aladdin\">信息熵</a>”的概念，</p>\r\n<p><strong>一条信息的信息量大小和它的不确定性有直接的关系， 要搞清楚一件非常非常不确定的事情，或者是一无所知的事情，需要了解大量信息。—&gt;信息量的度量就等于不确定性的多少。</strong></p>\r\n<span id=\"more\"></span>\r\n<p>信息熵公式： <span class=\"math display\">\\[\r\nH[x]=-\\sum_{x}p(x)logp(x)\r\n\\]</span></p>\r\n<h2 id=\"id3算法\"><a href=\"https://baike.baidu.com/item/ID3%E7%AE%97%E6%B3%95/5522381?fr=aladdin\">ID3算法</a></h2>\r\n<p>决策树会选择最大化信息增益来对结点进行划分。</p>\r\n<p>信息增益（Information Gain）计算： <span class=\"math display\">\\[\r\nInfo(D)=-\\sum_{i=1}^{m}p_ilog(p_i)\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nInfo_A(D)=-\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}\\times Info(D_j)\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nGain(A)=Info(D)-Info_A(D)\r\n\\]</span></p>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>RID</th>\r\n<th>age</th>\r\n<th>income</th>\r\n<th>student</th>\r\n<th>credit_rating</th>\r\n<th>class_buys_computer</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td>1</td>\r\n<td>youth</td>\r\n<td>high</td>\r\n<td>no</td>\r\n<td>fair</td>\r\n<td>no</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>2</td>\r\n<td>youth</td>\r\n<td>high</td>\r\n<td>no</td>\r\n<td>excellent</td>\r\n<td>no</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>3</td>\r\n<td>middle_aged</td>\r\n<td>high</td>\r\n<td>no</td>\r\n<td>fair</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>4</td>\r\n<td>senior</td>\r\n<td>medium</td>\r\n<td>no</td>\r\n<td>fair</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>5</td>\r\n<td>senior</td>\r\n<td>low</td>\r\n<td>yes</td>\r\n<td>fair</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>6</td>\r\n<td>senior</td>\r\n<td>low</td>\r\n<td>yes</td>\r\n<td>excellent</td>\r\n<td>no</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>7</td>\r\n<td>middle_aged</td>\r\n<td>low</td>\r\n<td>yes</td>\r\n<td>excellent</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>8</td>\r\n<td>youth</td>\r\n<td>medium</td>\r\n<td>no</td>\r\n<td>fair</td>\r\n<td>no</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>9</td>\r\n<td>youth</td>\r\n<td>low</td>\r\n<td>yes</td>\r\n<td>fair</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>10</td>\r\n<td>senior</td>\r\n<td>medium</td>\r\n<td>yes</td>\r\n<td>fair</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>11</td>\r\n<td>youth</td>\r\n<td>medium</td>\r\n<td>yes</td>\r\n<td>excellent</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>12</td>\r\n<td>middle_aged</td>\r\n<td>medium</td>\r\n<td>no</td>\r\n<td>excellent</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>13</td>\r\n<td>middle_aged</td>\r\n<td>high</td>\r\n<td>yes</td>\r\n<td>fair</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>14</td>\r\n<td>senior</td>\r\n<td>medium</td>\r\n<td>no</td>\r\n<td>excellent</td>\r\n<td>no</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<p>计算<strong>age</strong>的信息增益: <span class=\"math display\">\\[\r\nInfo(D)=-\\frac{9}{14}log_2(\\frac{9}{14})-\\frac{5}{14}log_2(\\frac{5}{14})=0.94\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nInfo_{age}(D)=\\frac{5}{14}(-\\frac{2}{5}log_2\\frac{2}{5}-\\frac{3}{5}log_2\\frac{3}{5})+\r\n\\frac{4}{14}(-\\frac{4}{4}log_2\\frac{4}{4}-\\frac{0}{4}log_2\\frac{0}{4})+\r\n\\frac{5}{14}(-\\frac{3}{5}log_2\\frac{3}{5}-\\frac{2}{5}log_2\\frac{2}{5})\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nGain(age)=Info(D)-Info_A(D)=0.94-0.694=0.246\r\n\\]</span></p>\r\n<p>其他的也是类似计算。</p>\r\n<h2 id=\"c4.5算法\"><a href=\"https://baike.baidu.com/item/C4.5%E7%AE%97%E6%B3%95/20814636\">C4.5算法</a></h2>\r\n<p>信息增益的方法倾向于首先选择因子数较多的变量 。</p>\r\n<p>信息增益的改进：增益率 <span class=\"math display\">\\[\r\nSplitInfo_A(D)=-\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}\\times log_2(\\frac{|D_j|}{|D|})\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nGainRatio(A)=\\frac{Gain(A)}{SpliInfo_A(D)}\r\n\\]</span></p>\r\n<h2 id=\"cart算法\"><a href=\"https://baike.baidu.com/item/CART/17679070\">CART算法</a></h2>\r\n<p>CART决策树的生成就是递归地构建二叉决策树的过程。</p>\r\n<p>CART用基尼（Gini）系数最小化准则来进行特征选择，生成二叉树。</p>\r\n<p>Gini系数计算： <span class=\"math display\">\\[\r\nGini(D)=1-\\sum_{i=1}^{m}p_i^2\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nGini_A(D)=\\frac{|D_1|}{|D|}Gini(D_1)+\\frac{|D_2|}{|D|}Gini(D_2)\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\Delta Gini(A)=Gini(D)-Gini_A(D)\r\n\\]</span></p>\r\n<p>优点：小规模数据集有效</p>\r\n<p>缺点： 处理连续变量不好 类别较多时，错误增加的比较快 不能处理大量数据</p>\r\n<h2 id=\"线性二分类示例代码\">线性二分类示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree <span class=\"comment\"># 决策树模块</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;LR-testSet.csv&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[:,:-<span class=\"number\">1</span>]</span><br><span class=\"line\">y_data = data[:,-<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">plt.scatter(x_data[:,<span class=\"number\">0</span>],x_data[:,<span class=\"number\">1</span>],c=y_data) </span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建决策树模型</span></span><br><span class=\"line\">model = tree.DecisionTreeClassifier()</span><br><span class=\"line\"><span class=\"comment\"># 输入数据建立模型</span></span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">x_min, x_max = x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">y_min, y_max = x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                     np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">z = model.predict(np.c_[xx.ravel(), yy.ravel()])<span class=\"comment\"># ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据</span></span><br><span class=\"line\">z = z.reshape(xx.shape)</span><br><span class=\"line\"><span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\"><span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试与评估</span></span><br><span class=\"line\">predictions = model.predict(x_data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(predictions,y_data))</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607084609741.png\"  style=\"zoom:50%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230606214438933.png\"  style=\"zoom:67%;\" /></p>\r\n<h2 id=\"非线性二分类示例代码\">非线性二分类示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;LR-testSet2.txt&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[:,:-<span class=\"number\">1</span>]</span><br><span class=\"line\">y_data = data[:,-<span class=\"number\">1</span>]</span><br><span class=\"line\">    </span><br><span class=\"line\">plt.scatter(x_data[:,<span class=\"number\">0</span>],x_data[:,<span class=\"number\">1</span>],c=y_data) <span class=\"comment\"># s散点图</span></span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#分割数据</span></span><br><span class=\"line\">x_train,x_test,y_train,y_test = train_test_split(x_data, y_data) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建决策树模型</span></span><br><span class=\"line\"><span class=\"comment\"># max_depth，树的深度</span></span><br><span class=\"line\"><span class=\"comment\"># min_samples_split 内部节点再划分所需最小样本数</span></span><br><span class=\"line\">model = tree.DecisionTreeClassifier(max_depth=<span class=\"number\">7</span>,min_samples_split=<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"comment\"># 拟合模型</span></span><br><span class=\"line\">model.fit(x_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">x_min, x_max = x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">y_min, y_max = x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                     np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">z = model.predict(np.c_[xx.ravel(), yy.ravel()])<span class=\"comment\"># ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据</span></span><br><span class=\"line\">z = z.reshape(xx.shape)</span><br><span class=\"line\"><span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\"><span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试并评估</span></span><br><span class=\"line\">predictions = model.predict(x_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(predictions,y_test))</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607084429752.png\"  style=\"zoom: 50%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607084526669.png\"  style=\"zoom:67%;\" /></p>\r\n<h2 id=\"回归树示例代码\">回归树示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;data.csv&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[:,<span class=\"number\">0</span>,np.newaxis]</span><br><span class=\"line\">y_data = data[:,<span class=\"number\">1</span>,np.newaxis]</span><br><span class=\"line\">plt.scatter(x_data,y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\">model = tree.DecisionTreeRegressor(max_depth=<span class=\"number\">5</span>)</span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\">x_test = np.linspace(<span class=\"number\">20</span>,<span class=\"number\">80</span>,<span class=\"number\">100</span>)</span><br><span class=\"line\">x_test = x_test[:,np.newaxis]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">plt.plot(x_data, y_data, <span class=\"string\">&#x27;b&#x27;</span>)</span><br><span class=\"line\">plt.plot(x_test, model.predict(x_test), <span class=\"string\">&#x27;r&#x27;</span>) </span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607090010220.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://www.bilibili.com/video/BV1Rt411q7WJ?p=50&amp;vd_source=fe8e916be2bd597efffd8dfd95249141\">决策树</a></p>\r\n",
            "tags": [
                "Python",
                "Jupyter Notebook"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95/",
            "url": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95/",
            "title": "KNN算法",
            "date_published": "2023-06-06T12:05:23.000Z",
            "content_html": "<h1 id=\"k最近邻k-nearest-neighborknn分类算法\"><a href=\"https://baike.baidu.com/item/k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/9512781?fr=aladdin\">K最近邻（K-Nearest Neighbor，KNN）</a>分类算法</h1>\r\n<ol type=\"1\">\r\n<li>为了判断未知实例的类别，以所有已知类别的实例作为 参照选择参数K</li>\r\n<li>计算未知实例与所有已知实例的距离</li>\r\n<li>选择最近K个已知实例</li>\r\n<li>根据少数服从多数的投票法则(majority-voting)，让 未知实例归类为K个最邻近样本中最多数的类别</li>\r\n</ol>\r\n<span id=\"more\"></span>\r\n<p>欧氏距离 <span class=\"math display\">\\[\r\nE(x,y)=\\sqrt{\\sum_{i=0}^{n}(x_i-y_i)^2}\r\n\\]</span> <a href=\"https://www.cnblogs.com/belfuture/p/5871452.html\">其他的距离衡量</a>：余弦值距离（cos），相关度（correlation），曼哈顿距离（Manhattan distance）</p>\r\n<p>算法缺点：</p>\r\n<ul>\r\n<li>算法复杂度较高（需要比较所有已知实例与要分类的实例）</li>\r\n<li>当其样本分布不平衡时，比如其中一类样本过大（实例数量过多）占主导的时候，新的未知实例容易被归类为这个主导样本，因为这类样本实例的数量过大，但这个新的未知实例实际并没有接近目标样本</li>\r\n</ul>\r\n<h2 id=\"示例代码\">示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入算法包以及数据集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> neighbors</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(iris)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 打乱数据切分数据集</span></span><br><span class=\"line\"><span class=\"comment\"># x_train,x_test,y_train,y_test = train_test_split(iris.data, iris.target, test_size=0.2) #分割数据0.2为测试数据，0.8为训练数据</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#打乱数据</span></span><br><span class=\"line\">data_size = iris.data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">index = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(data_size)] </span><br><span class=\"line\">random.shuffle(index)  </span><br><span class=\"line\">iris.data = iris.data[index]</span><br><span class=\"line\">iris.target = iris.target[index]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#切分数据集</span></span><br><span class=\"line\">test_size = <span class=\"number\">40</span></span><br><span class=\"line\">x_train = iris.data[test_size:]</span><br><span class=\"line\">x_test =  iris.data[:test_size]</span><br><span class=\"line\">y_train = iris.target[test_size:]</span><br><span class=\"line\">y_test = iris.target[:test_size]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 构建模型</span></span><br><span class=\"line\">model = neighbors.KNeighborsClassifier(n_neighbors=<span class=\"number\">3</span>)</span><br><span class=\"line\">model.fit(x_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试和评估</span></span><br><span class=\"line\">prediction = model.predict(x_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(y_test, prediction))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230606202144425.png\"  style=\"zoom: 67%;\" /></p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://www.bilibili.com/video/BV1Rt411q7WJ?p=41&amp;vd_source=fe8e916be2bd597efffd8dfd95249141\">KNN算法</a></p>\r\n",
            "tags": [
                "Python",
                "Jupyter Notebook"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/",
            "url": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/",
            "title": "逻辑回归",
            "date_published": "2023-06-05T13:32:23.000Z",
            "content_html": "<h1 id=\"逻辑回归logistic-regression\"><a href=\"https://baike.baidu.com/item/logistic%E5%9B%9E%E5%BD%92/2981575?fromtitle=%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92&amp;fromid=17202449&amp;fr=aladdin\">逻辑回归（Logistic Regression）</a></h1>\r\n<p>是一种广义的线性回归分析模型，与多重线性回归有很多相同之处。它们的模型形式基本上相同，都具有$ w’x+b$，其区别在于他们的因变量不同，</p>\r\n<ul>\r\n<li>多重线性回归直接将<span class=\"math inline\">\\(w&#39;x+b\\)</span>作为因变量，</li>\r\n<li>Logistic回归则通过函数L将<span class=\"math inline\">\\(w&#39;x+b\\)</span>对应一个隐状态<span class=\"math inline\">\\(p\\)</span>，<span class=\"math inline\">\\(p =L(w&#39;x+b)\\)</span>，然后根据<span class=\"math inline\">\\(p\\)</span>与<span class=\"math inline\">\\(1-p\\)</span>的大小决定因变量的值。</li>\r\n</ul>\r\n<p>如果L是Logistic函数，就是Logistic回归，</p>\r\n<p>如果L是多项式函数就是多项式回归。</p>\r\n<span id=\"more\"></span>\r\n<h2 id=\"logistic-function\">Logistic Function</h2>\r\n<p>定义逻辑回归的预测函数为<span class=\"math inline\">\\(ℎ_\\theta(x) = 𝑔(\\theta^𝑇𝑥)\\)</span> ，其中g(x)函数是sigmoid函数。 <span class=\"math display\">\\[\r\ng(x)=\\frac{1}{1+e^{-x}}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nh_\\theta(x)=\\frac{1}{1+e^{-\\theta^Tx}}\r\n\\]</span></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230606093600860.png\"  style=\"zoom:50%;\" /></p>\r\n<ol type=\"1\">\r\n<li>当<span class=\"math inline\">\\(\\theta^Tx≥0\\)</span>，<span class=\"math inline\">\\(g(\\theta^Tx)≥0.5\\)</span></li>\r\n<li>当<span class=\"math inline\">\\(\\theta^Tx≤0\\)</span>，<span class=\"math inline\">\\(g(\\theta^Tx)≤0.5\\)</span></li>\r\n</ol>\r\n<h2 id=\"逻辑回归的代价函数cost-function\">逻辑回归的代价函数（Cost Function）</h2>\r\n<p><span class=\"math display\">\\[\r\nCost(h_\\theta(x),y)= \r\n\\begin{cases}\r\n-log(h_\\theta(x))\\quad\\quad\\quad if\\quad y=1\\\\\r\n-log(1-h_\\theta(x))\\quad if\\quad y=0\r\n\\end{cases}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n=-ylog(h_\\theta(x))-(1-y)log(1-h_\\theta(x))\r\n\\]</span></p>\r\n<h2 id=\"梯度下降法gradient-descent\">梯度下降法（Gradient Descent）</h2>\r\n<p><span class=\"math display\">\\[\r\nJ(\\theta)=-\\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}logh_\\theta(x^{(i)})+(1-y^{(i)})log(1-h_\\theta(x^{(i)}))]\r\n\\]</span></p>\r\n<p>求解 <span class=\"math inline\">\\(min_\\theta J(\\theta)\\)</span> <span class=\"math display\">\\[\r\n\\theta_j:=\\theta_j-\\alpha\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}\r\n\\]</span></p>\r\n<h2 id=\"准确率精准率召回率f1分数\">准确率|精准率|召回率|F<sub>1</sub>分数</h2>\r\n<p>混淆矩阵</p>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th></th>\r\n<th></th>\r\n<th>实际</th>\r\n<th>实际</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td></td>\r\n<td></td>\r\n<td>1</td>\r\n<td>0</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>预测</td>\r\n<td>1</td>\r\n<td>TP</td>\r\n<td>FP</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>预测</td>\r\n<td>0</td>\r\n<td>FN</td>\r\n<td>TN</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<ul>\r\n<li>P（Positive）：代表1</li>\r\n<li>N（Negative）：代表0</li>\r\n<li>T（True）：代表预测正确</li>\r\n<li>F（False）：代表预测错误</li>\r\n</ul>\r\n<p><strong>准确率：</strong>即预测正确的结果占总样本的百分比 <span class=\"math display\">\\[\r\n准确率=\\frac{TP+TN}{TP+TN+FP+FN}\r\n\\]</span> <strong>精准率（Precision）：</strong>是指在所有被预测为正的样本中实际为正的样本的概率。 <span class=\"math display\">\\[\r\n精准率=\\frac{TP}{TP+FP}\r\n\\]</span> <strong>精准率就是你认为找的是对的实际上多少是对的</strong></p>\r\n<p><strong>召回率（Recall）：</strong>是指在实际为正的样本中被预测为正样本的概率。 <span class=\"math display\">\\[\r\n召回率=\\frac{TP}{TP+FN}\r\n\\]</span> <strong>F<sub>1</sub>分数：</strong>精准率和召回率之间的一个平衡点。 <span class=\"math display\">\\[\r\nF_1=\\frac{2\\times Precision\\times Recall}{Precision+Recall}\r\n\\]</span></p>\r\n<h2 id=\"逻辑回归示例代码\">逻辑回归示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> preprocessing</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"><span class=\"comment\"># 数据是否需要标准化</span></span><br><span class=\"line\">scale = <span class=\"literal\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;LR-testSet.csv&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[:,:-<span class=\"number\">1</span>]</span><br><span class=\"line\">y_data = data[:,-<span class=\"number\">1</span>]</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot</span>():</span><br><span class=\"line\">    x0 = []</span><br><span class=\"line\">    x1 = []</span><br><span class=\"line\">    y0 = []</span><br><span class=\"line\">    y1 = []</span><br><span class=\"line\">    <span class=\"comment\"># 切分不同类别的数据</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(x_data)):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> y_data[i]==<span class=\"number\">0</span>:</span><br><span class=\"line\">            x0.append(x_data[i,<span class=\"number\">0</span>])</span><br><span class=\"line\">            y0.append(x_data[i,<span class=\"number\">1</span>])</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            x1.append(x_data[i,<span class=\"number\">0</span>])</span><br><span class=\"line\">            y1.append(x_data[i,<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 画图</span></span><br><span class=\"line\">   scatter0 = plt.scatter(x0, y0, c=<span class=\"string\">&#x27;c&#x27;</span>, marker=<span class=\"string\">&#x27;+&#x27;</span>)</span><br><span class=\"line\">    scatter1 = plt.scatter(x1, y1, c=<span class=\"string\">&#x27;y&#x27;</span>, marker=<span class=\"string\">&#x27;*&#x27;</span>)</span><br><span class=\"line\">    <span class=\"comment\">#画图例</span></span><br><span class=\"line\">    plt.legend(handles=[scatter0,scatter1],labels=[<span class=\"string\">&#x27;label0&#x27;</span>,<span class=\"string\">&#x27;label1&#x27;</span>],loc=<span class=\"string\">&#x27;best&#x27;</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">plot()</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并拟合模型</span></span><br><span class=\"line\">logistic = linear_model.LogisticRegression()</span><br><span class=\"line\">logistic.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> scale == <span class=\"literal\">False</span>:</span><br><span class=\"line\">    <span class=\"comment\"># 画图决策边界</span></span><br><span class=\"line\">    plot()</span><br><span class=\"line\">    x_test = np.array([[-<span class=\"number\">4</span>],[<span class=\"number\">3</span>]])</span><br><span class=\"line\">    y_test = (-logistic.intercept_ - x_test*logistic.coef_[<span class=\"number\">0</span>][<span class=\"number\">0</span>])/logistic.coef_[<span class=\"number\">0</span>][<span class=\"number\">1</span>]</span><br><span class=\"line\">    plt.plot(x_test, y_test, <span class=\"string\">&#x27;k&#x27;</span>)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># 测试与评估    </span></span><br><span class=\"line\">predictions = logistic.predict(x_data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(y_data, predictions))</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230606164354040.png\"  style=\"zoom:50%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230606164557574.png\"  style=\"zoom: 67%;\" /></p>\r\n<h2 id=\"非线性逻辑回归示例代码\">非线性逻辑回归示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_gaussian_quantiles</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> PolynomialFeatures</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成2维正态分布，生成的数据按分位数分为两类，500个样本,2个样本特征</span></span><br><span class=\"line\"><span class=\"comment\"># 可以生成两类或多类数据</span></span><br><span class=\"line\">x_data, y_data = make_gaussian_quantiles(n_samples=<span class=\"number\">500</span>, n_features=<span class=\"number\">2</span>,n_classes=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并拟合模型</span></span><br><span class=\"line\">logistic = linear_model.LogisticRegression()</span><br><span class=\"line\">logistic.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义多项式回归,degree的值可以调节多项式的特征</span></span><br><span class=\"line\">poly_reg  = PolynomialFeatures(degree=<span class=\"number\">5</span>) </span><br><span class=\"line\"><span class=\"comment\"># 特征处理</span></span><br><span class=\"line\">x_poly = poly_reg.fit_transform(x_data)</span><br><span class=\"line\"><span class=\"comment\"># 定义逻辑回归模型</span></span><br><span class=\"line\">logistic = linear_model.LogisticRegression()</span><br><span class=\"line\"><span class=\"comment\"># 训练模型</span></span><br><span class=\"line\">logistic.fit(x_poly, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">x_min, x_max = x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">y_min, y_max = x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                     np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">z = logistic.predict(poly_reg.fit_transform(np.c_[xx.ravel(), yy.ravel()]))<span class=\"comment\"># ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据</span></span><br><span class=\"line\">z = z.reshape(xx.shape)</span><br><span class=\"line\"><span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\"><span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;score:&#x27;</span>,logistic.score(x_poly,y_data))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230606165631817.png\"  style=\"zoom:67%;\" /></p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://www.bilibili.com/video/BV1Rt411q7WJ?p=29\">逻辑回归</a></p>\r\n",
            "tags": [
                "Python",
                "Jupyter Notebook"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%8F%8A%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/",
            "url": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%8F%8A%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/",
            "title": "线性回归及非线性回归",
            "date_published": "2023-06-05T01:37:27.000Z",
            "content_html": "<h1 id=\"基本概念\">基本概念：</h1>\r\n<p>将数据划分为三部分：<span class=\"math inline\">\\(\\begin{cases} 训练集(Train):用来训练，构建模型\\\\ 验证集(Validate):在模型训练阶段，测试模型的好坏\\\\ 测试集(Test):等模型训练好后，评估模型的好坏 \\end{cases}\\)</span></p>\r\n<span id=\"more\"></span>\r\n<p>学习方式：<span class=\"math inline\">\\(\\begin{cases} 监督学习\\\\ 无监督学习\\\\ 半监督学习 \\end{cases}\\)</span></p>\r\n<p>常见应用：<span class=\"math inline\">\\(\\begin{cases} 回归：预测数据为连续型数值。\\\\ 分类：预测数据为类别型数据，并且类别已知。\\\\ 聚类：预测数据为类别型数据，但是类别未知。 \\end{cases}\\)</span></p>\r\n<h1 id=\"回归分析regression\"><a href=\"https://baike.baidu.com/item/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/2625498?fr=aladdin\">回归分析（Regression）</a></h1>\r\n<p>回归分析用来建立方程，模拟两个或者多个变量之间如何关联，</p>\r\n<ul>\r\n<li>被预测的变量叫做：因变量/输出</li>\r\n<li>被用来进行预测的变量叫做： 自变量,/输入</li>\r\n</ul>\r\n<p>一元线性回归包含一个自变量和一个因变量，两个变量的关系用一条直线来模拟，如果包含两个以上的自变量，则称作多元回归分析（multiple regression）</p>\r\n<h1 id=\"一元线性回归\"><a href=\"https://baike.baidu.com/item/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/22770888?fr=aladdin\">一元线性回归</a></h1>\r\n<p>一元线性回归：<span class=\"math inline\">\\(h_\\theta(x)=\\theta_0+\\theta_1x\\)</span></p>\r\n<h2 id=\"代价函数cost-function\"><a href=\"https://baike.baidu.com/item/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/1783236?fromtitle=%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0&amp;fromid=7048599&amp;fr=aladdin\">代价函数（Cost Function）</a></h2>\r\n<p><strong>最小二乘法</strong></p>\r\n<p>假设真实值为<span class=\"math inline\">\\(y\\)</span>，预测值<span class=\"math inline\">\\(h_\\theta(x)\\)</span> ，则误差平方为<span class=\"math inline\">\\((h_\\theta(x)-y)^2\\)</span></p>\r\n<p>找到合适的参数，使得误差平方和<span class=\"math inline\">\\(J(\\theta_0,\\theta_1)\\)</span>最小。 <span class=\"math display\">\\[\r\nJ(\\theta_0,\\theta_1)=\\frac{1}{2m}\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})^{2}}\r\n\\]</span></p>\r\n<h2 id=\"梯度下降法gradient-descent\"><a href=\"https://baike.baidu.com/item/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/8641233?fr=aladdin\">梯度下降法（Gradient Descent）</a></h2>\r\n<p><strong>最小化目标函数</strong> <span class=\"math inline\">\\(\\underset{\\theta_0,\\theta_1}{min}\\quad J(\\theta_0,\\theta_1)\\)</span></p>\r\n<p>初始化参数<span class=\"math inline\">\\(\\theta_0,\\theta_1\\)</span></p>\r\n<p>不断改变<span class=\"math inline\">\\(\\theta_0,\\theta_1\\)</span> ，直到<span class=\"math inline\">\\(J(\\theta_0,\\theta_1)\\)</span>到达一个全局最小值，或局部极小值。 <span class=\"math display\">\\[\r\n\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta_0,\\theta_1)\\quad (j=0,1,2\\cdots)\r\n\\]</span></p>\r\n<h2 id=\"用梯度下降法求解线性回归\">用梯度下降法求解线性回归</h2>\r\n<p><span class=\"math display\">\\[\r\n\\frac{\\partial}{\\partial\\theta_0}J(\\theta_0,\\theta_1)=\r\n\\frac{1}{m}\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}\r\n\\\\\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\frac{\\partial}{\\partial\\theta_1}J(\\theta_0,\\theta_1)=\r\n\\frac{1}{m}\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}\\times x^{(i)}\r\n\\]</span></p>\r\n<p>不断迭代，直到收敛： <span class=\"math display\">\\[\r\n\\theta_0:=\\theta_0-\\alpha\\frac{1}{m}{\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\theta_1:=\\theta_1-\\alpha\\frac{1}{m}{\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}}\\times x^{(i)}\r\n\\]</span></p>\r\n<h2 id=\"示例代码\">示例代码：</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LinearRegression <span class=\"comment\"># 线性回归模型</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;data.csv&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[:,<span class=\"number\">0</span>]</span><br><span class=\"line\">y_data = data[:,<span class=\"number\">1</span>]</span><br><span class=\"line\">plt.scatter(x_data,y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\">x_data = data[:,<span class=\"number\">0</span>,np.newaxis]</span><br><span class=\"line\">y_data = data[:,<span class=\"number\">1</span>,np.newaxis]</span><br><span class=\"line\"><span class=\"comment\"># 创建并拟合模型</span></span><br><span class=\"line\">model = LinearRegression() <span class=\"comment\"># 线性回归</span></span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试</span></span><br><span class=\"line\">x_test = [[<span class=\"number\">44.5</span>]]</span><br><span class=\"line\">predict = model.predict(x_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;predict&#x27;</span>,predict)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">plt.plot(x_data, y_data, <span class=\"string\">&#x27;b.&#x27;</span>)</span><br><span class=\"line\">plt.plot(x_data, model.predict(x_data), <span class=\"string\">&#x27;r&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230605203607162.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"多元线性回归multiple-linear-regression\"><a href=\"https://baike.baidu.com/item/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/10702248?fr=aladdin\">多元线性回归（Multiple Linear Regression）</a></h1>\r\n<p>多特征时，假设：<span class=\"math inline\">\\(h_\\theta(x)=\\theta_0+\\theta_1x_1+\\theta_2x_2+\\cdots+\\theta_nx_n\\)</span></p>\r\n<p>当真实值<span class=\"math inline\">\\(y\\)</span>的影响因素不是唯一时，需采用多元线性回归模型。</p>\r\n<p>代价函数： <span class=\"math display\">\\[\r\nJ(\\theta_0,\\theta_1,\\cdots,\\theta_n)=\\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^{2}\r\n\\]</span> 梯度下降法： <span class=\"math display\">\\[\r\n\\theta_j:=\\theta_j-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}\\times x_j^{(i)}\\quad (j=0,1,2\\cdots,n)\r\n\\]</span> 注意这里的<span class=\"math inline\">\\(j=0\\)</span>时，<span class=\"math inline\">\\(x_0=1\\)</span></p>\r\n<h2 id=\"示例代码-1\">示例代码：</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> numpy <span class=\"keyword\">import</span> genfromtxt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model <span class=\"comment\"># 线性回归模型</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt  </span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读入数据 </span></span><br><span class=\"line\">data = genfromtxt(<span class=\"string\">r&quot;Delivery.csv&quot;</span>,delimiter=<span class=\"string\">&#x27;,&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 切分数据</span></span><br><span class=\"line\">x_data = data[:,:-<span class=\"number\">1</span>]</span><br><span class=\"line\">y_data = data[:,-<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建模型</span></span><br><span class=\"line\">model = linear_model.LinearRegression()</span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试</span></span><br><span class=\"line\">x_test = [[<span class=\"number\">102</span>,<span class=\"number\">4</span>]]</span><br><span class=\"line\">predict = model.predict(x_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;predict:&quot;</span>,predict)</span><br><span class=\"line\"></span><br><span class=\"line\">ax = plt.figure().add_subplot(<span class=\"number\">111</span>, projection = <span class=\"string\">&#x27;3d&#x27;</span>) </span><br><span class=\"line\">ax.scatter(x_data[:,<span class=\"number\">0</span>], x_data[:,<span class=\"number\">1</span>], y_data, c = <span class=\"string\">&#x27;r&#x27;</span>, marker = <span class=\"string\">&#x27;o&#x27;</span>, s = <span class=\"number\">100</span>) <span class=\"comment\">#点为红色三角形  </span></span><br><span class=\"line\">x0 = x_data[:,<span class=\"number\">0</span>]</span><br><span class=\"line\">x1 = x_data[:,<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">x0, x1 = np.meshgrid(x0, x1)</span><br><span class=\"line\">z = model.intercept_ + x0*model.coef_[<span class=\"number\">0</span>] + x1*model.coef_[<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"comment\"># 画3D图</span></span><br><span class=\"line\">ax.plot_surface(x0, x1, z)</span><br><span class=\"line\"><span class=\"comment\">#设置坐标轴  </span></span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">&#x27;Miles&#x27;</span>)  </span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">&#x27;Num of Deliveries&#x27;</span>)  </span><br><span class=\"line\">ax.set_zlabel(<span class=\"string\">&#x27;Time&#x27;</span>)  </span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"comment\">#显示图像  </span></span><br><span class=\"line\">plt.show()  </span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230605204147960.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"多项式回归\">多项式回归</h1>\r\n<p>假如我们不是要找直线（或者超平面），而是需要找到一 个用多项式所表示的曲线（或者超曲面）</p>\r\n<p>多项式回归：<span class=\"math inline\">\\(h_\\theta(x)=\\theta_0+\\theta_1x+\\theta_2x^2+\\cdots+\\theta_nx^n\\)</span></p>\r\n<h2 id=\"示例代码-2\">示例代码：</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> PolynomialFeatures </span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LinearRegression</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;job.csv&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[<span class=\"number\">1</span>:,<span class=\"number\">1</span>]</span><br><span class=\"line\">y_data = data[<span class=\"number\">1</span>:,<span class=\"number\">2</span>]</span><br><span class=\"line\">plt.scatter(x_data,y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\">x_data = x_data[:,np.newaxis]</span><br><span class=\"line\">y_data = y_data[:,np.newaxis]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义多项式回归,degree的值可以调节多项式的特征</span></span><br><span class=\"line\">poly_reg  = PolynomialFeatures(degree=<span class=\"number\">5</span>) </span><br><span class=\"line\"><span class=\"comment\"># 特征处理</span></span><br><span class=\"line\">x_poly = poly_reg.fit_transform(x_data)</span><br><span class=\"line\"><span class=\"comment\"># 定义回归模型</span></span><br><span class=\"line\">lin_reg = LinearRegression()</span><br><span class=\"line\"><span class=\"comment\"># 训练模型</span></span><br><span class=\"line\">lin_reg.fit(x_poly, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">plt.plot(x_data, y_data, <span class=\"string\">&#x27;b.&#x27;</span>)</span><br><span class=\"line\">x_test = np.linspace(<span class=\"number\">1</span>,<span class=\"number\">10</span>,<span class=\"number\">100</span>)</span><br><span class=\"line\">x_test = x_test[:,np.newaxis]</span><br><span class=\"line\">plt.plot(x_test, lin_reg.predict(poly_reg.fit_transform(x_test)), c=<span class=\"string\">&#x27;r&#x27;</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Truth or Bluff (Polynomial Regression)&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Position level&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Salary&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230605205328029.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"标准方程法normal-equation\">标准方程法（Normal Equation）</h1>\r\n<p>注意这里的符号：<span class=\"math inline\">\\(w\\)</span>其实就是上面公式里的<span class=\"math inline\">\\(\\theta\\)</span>，就是要求解的那个参数。</p>\r\n<p>假设： <span class=\"math display\">\\[\r\nh_w(x)=w_0+w_1x_1+w_2x_2+\\cdots+w_nx_n\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nh_w(x)=xw\\\r\n\\]</span></p>\r\n<p>目标函数: <span class=\"math display\">\\[\r\nJ(w_0,w_1,\\cdots,w_n)=\\frac{1}{2m}\\sum_{i=1}^{m}(h_w(x^{(i)})-y^{(i)})^{2}\r\n\\]</span> 又因为 <span class=\"math display\">\\[\r\n\\sum_{i=1}^{m}(h_w(x^{(i)})-y^{(i)})^{2}=(y-Xw)^T(y-Xw)\r\n\\]</span> 所以 <span class=\"math display\">\\[\r\n\\frac{\\partial J(w)}{\\partial w}=\\frac{\\partial(y-Xw)^T(y-Xw)}{\\partial w}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n=\\frac{\\partial(y^Ty-y^TXw-w^TX^Ty+w^TX^TXw)}{\\partial w}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n=\\frac{\\partial(y^Ty)}{\\partial w}-\\frac{\\partial(y^TXw)}{\\partial w}-\\frac{\\partial(w^TX^Ty)}{\\partial w}+\\frac{\\partial(w^TX^TXw)}{\\partial w}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n=0-X^Ty-X^Ty+2X^TXw\r\n\\]</span></p>\r\n<p>令 <span class=\"math display\">\\[\r\n\\frac{\\partial J(w)}{\\partial w}=0\r\n\\]</span> 求解： <span class=\"math display\">\\[\r\n-2X^Ty+2X^TXw=0\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nX^TXw=X^Ty\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nw=(X^TX)^{-1}X^Ty\r\n\\]</span></p>\r\n<h1 id=\"特征缩放\"><a href=\"https://baike.baidu.com/item/%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE/17415222?fr=aladdin\">特征缩放</a></h1>\r\n<h2 id=\"数据归一化\">数据归一化</h2>\r\n<p>数据归一化就是把数据的取值范围处理为<span class=\"math inline\">\\(0-1\\)</span>，或者<span class=\"math inline\">\\(-1-1\\)</span>之间。</p>\r\n<p>任意数据转化为0-1之间： <span class=\"math display\">\\[\r\nNewValue = \\frac{OldValue-min}{max-min}\r\n\\]</span> 任意数据转化为-1-1之间： <span class=\"math display\">\\[\r\nNewValue=2\\times(\\frac{OldVaule-min}{max-min}-0.5)\r\n\\]</span></p>\r\n<h2 id=\"均值标准化\">均值标准化</h2>\r\n<p><span class=\"math inline\">\\(x\\)</span>为特征数据，<span class=\"math inline\">\\(u\\)</span>为数据的平均值，<span class=\"math inline\">\\(s\\)</span>为数据的方差。 <span class=\"math display\">\\[\r\nNewValue=\\frac{OldValue-u}{s}\r\n\\]</span></p>\r\n<h1 id=\"过拟合overfitting\">过拟合（Overfitting）</h1>\r\n<p>回归问题拟合有以下三种情况：</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230605154335888.png\"  style=\"zoom:50%;\" /></p>\r\n<p>分类问题有以下三种情况：</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230605154600447.png\" style=\"zoom:50%;\" /></p>\r\n<p>防止过拟合：减少特征；增加数据量；正则化（Regularized）</p>\r\n<h2 id=\"正则化\">正则化</h2>\r\n<p>L2正则化： <span class=\"math display\">\\[\r\nJ(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{\\theta_j^2}}]\r\n\\]</span> L1正则化： <span class=\"math display\">\\[\r\nJ(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{|\\theta_j|}}]\r\n\\]</span></p>\r\n<h1 id=\"岭回归ridge-regression\"><a href=\"https://baike.baidu.com/link?url=J428YjCOAduEv-hDj1BM53FvjQEMC1iR9icG161YvlKwmXXmtsgGoFBvkL_VK2T40KfCjPMUpQQ8ePln0cjp50QpceYEGvvCC4iewQhwY0fGCqcS9kwQCLnbARBjd0mT\">岭回归（Ridge Regression）</a></h1>\r\n<p>由标准方程法得出， <span class=\"math display\">\\[\r\nw = (𝑋^𝑇𝑋)^{-1}𝑋^𝑇y\r\n\\]</span> 如果数据的特征比样本点还多，（数据特征<span class=\"math inline\">\\(n\\)</span>，样本个数<span class=\"math inline\">\\(m\\)</span>），如果<span class=\"math inline\">\\(n&gt;m\\)</span>，<span class=\"math inline\">\\(𝑋^𝑇𝑋\\)</span>不是满秩矩阵，不可逆，计算<span class=\"math inline\">\\(𝑋^𝑇𝑋^{-1}\\)</span>时会出错。</p>\r\n<p>为了解决这个问题，引入了岭回归的概念。<span class=\"math inline\">\\(\\lambda\\)</span>为岭系数，<span class=\"math inline\">\\(I\\)</span>为单位矩阵。 <span class=\"math display\">\\[\r\nw = (𝑋^𝑇𝑋 + \\lambda I)^{-1}𝑋^𝑇y\r\n\\]</span> 推导： <span class=\"math display\">\\[\r\nJ(\\theta)=\\frac{1}{2}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{\\theta_j^2}}]\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n=\\frac{1}{2}(Xw-y)^T(Xw-y)+\\lambda w^Tw\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n=\\frac{1}{2}(w^TX^TXw-w^TX^Ty-y^TXw+y^Ty)+\\lambda w^Tw\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\frac{\\partial J(w)}{\\partial w}=X^TXw-X^Ty+\\lambda w\r\n\\]</span></p>\r\n<p>令 <span class=\"math display\">\\[\r\n\\frac{\\partial J(w)}{\\partial w}=0\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nw = (𝑋^𝑇𝑋 + \\lambda I)^{-1}𝑋^𝑇y\r\n\\]</span></p>\r\n<h2 id=\"示例代码-3\">示例代码：</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> numpy <span class=\"keyword\">import</span> genfromtxt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读入数据 </span></span><br><span class=\"line\">data = genfromtxt(<span class=\"string\">r&quot;longley.csv&quot;</span>,delimiter=<span class=\"string\">&#x27;,&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 切分数据</span></span><br><span class=\"line\">x_data = data[<span class=\"number\">1</span>:,<span class=\"number\">2</span>:]</span><br><span class=\"line\">y_data = data[<span class=\"number\">1</span>:,<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建模型</span></span><br><span class=\"line\"><span class=\"comment\"># 生成50个值</span></span><br><span class=\"line\">alphas_to_test = np.linspace(<span class=\"number\">0.001</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># 创建模型，保存误差值</span></span><br><span class=\"line\">model = linear_model.RidgeCV(alphas=alphas_to_test, store_cv_values=<span class=\"literal\">True</span>)</span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\"><span class=\"comment\"># 岭系数跟loss值的关系</span></span><br><span class=\"line\">plt.plot(alphas_to_test, model.cv_values_.mean(axis=<span class=\"number\">0</span>))</span><br><span class=\"line\"><span class=\"comment\"># 选取的岭系数值的位置</span></span><br><span class=\"line\">plt.plot(model.alpha_, <span class=\"built_in\">min</span>(model.cv_values_.mean(axis=<span class=\"number\">0</span>)),<span class=\"string\">&#x27;ro&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;alphas&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;loss&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试</span></span><br><span class=\"line\">model.predict(x_data[<span class=\"number\">2</span>,np.newaxis])</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230605210828441.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"lassoleast-absolute-shrinkage-and\">[LASSO（Least Absolute Shrinkage and</h1>\r\n<p>Selectionator operator）](https://baike.baidu.com/item/Lasso%E7%AE%97%E6%B3%95/22685468?fromtitle=LASSO&amp;fromid=20366865&amp;fr=aladdin)</p>\r\n<p>LASSO的代价函数： <span class=\"math display\">\\[\r\nJ(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{|\\theta_j|}}]\r\n\\]</span></p>\r\n<h2 id=\"示例代码-4\">示例代码：</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> numpy <span class=\"keyword\">import</span> genfromtxt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读入数据 </span></span><br><span class=\"line\">data = genfromtxt(<span class=\"string\">r&quot;longley.csv&quot;</span>,delimiter=<span class=\"string\">&#x27;,&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 切分数据</span></span><br><span class=\"line\">x_data = data[<span class=\"number\">1</span>:,<span class=\"number\">2</span>:]</span><br><span class=\"line\">y_data = data[<span class=\"number\">1</span>:,<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并拟合模型</span></span><br><span class=\"line\">model = linear_model.LassoCV()</span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># lasso系数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(model.alpha_)</span><br><span class=\"line\"><span class=\"comment\"># 相关系数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(model.coef_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 预测</span></span><br><span class=\"line\">model.predict(x_data[-<span class=\"number\">2</span>,np.newaxis])</span><br></pre></td></tr></table></figure>\r\n<h1 id=\"弹性网elastic-net\">弹性网（Elastic Net）</h1>\r\n<p>在<span class=\"math inline\">\\(q\\)</span>取不同值情况下的代价函数 <span class=\"math display\">\\[\r\nJ(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{|\\theta_j|^q}}]\r\n\\]</span> <img src=\"/imgs/$%7Bfiilename%7D/image-20230605164458909.png\"  style=\"zoom:50%;\" /></p>\r\n<p>Elastic Net的代价函数： <span class=\"math display\">\\[\r\nJ(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{\\alpha\\theta_j^2+(1-\\alpha)|\\theta_j|}}]\r\n\\]</span></p>\r\n<h2 id=\"示例代码-5\">示例代码：</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> numpy <span class=\"keyword\">import</span> genfromtxt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读入数据 </span></span><br><span class=\"line\">data = genfromtxt(<span class=\"string\">r&quot;longley.csv&quot;</span>,delimiter=<span class=\"string\">&#x27;,&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 切分数据</span></span><br><span class=\"line\">x_data = data[<span class=\"number\">1</span>:,<span class=\"number\">2</span>:]</span><br><span class=\"line\">y_data = data[<span class=\"number\">1</span>:,<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并拟合模型</span></span><br><span class=\"line\">model = linear_model.ElasticNetCV()</span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 弹性网系数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(model.alpha_)</span><br><span class=\"line\"><span class=\"comment\"># 相关系数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(model.coef_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 预测</span></span><br><span class=\"line\">model.predict(x_data[-<span class=\"number\">2</span>,np.newaxis])</span><br></pre></td></tr></table></figure>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://www.bilibili.com/video/BV1Rt411q7WJ?p=23&amp;vd_source=fe8e916be2bd597efffd8dfd95249141\">线性回归及其非线性回归</a></p>\r\n",
            "tags": [
                "Python",
                "Jupyter Notebook"
            ]
        }
    ]
}