<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>你不是单打独斗 • Posts by &#34;机器学习&#34; category</title>
        <link>https://liujk6525.github.io</link>
        <description></description>
        <language>zh-CN</language>
        <pubDate>Wed, 07 Jun 2023 21:39:07 +0800</pubDate>
        <lastBuildDate>Wed, 07 Jun 2023 21:39:07 +0800</lastBuildDate>
        <category>Hexo</category>
        <category>Anaconda</category>
        <category>Jetson Nano</category>
        <category>Yolo-v5</category>
        <category>JupyterLab</category>
        <category>Python</category>
        <category>Jupyter Notebook</category>
        <category>PyTorch</category>
        <category>Typora</category>
        <category>Git</category>
        <category>Matlab</category>
        <category>路径规划</category>
        <category>python</category>
        <category>Yolov5</category>
        <category>ssd.pytorch</category>
        <item>
            <guid isPermalink="true">https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</guid>
            <title>支持向量机</title>
            <link>https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</link>
            <category>Python</category>
            <category>Jupyter Notebook</category>
            <pubDate>Wed, 07 Jun 2023 21:39:07 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;支持向量机support-vector-machinessvm&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/link?url=4o8vmNTvVy9pd-Dpxirhv80tv92zBfxvv6uPHb4Wm3yyPV94e21R3itRTww9yHzkoXyesQZ8fAlpV-DZ579U5p1DUeS6T2O_hv_5Iwz7LHbAGg2cNexGPAxywQhxIzyKReLlwFlWv2iCdo1HE-_tKK&#34;&gt;支持向量机（Support Vector Machines，SVM）&lt;/a&gt;&lt;/h1&gt;
&lt;h2 id=&#34;svm&#34;&gt;SVM&lt;/h2&gt;
&lt;p&gt;SVM寻找区分两类的超平面（hyper plane), 使边际（margin）最大&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607214309677.png&#34; style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;向量内积&#34;&gt;向量内积&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
x=(x_1,x_2,\cdots,x_n)^T,y=(y_1,y_2,\cdots,y_n)^T
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
x\cdot y=x_1y_1+x_2y_2+\cdots+x_ny_n=||x||\cdot||y||\cos(\theta)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
||x||=\sqrt{x\cdot x}=\sqrt{x_1^2+x_2^2+\cdots+x_n^2}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;当&lt;span class=&#34;math inline&#34;&gt;\(||x||\neq0,||y||\neq0\)&lt;/span&gt;时，求解余弦相似度 &lt;span class=&#34;math display&#34;&gt;\[
\cos(\theta)=\frac{x\cdot y}{||x||\cdot||y||}
\]&lt;/span&gt;&lt;/p&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;推导&#34;&gt;推导&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230608085359722.png&#34;  style=&#34;zoom: 67%;&#34; /&gt; &lt;span class=&#34;math display&#34;&gt;\[
w\cdot x_1+b=1
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
w\cdot x_2+b=-1
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
w(x_1-x_2)=2
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
||w||\cdot||(x_1-x_2)||\cdot||\cos(\theta)||=2
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
||w||\cdot||d||=2
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
d=\frac{2}{||w||}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;转化为凸优化问题 &lt;span class=&#34;math display&#34;&gt;\[
y(w\cdot x+b)\geq1\begin{cases}w\cdot x+b\geq1\quad y=1\\w\cdot x+b\leq1\quad y=-1\end{cases}
\]&lt;/span&gt; 求&lt;span class=&#34;math inline&#34;&gt;\(d=\frac{2}{||w||}\)&lt;/span&gt;最大值，也就是求&lt;span class=&#34;math inline&#34;&gt;\(min\frac{||w||^2}{2}\)&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;凸优化问题&#34;&gt;凸优化问题&lt;/h2&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;&lt;p&gt;无约束优化问题：&lt;span class=&#34;math inline&#34;&gt;\(minf(x)\)&lt;/span&gt;——费马定理&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;带等式约束的优化问题：&lt;span class=&#34;math inline&#34;&gt;\(minf(x)\)&lt;/span&gt;–拉格朗日乘子法 &lt;span class=&#34;math display&#34;&gt;\[
s.t.h_i(x)=0,\quad i=1,2,\cdots,n\\
L(x,\lambda)=f(x)+\sum_{i=1}^{n}{\lambda_ih_i(x)}
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;带不等式约束的优化问题：&lt;span class=&#34;math inline&#34;&gt;\(minf(x)\)&lt;/span&gt;——&lt;a href=&#34;https://baike.baidu.com/item/%E5%8D%A1%E7%BD%97%E9%9C%80-%E5%BA%93%E6%81%A9-%E5%A1%94%E5%85%8B%E6%9D%A1%E4%BB%B6/23121032?fr=aladdin&#34;&gt;KKT（Karush-Kuhn-Tucker）条件&lt;/a&gt; &lt;span class=&#34;math display&#34;&gt;\[
s.t.h_i(x)=0,\quad i=1,2,\cdots,n\\
g_i(x)\leq0,\quad i=1,2,\cdots,k\\
L(x,\lambda,v)=f(x)+\sum_{i=1}^{k}{\lambda_ig_i(x)}+\sum_{i=1}^{n}{v_ih_i(x)}
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里我们处理的是&lt;strong&gt;带不等式约束&lt;/strong&gt;的优化问题： &lt;span class=&#34;math display&#34;&gt;\[
L(\alpha,w,b)=\frac{1}{2}||w||^2-\sum_{i=1}^{k}{\alpha(1-y_i(w^Tx_i+b))}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
s.t.\quad 1-y_i(w^Tx_i+b)\leq0
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;简化为对偶问题：&lt;span class=&#34;math inline&#34;&gt;\(\underset {w,b}{min}\quad\underset{\alpha\geq0}{max}\quad L(\alpha,w,b)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;可以等价为：&lt;span class=&#34;math inline&#34;&gt;\(\underset {\alpha\geq0}{max}\quad\underset {w,b}{min}\quad L(\alpha,w,b)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，先对&lt;span class=&#34;math inline&#34;&gt;\(w,b\)&lt;/span&gt;进行求导， &lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial L}{\partial w}=0\rightarrow w=\sum_{i=1}^{n}{\alpha_iy_ix_i}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial L}{\partial b}=0\rightarrow \sum_{i=1}^{n}{\alpha_iy_i}=0
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;然后，将上式代入&lt;span class=&#34;math inline&#34;&gt;\(L(\alpha,w,b)\)&lt;/span&gt;得到一个只与&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;相关的函数。 &lt;span class=&#34;math display&#34;&gt;\[
L(\alpha,w,b)=\sum_{i=1}^{n}{\alpha_i}-\frac{1}{2}\sum_{i,j=1}^{n}{\alpha_i\alpha_jy_iy_jx_i^Tx_j}
\]&lt;/span&gt; 最后优化问题可表示为： &lt;span class=&#34;math display&#34;&gt;\[
\underset {\alpha\geq0}{max}\quad\underset {w,b}{min}\quad L(\alpha,w,b)=\underset {\alpha\geq0}{max}\quad\sum_{i=1}^{n}{\alpha_i}-\frac{1}{2}\sum_{i,j=1}^{n}{\alpha_i\alpha_jy_iy_jx_i^Tx_j}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
=\underset {\alpha\geq0}{min}\quad
\frac{1}{2}\sum_{i,j=1}^{n}{\alpha_i\alpha_jy_iy_jx_i^Tx_j}-\sum_{i=1}^{n}{\alpha_i}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
s.t.\quad \sum_{i=1}^{n}{a_iy_i=0}\quad a_i\geq0,i=1,2,\cdots,n
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;由此，可求出最优解&lt;span class=&#34;math inline&#34;&gt;\(\alpha^{*}\)&lt;/span&gt;，然后再反代回去求&lt;span class=&#34;math inline&#34;&gt;\(w,b\)&lt;/span&gt;。 &lt;span class=&#34;math display&#34;&gt;\[
w^{*}=\sum_{i=1}^{n}{\alpha^{*}_iy_ix_i}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
b^{*}=y_i-(w^{*})^Tx_i
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;线性分类示例代码&#34;&gt;线性分类示例代码&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; svm&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建40个点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = np.r_[np.random.randn(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;) - [&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;], np.random.randn(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;) + [&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = [&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]*&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt; +[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]*&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],x_data[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;],c=y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 训练和拟合模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# (SVC，C是Classification(分类);SVR，R是Regression(回归))。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = svm.SVC(kernel=&lt;span class=&#34;string&#34;&gt;&amp;#x27;linear&amp;#x27;&lt;/span&gt;)  &lt;span class=&#34;comment&#34;&gt;# linear是线性核&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(x_data, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 获取分离平面 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],x_data[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;],c=y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_test = np.array([[-&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;],[&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d = -model.intercept_/model.coef_[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;k = -model.coef_[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]/model.coef_[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_test = d + k*x_test&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(x_test, y_test, &lt;span class=&#34;string&#34;&gt;&amp;#x27;k&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画出通过支持向量的分界线&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b1 = model.support_vectors_[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_down = k*x_test + (b1[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] - k*b1[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;b2 = model.support_vectors_[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_up = k*x_test + (b2[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;] - k*b2[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],x_data[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;],c=y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_test = np.array([[-&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;],[&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d = -model.intercept_/model.coef_[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;k = -model.coef_[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]/model.coef_[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_test = d + k*x_test&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(x_test, y_test, &lt;span class=&#34;string&#34;&gt;&amp;#x27;k&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(x_test, y_down, &lt;span class=&#34;string&#34;&gt;&amp;#x27;r--&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(x_test, y_up, &lt;span class=&#34;string&#34;&gt;&amp;#x27;b--&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230608111858386.png&#34;  style=&#34;zoom: 50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230608112059982.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;非线性分类示例代码&#34;&gt;非线性分类示例代码&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.metrics &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; classification_report&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; svm&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = np.genfromtxt(&lt;span class=&#34;string&#34;&gt;&amp;quot;LR-testSet2.txt&amp;quot;&lt;/span&gt;, delimiter=&lt;span class=&#34;string&#34;&gt;&amp;quot;,&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = data[:,:-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = data[:,-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;plot&lt;/span&gt;():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x0 = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x1 = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    y0 = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    y1 = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 切分不同类别的数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(x_data)):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; y_data[i]==&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            x0.append(x_data[i,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            y0.append(x_data[i,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            x1.append(x_data[i,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            y1.append(x_data[i,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 画图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    scatter0 = plt.scatter(x0, y0, c=&lt;span class=&#34;string&#34;&gt;&amp;#x27;b&amp;#x27;&lt;/span&gt;, marker=&lt;span class=&#34;string&#34;&gt;&amp;#x27;o&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    scatter1 = plt.scatter(x1, y1, c=&lt;span class=&#34;string&#34;&gt;&amp;#x27;r&amp;#x27;&lt;/span&gt;, marker=&lt;span class=&#34;string&#34;&gt;&amp;#x27;x&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#画图例&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.legend(handles=[scatter0,scatter1],labels=[&lt;span class=&#34;string&#34;&gt;&amp;#x27;label0&amp;#x27;&lt;/span&gt;,&lt;span class=&#34;string&#34;&gt;&amp;#x27;label1&amp;#x27;&lt;/span&gt;],loc=&lt;span class=&#34;string&#34;&gt;&amp;#x27;best&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plot()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建和训练模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# C和gamma&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = svm.SVC(kernel=&lt;span class=&#34;string&#34;&gt;&amp;#x27;rbf&amp;#x27;&lt;/span&gt;) &lt;span class=&#34;comment&#34;&gt;# rbf是gai&amp;#x27;si径向基函数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(x_data, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 获取数据值所在的范围&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_min, x_max = x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_min, y_max = x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 生成网格矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;xx, yy = np.meshgrid(np.arange(x_min, x_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                     np.arange(y_min, y_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = model.predict(np.c_[xx.ravel(), yy.ravel()])&lt;span class=&#34;comment&#34;&gt;# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = z.reshape(xx.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 等高线图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cs = plt.contourf(xx, yy, z)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plot() &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230608112344298.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;smosequential-minimal-optimization算法&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E5%BA%8F%E5%88%97%E6%9C%80%E5%B0%8F%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/22742660?fromtitle=SMO%E7%AE%97%E6%B3%95&amp;amp;fromid=24087607&amp;amp;fr=aladdin&#34;&gt;SMO（Sequential minimal optimization）算法&lt;/a&gt;&lt;/h2&gt;
&lt;h2 id=&#34;核函数&#34;&gt;核函数&lt;/h2&gt;
&lt;p&gt;构造核函数使得运算结果等同于非线性映射， 同时运算量要远远小于非线性映射。&lt;/p&gt;
&lt;p&gt;h次多项式核函数：&lt;span class=&#34;math inline&#34;&gt;\(K(X_i,X_j)=(X_i,X_j)^h\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;高斯径向基函数核函数：&lt;span class=&#34;math inline&#34;&gt;\(K(X_i,X_j)=e^{-\frac{||X_i-X_j||^2}{2\sigma^2}}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;S型核函数：&lt;span class=&#34;math inline&#34;&gt;\(K(X_i,X_j)=\tanh(kX_iY_i-\delta)\)&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;参考&#34;&gt;参考&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Rt411q7WJ/?p=81&amp;amp;spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;amp;vd_source=fe8e916be2bd597efffd8dfd95249141&#34;&gt;支持向量机&lt;/a&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/</guid>
            <title>主成分分析</title>
            <link>https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/</link>
            <category>Python</category>
            <category>Jupyter Notebook</category>
            <pubDate>Wed, 07 Jun 2023 21:06:14 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;主成分分析principal-component-analysispca&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/link?url=L2dvUGuaHxY-G-i8guCGRunHB4x6TIUECJUk3yG1d8pelX_sXVAtH2UXpHPA1Yn35TfalSGJ7jNxatvg-0ZCBVxNnyYX5pRSTbU-9EFsGKEW6C2NcydL1FZPhrMhWlPkUQRQW4jzsPpL_o3XRbQCnq&#34;&gt;主成分分析(Principal Component Analysis，PCA)&lt;/a&gt;&lt;/h1&gt;
&lt;h2 id=&#34;算法流程&#34;&gt;算法流程：&lt;/h2&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;数据预处理：中心化&lt;span class=&#34;math inline&#34;&gt;\(𝑋−\overline𝑋\)&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;求样本的协方差矩阵&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{m}XX^T\)&lt;/span&gt; 。&lt;/li&gt;
&lt;li&gt;对协方差矩阵&lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{m}XX^T\)&lt;/span&gt;做特征值分解。&lt;/li&gt;
&lt;li&gt;选出最大的&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;个特征值对应的&lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;个特征向量。&lt;/li&gt;
&lt;li&gt;将原始数据投影到选取的特征向量上。&lt;/li&gt;
&lt;li&gt;输出投影后的数据集。&lt;/li&gt;
&lt;/ol&gt;
&lt;!--- more --&gt;
&lt;h2 id=&#34;协方差&#34;&gt;协方差&lt;/h2&gt;
&lt;p&gt;方差就是描述&lt;strong&gt;一个数据&lt;/strong&gt;的离散程度： &lt;span class=&#34;math display&#34;&gt;\[
var(X)=\frac{\sum_{i=1}^{n}{(X_i-\overline X)(X_i-\overline X)}}{n-1}
\]&lt;/span&gt; 协方差是描述&lt;strong&gt;两个数据&lt;/strong&gt;的相关性，接近1就是正相关， 接近-1就是负相关，接近0就是不相关。 &lt;span class=&#34;math display&#34;&gt;\[
cov(X,Y)=\frac{\sum_{i=1}^{n}{(X_i-\overline X)(Y_i-\overline Y)}}{n-1}
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;协方差矩阵&#34;&gt;协方差矩阵&lt;/h2&gt;
&lt;p&gt;协方差矩阵是一个对称的矩阵，对角线是各个维度的方差。&lt;/p&gt;
&lt;p&gt;二维： &lt;span class=&#34;math display&#34;&gt;\[
C=\left[\begin{matrix}
cov(x,x)&amp;amp;cov(x,y)\\
cov(y,x)&amp;amp;cov(y,y))
\end{matrix})\right]=\left[\begin{matrix}
\frac{\sum_{i=1}^{m}{(x_i^2)}}{m}&amp;amp;\frac{\sum_{i=1}^{m}{(x_iy_i)}}{m}\\
\frac{\sum_{i=1}^{m}{(y_ix_i)}}{m}&amp;amp;\frac{\sum_{i=1}^{m}{(y_i^2)}}{m}
\end{matrix})\right]
\]&lt;/span&gt; 三维： &lt;span class=&#34;math display&#34;&gt;\[
C=\left[\begin{matrix}
cov(x,x)&amp;amp;cov(x,y)&amp;amp;cov(x,z)\\
cov(y,x)&amp;amp;cov(y,y))&amp;amp;cov(y,z)\\
cov(z,x)&amp;amp;cov(z,y)&amp;amp;cov(z,z)
\end{matrix})\right]
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;示例代码&#34;&gt;示例代码&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;64&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.neural_network &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; MLPClassifier&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.datasets &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; load_digits&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.model_selection &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; train_test_split&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.metrics &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; classification_report,confusion_matrix&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;digits = load_digits()&lt;span class=&#34;comment&#34;&gt;#载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = digits.data &lt;span class=&#34;comment&#34;&gt;#数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = digits.target &lt;span class=&#34;comment&#34;&gt;#标签&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_train,x_test,y_train,y_test = train_test_split(x_data,y_data) &lt;span class=&#34;comment&#34;&gt;#分割数据1/4为测试数据，3/4为训练数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建并拟合多层感知机分类器模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mlp = MLPClassifier(hidden_layer_sizes=(&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;) ,max_iter=&lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mlp.fit(x_train,y_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 数据中心化&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;zeroMean&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;dataMat&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 按列求平均，即各个特征的平均&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    meanVal = np.mean(dataMat, axis=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    newData = dataMat - meanVal&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; newData, meanVal&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;pca&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;dataMat,top&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 数据中心化&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    newData,meanVal=zeroMean(dataMat) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# np.cov用于求协方差矩阵，参数rowvar=0说明数据一行代表一个样本&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    covMat = np.cov(newData, rowvar=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# np.linalg.eig求矩阵的特征值和特征向量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    eigVals, eigVects = np.linalg.eig(np.mat(covMat))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 对特征值从小到大排序&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    eigValIndice = np.argsort(eigVals)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 最大的n个特征值的下标&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    n_eigValIndice = eigValIndice[-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:-(top+&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;):-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 最大的n个特征值对应的特征向量&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    n_eigVect = eigVects[:,n_eigValIndice]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 低维特征空间的数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    lowDDataMat = newData*n_eigVect&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 利用低纬度数据来重构数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    reconMat = (lowDDataMat*n_eigVect.T) + meanVal&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 返回低维特征空间的数据和重构的矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;return&lt;/span&gt; lowDDataMat,reconMat &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# PCA降二维&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lowDDataMat,reconMat = pca(x_data,&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 重构的数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = np.array(lowDDataMat)[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = np.array(lowDDataMat)[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x,y,c=y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# PCA降三维&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lowDDataMat,reconMat = pca(x_data,&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mpl_toolkits.mplot3d &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Axes3D  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = np.array(lowDDataMat)[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y = np.array(lowDDataMat)[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = np.array(lowDDataMat)[:,&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ax = plt.figure().add_subplot(&lt;span class=&#34;number&#34;&gt;111&lt;/span&gt;, projection = &lt;span class=&#34;string&#34;&gt;&amp;#x27;3d&amp;#x27;&lt;/span&gt;) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ax.scatter(x, y, z, c = y_data, s = &lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;) &lt;span class=&#34;comment&#34;&gt;#点为红色三角形 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607213629220.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607213644726.png&#34;  style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;参考&#34;&gt;参考&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Rt411q7WJ?p=74&#34;&gt;主成分分析&lt;/a&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</guid>
            <title>聚类算法</title>
            <link>https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</link>
            <category>Python</category>
            <category>Jupyter Notebook</category>
            <pubDate>Wed, 07 Jun 2023 19:53:51 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;聚类cluster算法&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/1252197?fr=aladdin&#34;&gt;聚类（Cluster）算法&lt;/a&gt;&lt;/h1&gt;
&lt;h2 id=&#34;k-means&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/15779627?fromtitle=K-MEANS%E7%AE%97%E6%B3%95&amp;amp;fromid=594631&amp;amp;fr=aladdin&#34;&gt;K-Means&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;以空间中k个点为中心进行聚类，对最靠近他们的对象归类。通过迭代的方法，逐次更新各聚类中心的值，直至得到最好的聚类结果。&lt;/p&gt;
&lt;p&gt;同一聚类中的对象相似度较高；而不同聚类中的对象相似度较小。&lt;/p&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;p&gt;算法流程：&lt;/p&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;&lt;p&gt;先从没有标签的元素集合A中随机取k个元素，作为 k个子集各自的重心。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;分别计算剩下的元素到k个子集重心的距离（这里的距离也可以使用欧氏距离），根据距离将这些元素分别划归到最近的子集。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;根据聚类结果，重新计算重心（重心的计算方法是 计算子集中所有元素各个维度的算数平均数）。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;将集合A中全部元素按照新的重心然后再重新聚类。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;重复第4步，直到聚类结果不再发生变化。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;示例代码&#34;&gt;示例代码&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.cluster &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; KMeans&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 忽视警告&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; warnings&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;warnings.filterwarnings(&lt;span class=&#34;string&#34;&gt;&amp;quot;ignore&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = np.genfromtxt(&lt;span class=&#34;string&#34;&gt;&amp;quot;kmeans.txt&amp;quot;&lt;/span&gt;, delimiter=&lt;span class=&#34;string&#34;&gt;&amp;quot; &amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 设置k值，这里需要手动设置K值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;k=&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建并训练模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = KMeans(n_clusters=k,n_init=&lt;span class=&#34;string&#34;&gt;&amp;#x27;auto&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 分类中心点坐标&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;centers = model.cluster_centers_&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(centers)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 预测结果&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result = model.predict(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(result)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画出各个数据点，用不同颜色表示分类&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mark = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;^r&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;vb&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;pg&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;+c&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i,d &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.plot(d[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], d[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], mark[result[i]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画出各个分类的中心点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mark = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;*r&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;*b&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;*g&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;*c&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i,center &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(centers):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.plot(center[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],center[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], mark[i], markersize=&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 获取数据值所在的范围&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_min, x_max = data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_min, y_max = data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 生成网格矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;xx, yy = np.meshgrid(np.arange(x_min, x_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                     np.arange(y_min, y_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = model.predict(np.c_[xx.ravel(), yy.ravel()])&lt;span class=&#34;comment&#34;&gt;# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = z.reshape(xx.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 等高线图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cs = plt.contourf(xx, yy, z)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画出各个数据点，用不同颜色表示分类&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mark = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;^r&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;vb&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;pg&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;+c&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i,d &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.plot(d[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], d[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], mark[result[i]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画出各个分类的中心点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mark = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;*r&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;*b&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;*g&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;*c&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i,center &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(centers):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.plot(center[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],center[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], mark[i], markersize=&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607203700434.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607203924280.png&#34;  style=&#34;zoom:52%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;mini-batch-k-means&#34;&gt;Mini Batch K-Means&lt;/h2&gt;
&lt;p&gt;采用小批量的数据子集减小计算时间。也就是随机抽取数据子集进行训练算法，结果一般只略差于标准算法。&lt;/p&gt;
&lt;p&gt;1：从数据集中随机抽取一些数据形成小批量，把他们分配给最近的质心&lt;/p&gt;
&lt;p&gt;2：更新质心，与&lt;strong&gt;K-Means&lt;/strong&gt;算法相比，数据的更新是在每一个小的样本集上。&lt;/p&gt;
&lt;h2 id=&#34;示例代码-1&#34;&gt;示例代码&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;62&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.cluster &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; MiniBatchKMeans&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 忽视警告&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; warnings&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;warnings.filterwarnings(&lt;span class=&#34;string&#34;&gt;&amp;quot;ignore&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = np.genfromtxt(&lt;span class=&#34;string&#34;&gt;&amp;quot;kmeans.txt&amp;quot;&lt;/span&gt;, delimiter=&lt;span class=&#34;string&#34;&gt;&amp;quot; &amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 设置k值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;k = &lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建并训练模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = MiniBatchKMeans(n_clusters=k,n_init=&lt;span class=&#34;string&#34;&gt;&amp;#x27;auto&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 分类中心点坐标&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;centers = model.cluster_centers_&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(centers)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 预测结果&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result = model.predict(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(result)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画出各个数据点，用不同颜色表示分类&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mark = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;or&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;ob&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;og&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;oy&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i,d &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.plot(d[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], d[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], mark[result[i]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画出各个分类的中心点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mark = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;*r&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;*b&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;*g&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;*y&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i,center &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(centers):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.plot(center[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],center[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], mark[i], markersize=&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 获取数据值所在的范围&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_min, x_max = data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_min, y_max = data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 生成网格矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;xx, yy = np.meshgrid(np.arange(x_min, x_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                     np.arange(y_min, y_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = model.predict(np.c_[xx.ravel(), yy.ravel()])&lt;span class=&#34;comment&#34;&gt;# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = z.reshape(xx.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 等高线图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cs = plt.contourf(xx, yy, z)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 显示结果&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画出各个数据点，用不同颜色表示分类&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mark = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;or&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;ob&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;og&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;oy&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i,d &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.plot(d[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], d[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], mark[result[i]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画出各个分类的中心点&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mark = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;*r&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;*b&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;*g&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;*y&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i,center &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(centers):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.plot(center[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],center[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], mark[i], markersize=&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607205405646.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;​ &lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607204231807.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;dbscandensity-based-spatial-clustering-of-applications-with-noise&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/DBSCAN/4864716?fr=aladdin&#34;&gt;DBSCAN（Density-Based Spatial Clustering of Applications with Noise）&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;能够将具有足够高密度的区域划分为簇，并可在噪声的空间数据库中发现任意形状的&lt;a href=&#34;https://baike.baidu.com/item/聚类/593695?fromModule=lemma_inlink&#34;&gt;聚类&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Epsilon\)&lt;/span&gt;邻域：给定对象半径&lt;span class=&#34;math inline&#34;&gt;\(\Epsilon\)&lt;/span&gt;内的区域称为该对象的&lt;span class=&#34;math inline&#34;&gt;\(\Epsilon\)&lt;/span&gt;邻域。&lt;/p&gt;
&lt;p&gt;核心对象：如果给定&lt;span class=&#34;math inline&#34;&gt;\(\Epsilon\)&lt;/span&gt;邻域内的样本点数大于等于&lt;span class=&#34;math inline&#34;&gt;\(Minpoints\)&lt;/span&gt;，则该对象为核心对象。&lt;/p&gt;
&lt;p&gt;直接密度可达：给定一个对象集合&lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;，如果&lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;在&lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt;的&lt;span class=&#34;math inline&#34;&gt;\(\Epsilon\)&lt;/span&gt;邻域内， 且&lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt;是一个核心对象，则我们说对象&lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;从&lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt;触发是直接密度可达的（directly density-reachable）。&lt;/p&gt;
&lt;p&gt;密度可达：集合&lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;，存在一个对象链 &lt;span class=&#34;math inline&#34;&gt;\(p_1,p_2,\cdots ,pn,p_1=q,p_n=p\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(p_{i+1}\)&lt;/span&gt;是从&lt;span class=&#34;math inline&#34;&gt;\(p_i\)&lt;/span&gt;关于𝜀和&lt;span class=&#34;math inline&#34;&gt;\(Minpoints\)&lt;/span&gt;直接密度可达，则称点&lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;是从&lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt;关于&lt;span class=&#34;math inline&#34;&gt;\(\Epsilon\)&lt;/span&gt;和&lt;span class=&#34;math inline&#34;&gt;\(Minpoints\)&lt;/span&gt;密度可达的。&lt;/p&gt;
&lt;p&gt;密度相连：集合&lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt;存在点&lt;span class=&#34;math inline&#34;&gt;\(o\)&lt;/span&gt;，使得点&lt;span class=&#34;math inline&#34;&gt;\(p、q\)&lt;/span&gt;是从&lt;span class=&#34;math inline&#34;&gt;\(o\)&lt;/span&gt;关于&lt;span class=&#34;math inline&#34;&gt;\(\Epsilon\)&lt;/span&gt;和 &lt;span class=&#34;math inline&#34;&gt;\(Minpoints\)&lt;/span&gt;密度可达的，那么点&lt;span class=&#34;math inline&#34;&gt;\(p、q\)&lt;/span&gt;是关于&lt;span class=&#34;math inline&#34;&gt;\(\Epsilon\)&lt;/span&gt;和 &lt;span class=&#34;math inline&#34;&gt;\(Minpoints\)&lt;/span&gt;密度相连的。&lt;/p&gt;
&lt;p&gt;算法流程：&lt;/p&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;&lt;p&gt;指定合适的&lt;span class=&#34;math inline&#34;&gt;\(\Epsilon\)&lt;/span&gt;和 &lt;span class=&#34;math inline&#34;&gt;\(Minpoints\)&lt;/span&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;计算所有的样本点，如果点&lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;的&lt;span class=&#34;math inline&#34;&gt;\(\Epsilon\)&lt;/span&gt;邻域里有超过&lt;span class=&#34;math inline&#34;&gt;\(Minpoints\)&lt;/span&gt;个点，则创建一个以&lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;为核心点的新簇。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;反复寻找这些核心点直接密度可达（之后可能是密度可达） 的点，将其加入到相应的簇，对于核心点发生“密度相连” 状况的簇，给予合并。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;没有新的点可以被添加到任何簇时，算法结束&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;示例代码-2&#34;&gt;示例代码&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.cluster &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DBSCAN&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = np.genfromtxt(&lt;span class=&#34;string&#34;&gt;&amp;quot;kmeans.txt&amp;quot;&lt;/span&gt;, delimiter=&lt;span class=&#34;string&#34;&gt;&amp;quot; &amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result = model.fit_predict(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;result&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画出各个数据点，用不同颜色表示分类&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mark = [&lt;span class=&#34;string&#34;&gt;&amp;#x27;or&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;ob&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;og&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;oy&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;ok&amp;#x27;&lt;/span&gt;, &lt;span class=&#34;string&#34;&gt;&amp;#x27;om&amp;#x27;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i,d &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;enumerate&lt;/span&gt;(data):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.plot(d[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], d[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], mark[result[i]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607205310944.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x1, y1 = datasets.make_circles(n_samples=&lt;span class=&#34;number&#34;&gt;2000&lt;/span&gt;, factor=&lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;, noise=&lt;span class=&#34;number&#34;&gt;0.05&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x2, y2 = datasets.make_blobs(n_samples=&lt;span class=&#34;number&#34;&gt;1000&lt;/span&gt;, centers=[[&lt;span class=&#34;number&#34;&gt;1.2&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;1.2&lt;/span&gt;]], cluster_std=[[&lt;span class=&#34;number&#34;&gt;.1&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x = np.concatenate((x1, x2))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], x[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], marker=&lt;span class=&#34;string&#34;&gt;&amp;#x27;o&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.cluster &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DBSCAN&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_pred = DBSCAN(eps = &lt;span class=&#34;number&#34;&gt;0.2&lt;/span&gt;, min_samples=&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;).fit_predict(x)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], x[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], c=y_pred)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607205925872.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607205903894.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;参考&#34;&gt;参考&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Rt411q7WJ?p=71&amp;amp;vd_source=fe8e916be2bd597efffd8dfd95249141&#34;&gt;聚类算法&lt;/a&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/</guid>
            <title>贝叶斯算法</title>
            <link>https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/</link>
            <category>Python</category>
            <category>Jupyter Notebook</category>
            <pubDate>Wed, 07 Jun 2023 15:56:38 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;贝叶斯算法&#34;&gt;贝叶斯算法&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;总体信息：当前总体样本符合某种分布。比如抛硬币符合二项 分布；学生的某一科的成绩符合正态分布。&lt;/li&gt;
&lt;li&gt;样本信息：通过抽样得到的部分样本的某种分布。&lt;/li&gt;
&lt;li&gt;抽样信息=总体信息+样本信息&lt;/li&gt;
&lt;li&gt;先验信息：抽样之前，有关推断问题中未知参数的一些信息， 通常来自于经验或历史资料。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基于抽样信息进行统计推断的理论和方法称为经典统计学。&lt;/p&gt;
&lt;p&gt;基于抽样信息+先验信息进行统计推断的方法和理 论，称为贝叶斯统计学。&lt;/p&gt;
&lt;h2 id=&#34;贝叶斯定理&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F/9683982?fr=aladdin&#34;&gt;贝叶斯定理&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;已知&lt;span class=&#34;math inline&#34;&gt;\(P(X|H)\)&lt;/span&gt;，要求解&lt;span class=&#34;math inline&#34;&gt;\(P(H|X)\)&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[
P(H|X)=\frac{P(X|H)P(H)}{P(X)}
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;示例代码&#34;&gt;示例代码&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 导入算法包以及数据集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.model_selection &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; train_test_split&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.metrics &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; classification_report,confusion_matrix&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.naive_bayes &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; MultinomialNB,BernoulliNB,GaussianNB&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;iris = datasets.load_iris()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_train,x_test,y_train,y_test = train_test_split(iris.data, iris.target) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建并拟合模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mul_nb = GaussianNB()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mul_nb.fit(x_train,y_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 评估&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(classification_report(mul_nb.predict(x_test),y_test))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607165131324.png&#34;  style=&#34;zoom: 67%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;词袋模型bag-of-words&#34;&gt;词袋模型(Bag of Words)&lt;/h2&gt;
&lt;p&gt;Bag of words model（BoW）最早出现在自然语言处理（Natural Language Processing）和信息检索 （Information Retrieval）领域。&lt;/p&gt;
&lt;p&gt;该模型忽略掉文本的语法和语序等要素，将其仅仅看作是若干个词汇的集合，文档中每个单词的出现都是独立的。BoW使用一组无序的单词(words)来表达一段文字或一个文档。&lt;/p&gt;
&lt;p&gt;简单例子&lt;/p&gt;
&lt;p&gt;首先给出两个简单的文本文档如下：&lt;/p&gt;
&lt;p&gt;John likes to watch movies. Mary likes too.&lt;/p&gt;
&lt;p&gt;John also likes to watch football games.&lt;/p&gt;
&lt;p&gt;对于上述两个文档中出现的单词，构建如下一个词典 (dictionary)：&lt;/p&gt;
&lt;p&gt;{“John”: 1, “likes”: 2,“to”: 3, “watch”: 4, “movies”: 5,“also”: 6, “football”: 7, “games”: 8,“Mary”: 9, “too”: 10}&lt;/p&gt;
&lt;p&gt;上面的词典中包含10个单词, 每个单词有唯一的索引, 那么每个文本可以使用一个10维的向量来表示。&lt;/p&gt;
&lt;p&gt;[1, 2, 1, 1, 1, 0, 0, 0, 1, 1]&lt;/p&gt;
&lt;p&gt;[1, 1,1, 1, 0, 1, 1, 1, 0, 0]&lt;/p&gt;
&lt;p&gt;该向量与原来文本中单词出现的顺序没有关系，而是词典中每个单词在文本中出现的频率。&lt;/p&gt;
&lt;h2 id=&#34;tf-idf&#34;&gt;TF-IDF&lt;/h2&gt;
&lt;p&gt;TF（Term Frequency） 词频&lt;/p&gt;
&lt;p&gt;IDF （Inverse Document Frequency）逆文档频率&lt;/p&gt;
&lt;h1 id=&#34;参考&#34;&gt;参考&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Rt411q7WJ?p=60&#34;&gt;贝叶斯算法&lt;/a&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</guid>
            <title>集成学习</title>
            <link>https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/</link>
            <category>Python</category>
            <category>Jupyter Notebook</category>
            <pubDate>Wed, 07 Jun 2023 09:32:09 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;集成学习ensemble-learning&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E5%88%86%E7%B1%BB%E5%99%A8%E9%9B%86%E6%88%90/21512231?fromtitle=%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0&amp;amp;fromid=3440721&amp;amp;fr=aladdin&#34;&gt;集成学习（Ensemble Learning）&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;集成学习就是组合多个学习器，最后可以得到一个更 好的学习器。&lt;/p&gt;
&lt;p&gt;集成学习算法：&lt;/p&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;&lt;p&gt;个体学习器之间不存在强依赖关系，装袋（Bagging）&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;随机森林（Random Forest）&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;个体学习器之间存在强依赖关系，提升（Boosting）&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Stacking&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;bagging&#34;&gt;Bagging&lt;/h2&gt;
&lt;p&gt;Bagging也叫做Bootstrap Aggregating，是在原始 数据集选择S次后得到S个新数据集的一种技术。是一 种有放回抽样。&lt;/p&gt;
&lt;p&gt;原始训练数据集&lt;span class=&#34;math inline&#34;&gt;\(0,1,2,3,4,5,6,7,8,9\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Bagging采样&lt;span class=&#34;math inline&#34;&gt;\(1,3,5,2,6,4,2,5,7,0——未采样8,9\)&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;示例代码&#34;&gt;示例代码&lt;/h3&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 导入算法包以及数据集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; neighbors&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.ensemble &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; BaggingClassifier&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tree&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.model_selection &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; train_test_split&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;划分数据集&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;iris = datasets.load_iris()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = iris.data[:,:&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = iris.target&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_train,x_test,y_train,y_test = train_test_split(x_data, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建并训练KNN模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;knn = neighbors.KNeighborsClassifier()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;knn.fit(x_train, y_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;plot&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;model&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 获取数据值所在的范围&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x_min, x_max = x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    y_min, y_max = x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 生成网格矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    xx, yy = np.meshgrid(np.arange(x_min, x_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                         np.arange(y_min, y_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    z = model.predict(np.c_[xx.ravel(), yy.ravel()])&lt;span class=&#34;comment&#34;&gt;# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    z = z.reshape(xx.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 等高线图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    cs = plt.contourf(xx, yy, z)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plot(knn)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 样本散点图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], c=y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.xlabel(&lt;span class=&#34;string&#34;&gt;&amp;quot;knn&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;knn.score(x_test, y_test) &lt;span class=&#34;comment&#34;&gt;# KNN模型准确率&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建并训练bagging_knn模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;bagging_knn = BaggingClassifier(knn, n_estimators=&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;bagging_knn.fit(x_train, y_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plot(bagging_knn)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 样本散点图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], c=y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.xlabel(&lt;span class=&#34;string&#34;&gt;&amp;#x27;bagging_knn&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;bagging_knn.score(x_test, y_test) &lt;span class=&#34;comment&#34;&gt;# bagging_knn模型准确率&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607113057905.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607113349947.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;随机森林random-forest&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/1974765?fr=aladdin&#34;&gt;随机森林（Random Forest）&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;算法流程：&lt;/p&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;&lt;p&gt;随机选取样本：在样本集用&lt;strong&gt;bagging&lt;/strong&gt;的方式随机选择n个样本。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;随机选取特征：从所有属性d中随机选择k个属性（k&amp;lt;d），然后从k个属性中选择最佳分割属性作为节点建立 CART决策树。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;重复以上两个步骤m次，建立m棵CART决策树。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;这m棵CART决策树形成随机森林，通过投票表决结 果，决定数据属于哪一类。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;示例代码-1&#34;&gt;示例代码&lt;/h3&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tree&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.model_selection &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; train_test_split&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.ensemble &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; RandomForestClassifier &lt;span class=&#34;comment&#34;&gt;# 集成学习中的随机森林模块&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = np.genfromtxt(&lt;span class=&#34;string&#34;&gt;&amp;quot;LR-testSet2.txt&amp;quot;&lt;/span&gt;, delimiter=&lt;span class=&#34;string&#34;&gt;&amp;quot;,&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = data[:,:-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = data[:,-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],x_data[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;],c=y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 划分数据集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_train,x_test,y_train,y_test = train_test_split(x_data, y_data, test_size = &lt;span class=&#34;number&#34;&gt;0.5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;plot&lt;/span&gt;(&lt;span class=&#34;params&#34;&gt;model&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 获取数据值所在的范围&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x_min, x_max = x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    y_min, y_max = x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 生成网格矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    xx, yy = np.meshgrid(np.arange(x_min, x_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                         np.arange(y_min, y_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    z = model.predict(np.c_[xx.ravel(), yy.ravel()])&lt;span class=&#34;comment&#34;&gt;# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    z = z.reshape(xx.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 等高线图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    cs = plt.contourf(xx, yy, z)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 样本散点图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.scatter(x_test[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], x_test[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], c=y_test)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建并训练随机森林模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;RF = RandomForestClassifier(n_estimators=&lt;span class=&#34;number&#34;&gt;50&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;RF.fit(x_train, y_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plot(RF)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;RF.score(x_test, y_test)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607114037530.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;boosting&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/Boosting/1403912?fr=aladdin&#34;&gt;Boosting&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;AdaBoost （Adaptive Boosting）算法，它的自适应在于，前一个基本分类器被错误分类的样本的权值会增大，而正确分类的样本的权值会减小，并再次用来训练下一个基本分类器。同时，在每一轮迭代中，加入一个新的弱分类器，直到达到某个预定的足够小的错误率或达到预先指定的最大迭代次数才确定最终的强分类器。&lt;/p&gt;
&lt;p&gt;算法流程：&lt;/p&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;&lt;p&gt;初始化训练数据的权值分布&lt;span class=&#34;math inline&#34;&gt;\(D1\)&lt;/span&gt;。假设有&lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;个训练样本数据，则每一个训练样本最开始时，都被赋予 相同的权值&lt;span class=&#34;math inline&#34;&gt;\(w~1~=1/N\)&lt;/span&gt;。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;训练弱分类器&lt;span class=&#34;math inline&#34;&gt;\(h_i\)&lt;/span&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;如果某个训练样本点，被弱分类器&lt;span class=&#34;math inline&#34;&gt;\(h_i\)&lt;/span&gt;准确地分类，那么在构造下一个训练集中，它对应的权值要减小；&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;如果某个训练样本点，被弱分类器&lt;span class=&#34;math inline&#34;&gt;\(h_i\)&lt;/span&gt;错误分类，那么它的权值就应该增大。权值更新过的样本集被用于训练下一个分类器，整个训练过程如此迭代地进行下去。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;将各个训练得到的弱分类器组合成一个强分类器。各个弱分类器的训练过程结束后，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加大分类误差率小的弱分类器的权重，使其在最终的分类函数中起着较大的决定作用，&lt;/li&gt;
&lt;li&gt;降低分类误差率大的弱分类器的权重，使其在最终的分类函数中起着较小的决定作用。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;示例代码-2&#34;&gt;示例代码&lt;/h3&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tree&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.ensemble &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; AdaBoostClassifier&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.tree &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DecisionTreeClassifier&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.datasets &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; make_gaussian_quantiles&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.metrics &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; classification_report&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 生成2维正态分布，生成的数据按分位数分为两类，500个样本,2个样本特征&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x1, y1 = make_gaussian_quantiles(n_samples=&lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;, n_features=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;,n_classes=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 生成2维正态分布，生成的数据按分位数分为两类，400个样本,2个样本特征均值都为3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x2, y2 = make_gaussian_quantiles(mean=(&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;), n_samples=&lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;, n_features=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;, n_classes=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 将两组数据合成一组数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = np.concatenate((x1, x2))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = np.concatenate((y1, - y2 + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], c=y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# AdaBoost模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;),n_estimators=&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 训练模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(x_data, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 获取数据值所在的范围&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_min, x_max = x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_min, y_max = x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 生成网格矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;xx, yy = np.meshgrid(np.arange(x_min, x_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                     np.arange(y_min, y_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 获取预测值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = model.predict(np.c_[xx.ravel(), yy.ravel()])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = z.reshape(xx.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 等高线图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cs = plt.contourf(xx, yy, z)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 样本散点图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], c=y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 模型准确率&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.score(x_data,y_data)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607153300730.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;stacking&#34;&gt;Stacking&lt;/h2&gt;
&lt;p&gt;使用多个不同的分类器对训练集进预测，把预测 得到的结果作为一个次级分类器的输入。次级分 类器的输出是整个模型的预测结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607153502918.png&#34;  style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;示例代码-3&#34;&gt;示例代码&lt;/h3&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; datasets  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; model_selection  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.linear_model &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; LogisticRegression&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.neighbors &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; KNeighborsClassifier  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.tree &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; DecisionTreeClassifier&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mlxtend.classifier &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; StackingClassifier&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;iris = datasets.load_iris()  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 只要第1,2列的特征&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data, y_data = iris.data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;], iris.target  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 定义三个不同的分类器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;clf1 = KNeighborsClassifier(n_neighbors=&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;clf2 = DecisionTreeClassifier() &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;clf3 = LogisticRegression()  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 定义一个次级分类器&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lr = LogisticRegression()  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;sclf = StackingClassifier(classifiers=[clf1, clf2, clf3],   &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                          meta_classifier=lr)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; clf,label &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;zip&lt;/span&gt;([clf1, clf2, clf3, sclf],&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                      [&lt;span class=&#34;string&#34;&gt;&amp;#x27;KNN&amp;#x27;&lt;/span&gt;,&lt;span class=&#34;string&#34;&gt;&amp;#x27;Decision Tree&amp;#x27;&lt;/span&gt;,&lt;span class=&#34;string&#34;&gt;&amp;#x27;LogisticRegression&amp;#x27;&lt;/span&gt;,&lt;span class=&#34;string&#34;&gt;&amp;#x27;StackingClassifier&amp;#x27;&lt;/span&gt;]):  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    scores = model_selection.cross_val_score(clf, x_data, y_data, cv=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;, scoring=&lt;span class=&#34;string&#34;&gt;&amp;#x27;accuracy&amp;#x27;&lt;/span&gt;)  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;quot;Accuracy: %0.2f [%s]&amp;quot;&lt;/span&gt; % (scores.mean(), label)) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 可视化   &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;sclf.fit(x_train,y_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plot(sclf)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],x_data[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;],c=y_data)    &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607155449811.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;参考&#34;&gt;参考&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Rt411q7WJ/?p=55&amp;amp;spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;amp;vd_source=fe8e916be2bd597efffd8dfd95249141&#34;&gt;集成学习&lt;/a&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/</guid>
            <title>决策树</title>
            <link>https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/</link>
            <category>Python</category>
            <category>Jupyter Notebook</category>
            <pubDate>Tue, 06 Jun 2023 20:25:49 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;决策树-decision-tree&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E5%86%B3%E7%AD%96%E6%A0%91/10377049?fr=aladdin&#34;&gt;决策树 （Decision Tree）&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;比较适合分析离散数据。 如果是连续数据要先转成离散数据再做分析&lt;/p&gt;
&lt;h2 id=&#34;熵entropy&#34;&gt;熵（entropy）&lt;/h2&gt;
&lt;p&gt;1948年，香浓提出了“&lt;a href=&#34;https://baike.baidu.com/item/%E4%BF%A1%E6%81%AF%E7%86%B5/7302318?fr=aladdin&#34;&gt;信息熵&lt;/a&gt;”的概念，&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一条信息的信息量大小和它的不确定性有直接的关系， 要搞清楚一件非常非常不确定的事情，或者是一无所知的事情，需要了解大量信息。—&amp;gt;信息量的度量就等于不确定性的多少。&lt;/strong&gt;&lt;/p&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;p&gt;信息熵公式： &lt;span class=&#34;math display&#34;&gt;\[
H[x]=-\sum_{x}p(x)logp(x)
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;id3算法&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/ID3%E7%AE%97%E6%B3%95/5522381?fr=aladdin&#34;&gt;ID3算法&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;决策树会选择最大化信息增益来对结点进行划分。&lt;/p&gt;
&lt;p&gt;信息增益（Information Gain）计算： &lt;span class=&#34;math display&#34;&gt;\[
Info(D)=-\sum_{i=1}^{m}p_ilog(p_i)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Info_A(D)=-\sum_{j=1}^{v}\frac{|D_j|}{|D|}\times Info(D_j)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Gain(A)=Info(D)-Info_A(D)
\]&lt;/span&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;RID&lt;/th&gt;
&lt;th&gt;age&lt;/th&gt;
&lt;th&gt;income&lt;/th&gt;
&lt;th&gt;student&lt;/th&gt;
&lt;th&gt;credit_rating&lt;/th&gt;
&lt;th&gt;class_buys_computer&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;youth&lt;/td&gt;
&lt;td&gt;high&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;td&gt;fair&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;youth&lt;/td&gt;
&lt;td&gt;high&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;td&gt;excellent&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;middle_aged&lt;/td&gt;
&lt;td&gt;high&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;td&gt;fair&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;senior&lt;/td&gt;
&lt;td&gt;medium&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;td&gt;fair&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;senior&lt;/td&gt;
&lt;td&gt;low&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;td&gt;fair&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;senior&lt;/td&gt;
&lt;td&gt;low&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;td&gt;excellent&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;middle_aged&lt;/td&gt;
&lt;td&gt;low&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;td&gt;excellent&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;youth&lt;/td&gt;
&lt;td&gt;medium&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;td&gt;fair&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;youth&lt;/td&gt;
&lt;td&gt;low&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;td&gt;fair&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;senior&lt;/td&gt;
&lt;td&gt;medium&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;td&gt;fair&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;youth&lt;/td&gt;
&lt;td&gt;medium&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;td&gt;excellent&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;middle_aged&lt;/td&gt;
&lt;td&gt;medium&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;td&gt;excellent&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;middle_aged&lt;/td&gt;
&lt;td&gt;high&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;td&gt;fair&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;td&gt;senior&lt;/td&gt;
&lt;td&gt;medium&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;td&gt;excellent&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;计算&lt;strong&gt;age&lt;/strong&gt;的信息增益: &lt;span class=&#34;math display&#34;&gt;\[
Info(D)=-\frac{9}{14}log_2(\frac{9}{14})-\frac{5}{14}log_2(\frac{5}{14})=0.94
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Info_{age}(D)=\frac{5}{14}(-\frac{2}{5}log_2\frac{2}{5}-\frac{3}{5}log_2\frac{3}{5})+
\frac{4}{14}(-\frac{4}{4}log_2\frac{4}{4}-\frac{0}{4}log_2\frac{0}{4})+
\frac{5}{14}(-\frac{3}{5}log_2\frac{3}{5}-\frac{2}{5}log_2\frac{2}{5})
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Gain(age)=Info(D)-Info_A(D)=0.94-0.694=0.246
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;其他的也是类似计算。&lt;/p&gt;
&lt;h2 id=&#34;c4.5算法&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/C4.5%E7%AE%97%E6%B3%95/20814636&#34;&gt;C4.5算法&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;信息增益的方法倾向于首先选择因子数较多的变量 。&lt;/p&gt;
&lt;p&gt;信息增益的改进：增益率 &lt;span class=&#34;math display&#34;&gt;\[
SplitInfo_A(D)=-\sum_{j=1}^{v}\frac{|D_j|}{|D|}\times log_2(\frac{|D_j|}{|D|})
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
GainRatio(A)=\frac{Gain(A)}{SpliInfo_A(D)}
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;cart算法&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/CART/17679070&#34;&gt;CART算法&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;CART决策树的生成就是递归地构建二叉决策树的过程。&lt;/p&gt;
&lt;p&gt;CART用基尼（Gini）系数最小化准则来进行特征选择，生成二叉树。&lt;/p&gt;
&lt;p&gt;Gini系数计算： &lt;span class=&#34;math display&#34;&gt;\[
Gini(D)=1-\sum_{i=1}^{m}p_i^2
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Gini_A(D)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\Delta Gini(A)=Gini(D)-Gini_A(D)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;优点：小规模数据集有效&lt;/p&gt;
&lt;p&gt;缺点： 处理连续变量不好 类别较多时，错误增加的比较快 不能处理大量数据&lt;/p&gt;
&lt;h2 id=&#34;线性二分类示例代码&#34;&gt;线性二分类示例代码&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.metrics &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; classification_report&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tree &lt;span class=&#34;comment&#34;&gt;# 决策树模块&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = np.genfromtxt(&lt;span class=&#34;string&#34;&gt;&amp;quot;LR-testSet.csv&amp;quot;&lt;/span&gt;, delimiter=&lt;span class=&#34;string&#34;&gt;&amp;quot;,&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = data[:,:-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = data[:,-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],x_data[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;],c=y_data) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建决策树模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = tree.DecisionTreeClassifier()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 输入数据建立模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(x_data, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 获取数据值所在的范围&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_min, x_max = x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_min, y_max = x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 生成网格矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;xx, yy = np.meshgrid(np.arange(x_min, x_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                     np.arange(y_min, y_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = model.predict(np.c_[xx.ravel(), yy.ravel()])&lt;span class=&#34;comment&#34;&gt;# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = z.reshape(xx.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 等高线图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cs = plt.contourf(xx, yy, z)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 样本散点图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], c=y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 测试与评估&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;predictions = model.predict(x_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(classification_report(predictions,y_data))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607084609741.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230606214438933.png&#34;  style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;非线性二分类示例代码&#34;&gt;非线性二分类示例代码&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.metrics &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; classification_report&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tree&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.model_selection &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; train_test_split&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = np.genfromtxt(&lt;span class=&#34;string&#34;&gt;&amp;quot;LR-testSet2.txt&amp;quot;&lt;/span&gt;, delimiter=&lt;span class=&#34;string&#34;&gt;&amp;quot;,&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = data[:,:-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = data[:,-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;],x_data[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;],c=y_data) &lt;span class=&#34;comment&#34;&gt;# s散点图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#分割数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_train,x_test,y_train,y_test = train_test_split(x_data, y_data) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建决策树模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# max_depth，树的深度&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# min_samples_split 内部节点再划分所需最小样本数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = tree.DecisionTreeClassifier(max_depth=&lt;span class=&#34;number&#34;&gt;7&lt;/span&gt;,min_samples_split=&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 拟合模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(x_train, y_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 获取数据值所在的范围&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_min, x_max = x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_min, y_max = x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 生成网格矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;xx, yy = np.meshgrid(np.arange(x_min, x_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                     np.arange(y_min, y_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = model.predict(np.c_[xx.ravel(), yy.ravel()])&lt;span class=&#34;comment&#34;&gt;# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = z.reshape(xx.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 等高线图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cs = plt.contourf(xx, yy, z)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 样本散点图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], c=y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 测试并评估&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;predictions = model.predict(x_test)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(classification_report(predictions,y_test))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607084429752.png&#34;  style=&#34;zoom: 50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607084526669.png&#34;  style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;回归树示例代码&#34;&gt;回归树示例代码&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; tree&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = np.genfromtxt(&lt;span class=&#34;string&#34;&gt;&amp;quot;data.csv&amp;quot;&lt;/span&gt;, delimiter=&lt;span class=&#34;string&#34;&gt;&amp;quot;,&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = data[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;,np.newaxis]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = data[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,np.newaxis]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data,y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = tree.DecisionTreeRegressor(max_depth=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(x_data, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_test = np.linspace(&lt;span class=&#34;number&#34;&gt;20&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;80&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_test = x_test[:,np.newaxis]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(x_data, y_data, &lt;span class=&#34;string&#34;&gt;&amp;#x27;b&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(x_test, model.predict(x_test), &lt;span class=&#34;string&#34;&gt;&amp;#x27;r&amp;#x27;&lt;/span&gt;) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230607090010220.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;参考&#34;&gt;参考&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Rt411q7WJ?p=50&amp;amp;vd_source=fe8e916be2bd597efffd8dfd95249141&#34;&gt;决策树&lt;/a&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95/</guid>
            <title>KNN算法</title>
            <link>https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95/</link>
            <category>Python</category>
            <category>Jupyter Notebook</category>
            <pubDate>Tue, 06 Jun 2023 20:05:23 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;k最近邻k-nearest-neighborknn分类算法&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/9512781?fr=aladdin&#34;&gt;K最近邻（K-Nearest Neighbor，KNN）&lt;/a&gt;分类算法&lt;/h1&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;为了判断未知实例的类别，以所有已知类别的实例作为 参照选择参数K&lt;/li&gt;
&lt;li&gt;计算未知实例与所有已知实例的距离&lt;/li&gt;
&lt;li&gt;选择最近K个已知实例&lt;/li&gt;
&lt;li&gt;根据少数服从多数的投票法则(majority-voting)，让 未知实例归类为K个最邻近样本中最多数的类别&lt;/li&gt;
&lt;/ol&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;p&gt;欧氏距离 &lt;span class=&#34;math display&#34;&gt;\[
E(x,y)=\sqrt{\sum_{i=0}^{n}(x_i-y_i)^2}
\]&lt;/span&gt; &lt;a href=&#34;https://www.cnblogs.com/belfuture/p/5871452.html&#34;&gt;其他的距离衡量&lt;/a&gt;：余弦值距离（cos），相关度（correlation），曼哈顿距离（Manhattan distance）&lt;/p&gt;
&lt;p&gt;算法缺点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;算法复杂度较高（需要比较所有已知实例与要分类的实例）&lt;/li&gt;
&lt;li&gt;当其样本分布不平衡时，比如其中一类样本过大（实例数量过多）占主导的时候，新的未知实例容易被归类为这个主导样本，因为这类样本实例的数量过大，但这个新的未知实例实际并没有接近目标样本&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;示例代码&#34;&gt;示例代码&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 导入算法包以及数据集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; neighbors&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; datasets&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.model_selection &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; train_test_split&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.metrics &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; classification_report&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; random&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;iris = datasets.load_iris()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(iris)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 打乱数据切分数据集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# x_train,x_test,y_train,y_test = train_test_split(iris.data, iris.target, test_size=0.2) #分割数据0.2为测试数据，0.8为训练数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#打乱数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data_size = iris.data.shape[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;index = [i &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(data_size)] &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;random.shuffle(index)  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;iris.data = iris.data[index]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;iris.target = iris.target[index]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#切分数据集&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;test_size = &lt;span class=&#34;number&#34;&gt;40&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_train = iris.data[test_size:]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_test =  iris.data[:test_size]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_train = iris.target[test_size:]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_test = iris.target[:test_size]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 构建模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = neighbors.KNeighborsClassifier(n_neighbors=&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(x_train, y_train)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 测试和评估&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;prediction = model.predict(x_test)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(classification_report(y_test, prediction))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230606202144425.png&#34;  style=&#34;zoom: 67%;&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;参考&#34;&gt;参考&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Rt411q7WJ?p=41&amp;amp;vd_source=fe8e916be2bd597efffd8dfd95249141&#34;&gt;KNN算法&lt;/a&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</guid>
            <title>逻辑回归</title>
            <link>https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</link>
            <category>Python</category>
            <category>Jupyter Notebook</category>
            <pubDate>Mon, 05 Jun 2023 21:32:23 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;逻辑回归logistic-regression&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/logistic%E5%9B%9E%E5%BD%92/2981575?fromtitle=%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92&amp;amp;fromid=17202449&amp;amp;fr=aladdin&#34;&gt;逻辑回归（Logistic Regression）&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;是一种广义的线性回归分析模型，与多重线性回归有很多相同之处。它们的模型形式基本上相同，都具有$ w’x+b$，其区别在于他们的因变量不同，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多重线性回归直接将&lt;span class=&#34;math inline&#34;&gt;\(w&amp;#39;x+b\)&lt;/span&gt;作为因变量，&lt;/li&gt;
&lt;li&gt;Logistic回归则通过函数L将&lt;span class=&#34;math inline&#34;&gt;\(w&amp;#39;x+b\)&lt;/span&gt;对应一个隐状态&lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(p =L(w&amp;#39;x+b)\)&lt;/span&gt;，然后根据&lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;与&lt;span class=&#34;math inline&#34;&gt;\(1-p\)&lt;/span&gt;的大小决定因变量的值。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果L是Logistic函数，就是Logistic回归，&lt;/p&gt;
&lt;p&gt;如果L是多项式函数就是多项式回归。&lt;/p&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;h2 id=&#34;logistic-function&#34;&gt;Logistic Function&lt;/h2&gt;
&lt;p&gt;定义逻辑回归的预测函数为&lt;span class=&#34;math inline&#34;&gt;\(ℎ_\theta(x) = 𝑔(\theta^𝑇𝑥)\)&lt;/span&gt; ，其中g(x)函数是sigmoid函数。 &lt;span class=&#34;math display&#34;&gt;\[
g(x)=\frac{1}{1+e^{-x}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230606093600860.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;ol type=&#34;1&#34;&gt;
&lt;li&gt;当&lt;span class=&#34;math inline&#34;&gt;\(\theta^Tx≥0\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(g(\theta^Tx)≥0.5\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;当&lt;span class=&#34;math inline&#34;&gt;\(\theta^Tx≤0\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(g(\theta^Tx)≤0.5\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;逻辑回归的代价函数cost-function&#34;&gt;逻辑回归的代价函数（Cost Function）&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Cost(h_\theta(x),y)= 
\begin{cases}
-log(h_\theta(x))\quad\quad\quad if\quad y=1\\
-log(1-h_\theta(x))\quad if\quad y=0
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
=-ylog(h_\theta(x))-(1-y)log(1-h_\theta(x))
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;梯度下降法gradient-descent&#34;&gt;梯度下降法（Gradient Descent）&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
J(\theta)=-\frac{1}{m}[\sum_{i=1}^{m}y^{(i)}logh_\theta(x^{(i)})+(1-y^{(i)})log(1-h_\theta(x^{(i)}))]
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;求解 &lt;span class=&#34;math inline&#34;&gt;\(min_\theta J(\theta)\)&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[
\theta_j:=\theta_j-\alpha\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;准确率精准率召回率f1分数&#34;&gt;准确率|精准率|召回率|F&lt;sub&gt;1&lt;/sub&gt;分数&lt;/h2&gt;
&lt;p&gt;混淆矩阵&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;实际&lt;/th&gt;
&lt;th&gt;实际&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;预测&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;TP&lt;/td&gt;
&lt;td&gt;FP&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;预测&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;FN&lt;/td&gt;
&lt;td&gt;TN&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;P（Positive）：代表1&lt;/li&gt;
&lt;li&gt;N（Negative）：代表0&lt;/li&gt;
&lt;li&gt;T（True）：代表预测正确&lt;/li&gt;
&lt;li&gt;F（False）：代表预测错误&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;准确率：&lt;/strong&gt;即预测正确的结果占总样本的百分比 &lt;span class=&#34;math display&#34;&gt;\[
准确率=\frac{TP+TN}{TP+TN+FP+FN}
\]&lt;/span&gt; &lt;strong&gt;精准率（Precision）：&lt;/strong&gt;是指在所有被预测为正的样本中实际为正的样本的概率。 &lt;span class=&#34;math display&#34;&gt;\[
精准率=\frac{TP}{TP+FP}
\]&lt;/span&gt; &lt;strong&gt;精准率就是你认为找的是对的实际上多少是对的&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;召回率（Recall）：&lt;/strong&gt;是指在实际为正的样本中被预测为正样本的概率。 &lt;span class=&#34;math display&#34;&gt;\[
召回率=\frac{TP}{TP+FN}
\]&lt;/span&gt; &lt;strong&gt;F&lt;sub&gt;1&lt;/sub&gt;分数：&lt;/strong&gt;精准率和召回率之间的一个平衡点。 &lt;span class=&#34;math display&#34;&gt;\[
F_1=\frac{2\times Precision\times Recall}{Precision+Recall}
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;逻辑回归示例代码&#34;&gt;逻辑回归示例代码&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;51&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.metrics &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; classification_report&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; preprocessing&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; linear_model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 数据是否需要标准化&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;scale = &lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = np.genfromtxt(&lt;span class=&#34;string&#34;&gt;&amp;quot;LR-testSet.csv&amp;quot;&lt;/span&gt;, delimiter=&lt;span class=&#34;string&#34;&gt;&amp;quot;,&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = data[:,:-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = data[:,-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;title function_&#34;&gt;plot&lt;/span&gt;():&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x0 = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x1 = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    y0 = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    y1 = []&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 切分不同类别的数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; i &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;built_in&#34;&gt;range&lt;/span&gt;(&lt;span class=&#34;built_in&#34;&gt;len&lt;/span&gt;(x_data)):&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; y_data[i]==&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            x0.append(x_data[i,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            y0.append(x_data[i,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;keyword&#34;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            x1.append(x_data[i,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;            y1.append(x_data[i,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 画图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;   scatter0 = plt.scatter(x0, y0, c=&lt;span class=&#34;string&#34;&gt;&amp;#x27;c&amp;#x27;&lt;/span&gt;, marker=&lt;span class=&#34;string&#34;&gt;&amp;#x27;+&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    scatter1 = plt.scatter(x1, y1, c=&lt;span class=&#34;string&#34;&gt;&amp;#x27;y&amp;#x27;&lt;/span&gt;, marker=&lt;span class=&#34;string&#34;&gt;&amp;#x27;*&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;#画图例&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.legend(handles=[scatter0,scatter1],labels=[&lt;span class=&#34;string&#34;&gt;&amp;#x27;label0&amp;#x27;&lt;/span&gt;,&lt;span class=&#34;string&#34;&gt;&amp;#x27;label1&amp;#x27;&lt;/span&gt;],loc=&lt;span class=&#34;string&#34;&gt;&amp;#x27;best&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plot()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建并拟合模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;logistic = linear_model.LogisticRegression()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;logistic.fit(x_data, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;if&lt;/span&gt; scale == &lt;span class=&#34;literal&#34;&gt;False&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;span class=&#34;comment&#34;&gt;# 画图决策边界&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plot()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    x_test = np.array([[-&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;],[&lt;span class=&#34;number&#34;&gt;3&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    y_test = (-logistic.intercept_ - x_test*logistic.coef_[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;])/logistic.coef_[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;][&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.plot(x_test, y_test, &lt;span class=&#34;string&#34;&gt;&amp;#x27;k&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 测试与评估    &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;predictions = logistic.predict(x_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(classification_report(y_data, predictions))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230606164354040.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230606164557574.png&#34;  style=&#34;zoom: 67%;&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;非线性逻辑回归示例代码&#34;&gt;非线性逻辑回归示例代码&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;43&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; linear_model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.datasets &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; make_gaussian_quantiles&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.preprocessing &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; PolynomialFeatures&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 生成2维正态分布，生成的数据按分位数分为两类，500个样本,2个样本特征&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 可以生成两类或多类数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data, y_data = make_gaussian_quantiles(n_samples=&lt;span class=&#34;number&#34;&gt;500&lt;/span&gt;, n_features=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;,n_classes=&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], c=y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建并拟合模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;logistic = linear_model.LogisticRegression()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;logistic.fit(x_data, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 定义多项式回归,degree的值可以调节多项式的特征&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;poly_reg  = PolynomialFeatures(degree=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 特征处理&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_poly = poly_reg.fit_transform(x_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 定义逻辑回归模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;logistic = linear_model.LogisticRegression()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 训练模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;logistic.fit(x_poly, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 获取数据值所在的范围&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_min, x_max = x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_min, y_max = x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;() - &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;, x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;].&lt;span class=&#34;built_in&#34;&gt;max&lt;/span&gt;() + &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 生成网格矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;xx, yy = np.meshgrid(np.arange(x_min, x_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;                     np.arange(y_min, y_max, &lt;span class=&#34;number&#34;&gt;0.02&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = logistic.predict(poly_reg.fit_transform(np.c_[xx.ravel(), yy.ravel()]))&lt;span class=&#34;comment&#34;&gt;# ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = z.reshape(xx.shape)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 等高线图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;cs = plt.contourf(xx, yy, z)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 样本散点图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data[:, &lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], x_data[:, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], c=y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;score:&amp;#x27;&lt;/span&gt;,logistic.score(x_poly,y_data))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230606165631817.png&#34;  style=&#34;zoom:67%;&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;参考&#34;&gt;参考&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Rt411q7WJ?p=29&#34;&gt;逻辑回归&lt;/a&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%8F%8A%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</guid>
            <title>线性回归及非线性回归</title>
            <link>https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%8F%8A%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</link>
            <category>Python</category>
            <category>Jupyter Notebook</category>
            <pubDate>Mon, 05 Jun 2023 09:37:27 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;基本概念&#34;&gt;基本概念：&lt;/h1&gt;
&lt;p&gt;将数据划分为三部分：&lt;span class=&#34;math inline&#34;&gt;\(\begin{cases} 训练集(Train):用来训练，构建模型\\ 验证集(Validate):在模型训练阶段，测试模型的好坏\\ 测试集(Test):等模型训练好后，评估模型的好坏 \end{cases}\)&lt;/span&gt;&lt;/p&gt;
&lt;span id=&#34;more&#34;&gt;&lt;/span&gt;
&lt;p&gt;学习方式：&lt;span class=&#34;math inline&#34;&gt;\(\begin{cases} 监督学习\\ 无监督学习\\ 半监督学习\\ 强化学习\end{cases}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;监督学习&lt;/strong&gt;是利用一组&lt;strong&gt;带标签的数据&lt;/strong&gt;，学习从输入到输出的映射关系&lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;，然后将学习到的映射关系&lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;应用到未知的数据上，用于预测未知数据的类别或数值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;半监督学习&lt;/strong&gt;属于监督学习的延伸，它的输入数据小部分有标签的，而&lt;strong&gt;大部分是没有标签的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;无监督学习&lt;/strong&gt;是为了标识出数据内在的结构和规律，输入数据是没有任何标签的。常见的有关联规则分析、数据降维、聚类算法、词嵌入等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;强化学习&lt;/strong&gt;通过&lt;strong&gt;试错&lt;/strong&gt;（Trail and Error）学会在给定的情境下选择最恰当的行为。&lt;/p&gt;
&lt;p&gt;常见应用：&lt;span class=&#34;math inline&#34;&gt;\(\begin{cases} 回归：预测数据为连续型数值。\\ 分类：预测数据为类别型数据，并且类别已知。\\ 聚类：预测数据为类别型数据，但是类别未知。 \end{cases}\)&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;回归分析regression&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/2625498?fr=aladdin&#34;&gt;回归分析（Regression）&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;回归分析用来建立方程，模拟两个或者多个变量之间如何关联，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;被预测的变量叫做：因变量/输出&lt;/li&gt;
&lt;li&gt;被用来进行预测的变量叫做： 自变量,/输入&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一元线性回归包含一个自变量和一个因变量，两个变量的关系用一条直线来模拟，如果包含两个以上的自变量，则称作多元回归分析（multiple regression）&lt;/p&gt;
&lt;h1 id=&#34;一元线性回归&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/22770888?fr=aladdin&#34;&gt;一元线性回归&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;一元线性回归：&lt;span class=&#34;math inline&#34;&gt;\(h_\theta(x)=\theta_0+\theta_1x\)&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;代价函数cost-function&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/1783236?fromtitle=%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0&amp;amp;fromid=7048599&amp;amp;fr=aladdin&#34;&gt;代价函数（Cost Function）&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;最小二乘法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假设真实值为&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;，预测值&lt;span class=&#34;math inline&#34;&gt;\(h_\theta(x)\)&lt;/span&gt; ，则误差平方为&lt;span class=&#34;math inline&#34;&gt;\((h_\theta(x)-y)^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;找到合适的参数，使得误差平方和&lt;span class=&#34;math inline&#34;&gt;\(J(\theta_0,\theta_1)\)&lt;/span&gt;最小。 &lt;span class=&#34;math display&#34;&gt;\[
J(\theta_0,\theta_1)=\frac{1}{2m}\sum_{i=1}^{m}{(h_\theta(x^{(i)})-y^{(i)})^{2}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;梯度下降法gradient-descent&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/8641233?fr=aladdin&#34;&gt;梯度下降法（Gradient Descent）&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;最小化目标函数&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(\underset{\theta_0,\theta_1}{min}\quad J(\theta_0,\theta_1)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;初始化参数&lt;span class=&#34;math inline&#34;&gt;\(\theta_0,\theta_1\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;不断改变&lt;span class=&#34;math inline&#34;&gt;\(\theta_0,\theta_1\)&lt;/span&gt; ，直到&lt;span class=&#34;math inline&#34;&gt;\(J(\theta_0,\theta_1)\)&lt;/span&gt;到达一个全局最小值，或局部极小值。 &lt;span class=&#34;math display&#34;&gt;\[
\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)\quad (j=0,1,2\cdots)
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;用梯度下降法求解线性回归&#34;&gt;用梯度下降法求解线性回归&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1)=
\frac{1}{m}\sum_{i=1}^{m}{(h_\theta(x^{(i)})-y^{(i)})}
\\
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial}{\partial\theta_1}J(\theta_0,\theta_1)=
\frac{1}{m}\sum_{i=1}^{m}{(h_\theta(x^{(i)})-y^{(i)})}\times x^{(i)}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;不断迭代，直到收敛： &lt;span class=&#34;math display&#34;&gt;\[
\theta_0:=\theta_0-\alpha\frac{1}{m}{\sum_{i=1}^{m}{(h_\theta(x^{(i)})-y^{(i)})}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\theta_1:=\theta_1-\alpha\frac{1}{m}{\sum_{i=1}^{m}{(h_\theta(x^{(i)})-y^{(i)})}}\times x^{(i)}
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;示例代码&#34;&gt;示例代码：&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.linear_model &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; LinearRegression &lt;span class=&#34;comment&#34;&gt;# 线性回归模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = np.genfromtxt(&lt;span class=&#34;string&#34;&gt;&amp;quot;data.csv&amp;quot;&lt;/span&gt;, delimiter=&lt;span class=&#34;string&#34;&gt;&amp;quot;,&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = data[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = data[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data,y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = data[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;,np.newaxis]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = data[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,np.newaxis]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建并拟合模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = LinearRegression() &lt;span class=&#34;comment&#34;&gt;# 线性回归&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(x_data, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 测试&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_test = [[&lt;span class=&#34;number&#34;&gt;44.5&lt;/span&gt;]]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;predict = model.predict(x_test)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;#x27;predict&amp;#x27;&lt;/span&gt;,predict)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(x_data, y_data, &lt;span class=&#34;string&#34;&gt;&amp;#x27;b.&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(x_data, model.predict(x_data), &lt;span class=&#34;string&#34;&gt;&amp;#x27;r&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230605203607162.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;多元线性回归multiple-linear-regression&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/10702248?fr=aladdin&#34;&gt;多元线性回归（Multiple Linear Regression）&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;多特征时，假设：&lt;span class=&#34;math inline&#34;&gt;\(h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+\cdots+\theta_nx_n\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;当真实值&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;的影响因素不是唯一时，需采用多元线性回归模型。&lt;/p&gt;
&lt;p&gt;代价函数： &lt;span class=&#34;math display&#34;&gt;\[
J(\theta_0,\theta_1,\cdots,\theta_n)=\frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^{2}
\]&lt;/span&gt; 梯度下降法： &lt;span class=&#34;math display&#34;&gt;\[
\theta_j:=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^{m}{(h_\theta(x^{(i)})-y^{(i)})}\times x_j^{(i)}\quad (j=0,1,2\cdots,n)
\]&lt;/span&gt; 注意这里的&lt;span class=&#34;math inline&#34;&gt;\(j=0\)&lt;/span&gt;时，&lt;span class=&#34;math inline&#34;&gt;\(x_0=1\)&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;示例代码-1&#34;&gt;示例代码：&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;41&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; genfromtxt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; linear_model &lt;span class=&#34;comment&#34;&gt;# 线性回归模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; mpl_toolkits.mplot3d &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; Axes3D  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 读入数据 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = genfromtxt(&lt;span class=&#34;string&#34;&gt;r&amp;quot;Delivery.csv&amp;quot;&lt;/span&gt;,delimiter=&lt;span class=&#34;string&#34;&gt;&amp;#x27;,&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 切分数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = data[:,:-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = data[:,-&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = linear_model.LinearRegression()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(x_data, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 测试&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_test = [[&lt;span class=&#34;number&#34;&gt;102&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;4&lt;/span&gt;]]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;predict = model.predict(x_test)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(&lt;span class=&#34;string&#34;&gt;&amp;quot;predict:&amp;quot;&lt;/span&gt;,predict)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ax = plt.figure().add_subplot(&lt;span class=&#34;number&#34;&gt;111&lt;/span&gt;, projection = &lt;span class=&#34;string&#34;&gt;&amp;#x27;3d&amp;#x27;&lt;/span&gt;) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ax.scatter(x_data[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;], x_data[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;], y_data, c = &lt;span class=&#34;string&#34;&gt;&amp;#x27;r&amp;#x27;&lt;/span&gt;, marker = &lt;span class=&#34;string&#34;&gt;&amp;#x27;o&amp;#x27;&lt;/span&gt;, s = &lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;) &lt;span class=&#34;comment&#34;&gt;#点为红色三角形  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x0 = x_data[:,&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x1 = x_data[:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 生成网格矩阵&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x0, x1 = np.meshgrid(x0, x1)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;z = model.intercept_ + x0*model.coef_[&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;] + x1*model.coef_[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画3D图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ax.plot_surface(x0, x1, z)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#设置坐标轴  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ax.set_xlabel(&lt;span class=&#34;string&#34;&gt;&amp;#x27;Miles&amp;#x27;&lt;/span&gt;)  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ax.set_ylabel(&lt;span class=&#34;string&#34;&gt;&amp;#x27;Num of Deliveries&amp;#x27;&lt;/span&gt;)  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;ax.set_zlabel(&lt;span class=&#34;string&#34;&gt;&amp;#x27;Time&amp;#x27;&lt;/span&gt;)  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;#显示图像  &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()  &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230605204147960.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;多项式回归&#34;&gt;多项式回归&lt;/h1&gt;
&lt;p&gt;假如我们不是要找直线（或者超平面），而是需要找到一 个用多项式所表示的曲线（或者超曲面）&lt;/p&gt;
&lt;p&gt;多项式回归：&lt;span class=&#34;math inline&#34;&gt;\(h_\theta(x)=\theta_0+\theta_1x+\theta_2x^2+\cdots+\theta_nx^n\)&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;示例代码-2&#34;&gt;示例代码：&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.preprocessing &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; PolynomialFeatures &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn.linear_model &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; LinearRegression&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 载入数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = np.genfromtxt(&lt;span class=&#34;string&#34;&gt;&amp;quot;job.csv&amp;quot;&lt;/span&gt;, delimiter=&lt;span class=&#34;string&#34;&gt;&amp;quot;,&amp;quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = data[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = data[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:,&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.scatter(x_data,y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = x_data[:,np.newaxis]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = y_data[:,np.newaxis]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 定义多项式回归,degree的值可以调节多项式的特征&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;poly_reg  = PolynomialFeatures(degree=&lt;span class=&#34;number&#34;&gt;5&lt;/span&gt;) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 特征处理&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_poly = poly_reg.fit_transform(x_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 定义回归模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lin_reg = LinearRegression()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 训练模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;lin_reg.fit(x_poly, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(x_data, y_data, &lt;span class=&#34;string&#34;&gt;&amp;#x27;b.&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_test = np.linspace(&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;10&lt;/span&gt;,&lt;span class=&#34;number&#34;&gt;100&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_test = x_test[:,np.newaxis]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(x_test, lin_reg.predict(poly_reg.fit_transform(x_test)), c=&lt;span class=&#34;string&#34;&gt;&amp;#x27;r&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.title(&lt;span class=&#34;string&#34;&gt;&amp;#x27;Truth or Bluff (Polynomial Regression)&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.xlabel(&lt;span class=&#34;string&#34;&gt;&amp;#x27;Position level&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.ylabel(&lt;span class=&#34;string&#34;&gt;&amp;#x27;Salary&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230605205328029.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;标准方程法normal-equation&#34;&gt;标准方程法（Normal Equation）&lt;/h1&gt;
&lt;p&gt;注意这里的符号：&lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt;其实就是上面公式里的&lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;，就是要求解的那个参数。&lt;/p&gt;
&lt;p&gt;假设： &lt;span class=&#34;math display&#34;&gt;\[
h_w(x)=w_0+w_1x_1+w_2x_2+\cdots+w_nx_n
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
h_w(x)=xw\
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;目标函数: &lt;span class=&#34;math display&#34;&gt;\[
J(w_0,w_1,\cdots,w_n)=\frac{1}{2m}\sum_{i=1}^{m}(h_w(x^{(i)})-y^{(i)})^{2}
\]&lt;/span&gt; 又因为 &lt;span class=&#34;math display&#34;&gt;\[
\sum_{i=1}^{m}(h_w(x^{(i)})-y^{(i)})^{2}=(y-Xw)^T(y-Xw)
\]&lt;/span&gt; 所以 &lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial J(w)}{\partial w}=\frac{\partial(y-Xw)^T(y-Xw)}{\partial w}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
=\frac{\partial(y^Ty-y^TXw-w^TX^Ty+w^TX^TXw)}{\partial w}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
=\frac{\partial(y^Ty)}{\partial w}-\frac{\partial(y^TXw)}{\partial w}-\frac{\partial(w^TX^Ty)}{\partial w}+\frac{\partial(w^TX^TXw)}{\partial w}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
=0-X^Ty-X^Ty+2X^TXw
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial J(w)}{\partial w}=0
\]&lt;/span&gt; 求解： &lt;span class=&#34;math display&#34;&gt;\[
-2X^Ty+2X^TXw=0
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
X^TXw=X^Ty
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
w=(X^TX)^{-1}X^Ty
\]&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;特征缩放&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/item/%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE/17415222?fr=aladdin&#34;&gt;特征缩放&lt;/a&gt;&lt;/h1&gt;
&lt;h2 id=&#34;数据归一化&#34;&gt;数据归一化&lt;/h2&gt;
&lt;p&gt;数据归一化就是把数据的取值范围处理为&lt;span class=&#34;math inline&#34;&gt;\(0-1\)&lt;/span&gt;，或者&lt;span class=&#34;math inline&#34;&gt;\(-1-1\)&lt;/span&gt;之间。&lt;/p&gt;
&lt;p&gt;任意数据转化为0-1之间： &lt;span class=&#34;math display&#34;&gt;\[
NewValue = \frac{OldValue-min}{max-min}
\]&lt;/span&gt; 任意数据转化为-1-1之间： &lt;span class=&#34;math display&#34;&gt;\[
NewValue=2\times(\frac{OldVaule-min}{max-min}-0.5)
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;均值标准化&#34;&gt;均值标准化&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;为特征数据，&lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt;为数据的平均值，&lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt;为数据的方差。 &lt;span class=&#34;math display&#34;&gt;\[
NewValue=\frac{OldValue-u}{s}
\]&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;过拟合overfitting&#34;&gt;过拟合（Overfitting）&lt;/h1&gt;
&lt;p&gt;回归问题拟合有以下三种情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230605154335888.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;分类问题有以下三种情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230605154600447.png&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;防止过拟合：减少特征；增加数据量；正则化（Regularized）&lt;/p&gt;
&lt;h2 id=&#34;正则化&#34;&gt;正则化&lt;/h2&gt;
&lt;p&gt;L2正则化： &lt;span class=&#34;math display&#34;&gt;\[
J(\theta)=\frac{1}{2m}[\sum_{i=1}^{m}{h_\theta(x^{(i)}-y^{(i)})^2+\lambda\sum_{j=1}^{n}{\theta_j^2}}]
\]&lt;/span&gt; L1正则化： &lt;span class=&#34;math display&#34;&gt;\[
J(\theta)=\frac{1}{2m}[\sum_{i=1}^{m}{h_\theta(x^{(i)}-y^{(i)})^2+\lambda\sum_{j=1}^{n}{|\theta_j|}}]
\]&lt;/span&gt;&lt;/p&gt;
&lt;h1 id=&#34;岭回归ridge-regression&#34;&gt;&lt;a href=&#34;https://baike.baidu.com/link?url=J428YjCOAduEv-hDj1BM53FvjQEMC1iR9icG161YvlKwmXXmtsgGoFBvkL_VK2T40KfCjPMUpQQ8ePln0cjp50QpceYEGvvCC4iewQhwY0fGCqcS9kwQCLnbARBjd0mT&#34;&gt;岭回归（Ridge Regression）&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;由标准方程法得出， &lt;span class=&#34;math display&#34;&gt;\[
w = (𝑋^𝑇𝑋)^{-1}𝑋^𝑇y
\]&lt;/span&gt; 如果数据的特征比样本点还多，（数据特征&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;，样本个数&lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt;），如果&lt;span class=&#34;math inline&#34;&gt;\(n&amp;gt;m\)&lt;/span&gt;，&lt;span class=&#34;math inline&#34;&gt;\(𝑋^𝑇𝑋\)&lt;/span&gt;不是满秩矩阵，不可逆，计算&lt;span class=&#34;math inline&#34;&gt;\(𝑋^𝑇𝑋^{-1}\)&lt;/span&gt;时会出错。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，引入了岭回归的概念。&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;为岭系数，&lt;span class=&#34;math inline&#34;&gt;\(I\)&lt;/span&gt;为单位矩阵。 &lt;span class=&#34;math display&#34;&gt;\[
w = (𝑋^𝑇𝑋 + \lambda I)^{-1}𝑋^𝑇y
\]&lt;/span&gt; 推导： &lt;span class=&#34;math display&#34;&gt;\[
J(\theta)=\frac{1}{2}[\sum_{i=1}^{m}{h_\theta(x^{(i)}-y^{(i)})^2+\lambda\sum_{j=1}^{n}{\theta_j^2}}]
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
=\frac{1}{2}(Xw-y)^T(Xw-y)+\lambda w^Tw
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
=\frac{1}{2}(w^TX^TXw-w^TX^Ty-y^TXw+y^Ty)+\lambda w^Tw
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial J(w)}{\partial w}=X^TXw-X^Ty+\lambda w
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;令 &lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial J(w)}{\partial w}=0
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
w = (𝑋^𝑇𝑋 + \lambda I)^{-1}𝑋^𝑇y
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;示例代码-3&#34;&gt;示例代码：&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; genfromtxt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; linear_model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 读入数据 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = genfromtxt(&lt;span class=&#34;string&#34;&gt;r&amp;quot;longley.csv&amp;quot;&lt;/span&gt;,delimiter=&lt;span class=&#34;string&#34;&gt;&amp;#x27;,&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 切分数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = data[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:,&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = data[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 生成50个值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;alphas_to_test = np.linspace(&lt;span class=&#34;number&#34;&gt;0.001&lt;/span&gt;, &lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建模型，保存误差值&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = linear_model.RidgeCV(alphas=alphas_to_test, store_cv_values=&lt;span class=&#34;literal&#34;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(x_data, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 画图&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 岭系数跟loss值的关系&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(alphas_to_test, model.cv_values_.mean(axis=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 选取的岭系数值的位置&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.plot(model.alpha_, &lt;span class=&#34;built_in&#34;&gt;min&lt;/span&gt;(model.cv_values_.mean(axis=&lt;span class=&#34;number&#34;&gt;0&lt;/span&gt;)),&lt;span class=&#34;string&#34;&gt;&amp;#x27;ro&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.xlabel(&lt;span class=&#34;string&#34;&gt;&amp;#x27;alphas&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.ylabel(&lt;span class=&#34;string&#34;&gt;&amp;#x27;loss&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;plt.show()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 测试&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.predict(x_data[&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;,np.newaxis])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230605210828441.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;h1 id=&#34;lassoleast-absolute-shrinkage-and&#34;&gt;[LASSO（Least Absolute Shrinkage and&lt;/h1&gt;
&lt;p&gt;Selectionator operator）](https://baike.baidu.com/item/Lasso%E7%AE%97%E6%B3%95/22685468?fromtitle=LASSO&amp;amp;fromid=20366865&amp;amp;fr=aladdin)&lt;/p&gt;
&lt;p&gt;LASSO的代价函数： &lt;span class=&#34;math display&#34;&gt;\[
J(\theta)=\frac{1}{2m}[\sum_{i=1}^{m}{h_\theta(x^{(i)}-y^{(i)})^2+\lambda\sum_{j=1}^{n}{|\theta_j|}}]
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;示例代码-4&#34;&gt;示例代码：&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; genfromtxt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; linear_model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 读入数据 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = genfromtxt(&lt;span class=&#34;string&#34;&gt;r&amp;quot;longley.csv&amp;quot;&lt;/span&gt;,delimiter=&lt;span class=&#34;string&#34;&gt;&amp;#x27;,&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 切分数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = data[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:,&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = data[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建并拟合模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = linear_model.LassoCV()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(x_data, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# lasso系数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(model.alpha_)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 相关系数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(model.coef_)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 预测&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.predict(x_data[-&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;,np.newaxis])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h1 id=&#34;弹性网elastic-net&#34;&gt;弹性网（Elastic Net）&lt;/h1&gt;
&lt;p&gt;在&lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt;取不同值情况下的代价函数 &lt;span class=&#34;math display&#34;&gt;\[
J(\theta)=\frac{1}{2m}[\sum_{i=1}^{m}{h_\theta(x^{(i)}-y^{(i)})^2+\lambda\sum_{j=1}^{n}{|\theta_j|^q}}]
\]&lt;/span&gt; &lt;img src=&#34;/imgs/$%7Bfiilename%7D/image-20230605164458909.png&#34;  style=&#34;zoom:50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Elastic Net的代价函数： &lt;span class=&#34;math display&#34;&gt;\[
J(\theta)=\frac{1}{2m}[\sum_{i=1}^{m}{h_\theta(x^{(i)}-y^{(i)})^2+\lambda\sum_{j=1}^{n}{\alpha\theta_j^2+(1-\alpha)|\theta_j|}}]
\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;示例代码-5&#34;&gt;示例代码：&lt;/h2&gt;
&lt;figure class=&#34;highlight python&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;as&lt;/span&gt; np&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; numpy &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; genfromtxt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;keyword&#34;&gt;from&lt;/span&gt; sklearn &lt;span class=&#34;keyword&#34;&gt;import&lt;/span&gt; linear_model&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 读入数据 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;data = genfromtxt(&lt;span class=&#34;string&#34;&gt;r&amp;quot;longley.csv&amp;quot;&lt;/span&gt;,delimiter=&lt;span class=&#34;string&#34;&gt;&amp;#x27;,&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 切分数据&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;x_data = data[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:,&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;:]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;y_data = data[&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;:,&lt;span class=&#34;number&#34;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(x_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 创建并拟合模型&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model = linear_model.ElasticNetCV()&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.fit(x_data, y_data)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 弹性网系数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(model.alpha_)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 相关系数&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;built_in&#34;&gt;print&lt;/span&gt;(model.coef_)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;comment&#34;&gt;# 预测&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;model.predict(x_data[-&lt;span class=&#34;number&#34;&gt;2&lt;/span&gt;,np.newaxis])&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h1 id=&#34;参考&#34;&gt;参考&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Rt411q7WJ?p=23&amp;amp;vd_source=fe8e916be2bd597efffd8dfd95249141&#34;&gt;线性回归及其非线性回归&lt;/a&gt;&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>
