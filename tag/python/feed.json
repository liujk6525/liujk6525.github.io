{
    "version": "https://jsonfeed.org/version/1",
    "title": "你不是单打独斗 • All posts by \"python\" tag",
    "description": "",
    "home_page_url": "https://liujk6525.github.io",
    "items": [
        {
            "id": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/",
            "url": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/",
            "title": "聚类算法",
            "date_published": "2023-06-07T11:53:51.000Z",
            "content_html": "<h1 id=\"聚类cluster算法\"><a href=\"https://baike.baidu.com/item/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/1252197?fr=aladdin\">聚类（Cluster）算法</a></h1>\r\n<h2 id=\"k-means\"><a href=\"https://baike.baidu.com/item/K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/15779627?fromtitle=K-MEANS%E7%AE%97%E6%B3%95&amp;fromid=594631&amp;fr=aladdin\">K-Means</a></h2>\r\n<p>以空间中k个点为中心进行聚类，对最靠近他们的对象归类。通过迭代的方法，逐次更新各聚类中心的值，直至得到最好的聚类结果。</p>\r\n<p>同一聚类中的对象相似度较高；而不同聚类中的对象相似度较小。</p>\r\n<p>算法流程：</p>\r\n<ol type=\"1\">\r\n<li><p>先从没有标签的元素集合A中随机取k个元素，作为 k个子集各自的重心。</p></li>\r\n<li><p>分别计算剩下的元素到k个子集重心的距离（这里的距离也可以使用欧氏距离），根据距离将这些元素分别划归到最近的子集。</p></li>\r\n<li><p>根据聚类结果，重新计算重心（重心的计算方法是 计算子集中所有元素各个维度的算数平均数）。</p></li>\r\n<li><p>将集合A中全部元素按照新的重心然后再重新聚类。</p></li>\r\n<li><p>重复第4步，直到聚类结果不再发生变化。</p></li>\r\n</ol>\r\n<h2 id=\"示例代码\">示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.cluster <span class=\"keyword\">import</span> KMeans</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 忽视警告</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> warnings</span><br><span class=\"line\">warnings.filterwarnings(<span class=\"string\">&quot;ignore&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;kmeans.txt&quot;</span>, delimiter=<span class=\"string\">&quot; &quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 设置k值，这里需要手动设置K值</span></span><br><span class=\"line\">k=<span class=\"number\">4</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并训练模型</span></span><br><span class=\"line\">model = KMeans(n_clusters=k,n_init=<span class=\"string\">&#x27;auto&#x27;</span>)</span><br><span class=\"line\">model.fit(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 分类中心点坐标</span></span><br><span class=\"line\">centers = model.cluster_centers_</span><br><span class=\"line\"><span class=\"built_in\">print</span>(centers)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 预测结果</span></span><br><span class=\"line\">result = model.predict(data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(result)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画出各个数据点，用不同颜色表示分类</span></span><br><span class=\"line\">mark = [<span class=\"string\">&#x27;^r&#x27;</span>, <span class=\"string\">&#x27;vb&#x27;</span>, <span class=\"string\">&#x27;pg&#x27;</span>, <span class=\"string\">&#x27;+c&#x27;</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i,d <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data):</span><br><span class=\"line\">    plt.plot(d[<span class=\"number\">0</span>], d[<span class=\"number\">1</span>], mark[result[i]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画出各个分类的中心点</span></span><br><span class=\"line\">mark = [<span class=\"string\">&#x27;*r&#x27;</span>, <span class=\"string\">&#x27;*b&#x27;</span>, <span class=\"string\">&#x27;*g&#x27;</span>, <span class=\"string\">&#x27;*c&#x27;</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i,center <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(centers):</span><br><span class=\"line\">    plt.plot(center[<span class=\"number\">0</span>],center[<span class=\"number\">1</span>], mark[i], markersize=<span class=\"number\">20</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">x_min, x_max = data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">y_min, y_max = data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                     np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">z = model.predict(np.c_[xx.ravel(), yy.ravel()])<span class=\"comment\"># ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据</span></span><br><span class=\"line\">z = z.reshape(xx.shape)</span><br><span class=\"line\"><span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\"><span class=\"comment\"># 画出各个数据点，用不同颜色表示分类</span></span><br><span class=\"line\">mark = [<span class=\"string\">&#x27;^r&#x27;</span>, <span class=\"string\">&#x27;vb&#x27;</span>, <span class=\"string\">&#x27;pg&#x27;</span>, <span class=\"string\">&#x27;+c&#x27;</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i,d <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data):</span><br><span class=\"line\">    plt.plot(d[<span class=\"number\">0</span>], d[<span class=\"number\">1</span>], mark[result[i]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画出各个分类的中心点</span></span><br><span class=\"line\">mark = [<span class=\"string\">&#x27;*r&#x27;</span>, <span class=\"string\">&#x27;*b&#x27;</span>, <span class=\"string\">&#x27;*g&#x27;</span>, <span class=\"string\">&#x27;*c&#x27;</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i,center <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(centers):</span><br><span class=\"line\">    plt.plot(center[<span class=\"number\">0</span>],center[<span class=\"number\">1</span>], mark[i], markersize=<span class=\"number\">20</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607203700434.png\"  style=\"zoom:50%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607203924280.png\"  style=\"zoom:52%;\" /></p>\r\n<h2 id=\"mini-batch-k-means\">Mini Batch K-Means</h2>\r\n<p>采用小批量的数据子集减小计算时间。也就是随机抽取数据子集进行训练算法，结果一般只略差于标准算法。</p>\r\n<p>1：从数据集中随机抽取一些数据形成小批量，把他们分配给最近的质心</p>\r\n<p>2：更新质心，与<strong>K-Means</strong>算法相比，数据的更新是在每一个小的样本集上。</p>\r\n<h2 id=\"示例代码-1\">示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.cluster <span class=\"keyword\">import</span> MiniBatchKMeans</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"comment\"># 忽视警告</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> warnings</span><br><span class=\"line\">warnings.filterwarnings(<span class=\"string\">&quot;ignore&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;kmeans.txt&quot;</span>, delimiter=<span class=\"string\">&quot; &quot;</span>)</span><br><span class=\"line\"><span class=\"comment\"># 设置k值</span></span><br><span class=\"line\">k = <span class=\"number\">4</span>  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并训练模型</span></span><br><span class=\"line\">model = MiniBatchKMeans(n_clusters=k,n_init=<span class=\"string\">&#x27;auto&#x27;</span>)</span><br><span class=\"line\">model.fit(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 分类中心点坐标</span></span><br><span class=\"line\">centers = model.cluster_centers_</span><br><span class=\"line\"><span class=\"built_in\">print</span>(centers)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 预测结果</span></span><br><span class=\"line\">result = model.predict(data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(result)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画出各个数据点，用不同颜色表示分类</span></span><br><span class=\"line\">mark = [<span class=\"string\">&#x27;or&#x27;</span>, <span class=\"string\">&#x27;ob&#x27;</span>, <span class=\"string\">&#x27;og&#x27;</span>, <span class=\"string\">&#x27;oy&#x27;</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i,d <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data):</span><br><span class=\"line\">    plt.plot(d[<span class=\"number\">0</span>], d[<span class=\"number\">1</span>], mark[result[i]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画出各个分类的中心点</span></span><br><span class=\"line\">mark = [<span class=\"string\">&#x27;*r&#x27;</span>, <span class=\"string\">&#x27;*b&#x27;</span>, <span class=\"string\">&#x27;*g&#x27;</span>, <span class=\"string\">&#x27;*y&#x27;</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i,center <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(centers):</span><br><span class=\"line\">    plt.plot(center[<span class=\"number\">0</span>],center[<span class=\"number\">1</span>], mark[i], markersize=<span class=\"number\">20</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">x_min, x_max = data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">y_min, y_max = data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                     np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">z = model.predict(np.c_[xx.ravel(), yy.ravel()])<span class=\"comment\"># ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据</span></span><br><span class=\"line\">z = z.reshape(xx.shape)</span><br><span class=\"line\"><span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\"><span class=\"comment\"># 显示结果</span></span><br><span class=\"line\"><span class=\"comment\"># 画出各个数据点，用不同颜色表示分类</span></span><br><span class=\"line\">mark = [<span class=\"string\">&#x27;or&#x27;</span>, <span class=\"string\">&#x27;ob&#x27;</span>, <span class=\"string\">&#x27;og&#x27;</span>, <span class=\"string\">&#x27;oy&#x27;</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i,d <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data):</span><br><span class=\"line\">    plt.plot(d[<span class=\"number\">0</span>], d[<span class=\"number\">1</span>], mark[result[i]])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画出各个分类的中心点</span></span><br><span class=\"line\">mark = [<span class=\"string\">&#x27;*r&#x27;</span>, <span class=\"string\">&#x27;*b&#x27;</span>, <span class=\"string\">&#x27;*g&#x27;</span>, <span class=\"string\">&#x27;*y&#x27;</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i,center <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(centers):</span><br><span class=\"line\">    plt.plot(center[<span class=\"number\">0</span>],center[<span class=\"number\">1</span>], mark[i], markersize=<span class=\"number\">20</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607205405646.png\"  style=\"zoom:50%;\" /></p>\r\n<p>​ <img src=\"/imgs/$%7Bfiilename%7D/image-20230607204231807.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"dbscandensity-based-spatial-clustering-of-applications-with-noise\"><a href=\"https://baike.baidu.com/item/DBSCAN/4864716?fr=aladdin\">DBSCAN（Density-Based Spatial Clustering of Applications with Noise）</a></h1>\r\n<p>能够将具有足够高密度的区域划分为簇，并可在噪声的空间数据库中发现任意形状的<a href=\"https://baike.baidu.com/item/聚类/593695?fromModule=lemma_inlink\">聚类</a>。</p>\r\n<p><span class=\"math inline\">\\(\\Epsilon\\)</span>邻域：给定对象半径<span class=\"math inline\">\\(\\Epsilon\\)</span>内的区域称为该对象的<span class=\"math inline\">\\(\\Epsilon\\)</span>邻域。</p>\r\n<p>核心对象：如果给定<span class=\"math inline\">\\(\\Epsilon\\)</span>邻域内的样本点数大于等于<span class=\"math inline\">\\(Minpoints\\)</span>，则该对象为核心对象。</p>\r\n<p>直接密度可达：给定一个对象集合<span class=\"math inline\">\\(D\\)</span>，如果<span class=\"math inline\">\\(p\\)</span>在<span class=\"math inline\">\\(q\\)</span>的<span class=\"math inline\">\\(\\Epsilon\\)</span>邻域内， 且<span class=\"math inline\">\\(q\\)</span>是一个核心对象，则我们说对象<span class=\"math inline\">\\(p\\)</span>从<span class=\"math inline\">\\(q\\)</span>触发是直接密度可达的（directly density-reachable）。</p>\r\n<p>密度可达：集合<span class=\"math inline\">\\(D\\)</span>，存在一个对象链 <span class=\"math inline\">\\(p_1,p_2,\\cdots ,pn,p_1=q,p_n=p\\)</span>，<span class=\"math inline\">\\(p_{i+1}\\)</span>是从<span class=\"math inline\">\\(p_i\\)</span>关于𝜀和<span class=\"math inline\">\\(Minpoints\\)</span>直接密度可达，则称点<span class=\"math inline\">\\(p\\)</span>是从<span class=\"math inline\">\\(q\\)</span>关于<span class=\"math inline\">\\(\\Epsilon\\)</span>和<span class=\"math inline\">\\(Minpoints\\)</span>密度可达的。</p>\r\n<p>密度相连：集合<span class=\"math inline\">\\(D\\)</span>存在点<span class=\"math inline\">\\(o\\)</span>，使得点<span class=\"math inline\">\\(p、q\\)</span>是从<span class=\"math inline\">\\(o\\)</span>关于<span class=\"math inline\">\\(\\Epsilon\\)</span>和 <span class=\"math inline\">\\(Minpoints\\)</span>密度可达的，那么点<span class=\"math inline\">\\(p、q\\)</span>是关于<span class=\"math inline\">\\(\\Epsilon\\)</span>和 <span class=\"math inline\">\\(Minpoints\\)</span>密度相连的。</p>\r\n<p>算法流程：</p>\r\n<ol type=\"1\">\r\n<li><p>指定合适的<span class=\"math inline\">\\(\\Epsilon\\)</span>和 <span class=\"math inline\">\\(Minpoints\\)</span>。</p></li>\r\n<li><p>计算所有的样本点，如果点<span class=\"math inline\">\\(p\\)</span>的<span class=\"math inline\">\\(\\Epsilon\\)</span>邻域里有超过<span class=\"math inline\">\\(Minpoints\\)</span>个点，则创建一个以<span class=\"math inline\">\\(p\\)</span>为核心点的新簇。</p></li>\r\n<li><p>反复寻找这些核心点直接密度可达（之后可能是密度可达） 的点，将其加入到相应的簇，对于核心点发生“密度相连” 状况的簇，给予合并。</p></li>\r\n<li><p>没有新的点可以被添加到任何簇时，算法结束</p></li>\r\n</ol>\r\n<h2 id=\"示例代码-2\">示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.cluster <span class=\"keyword\">import</span> DBSCAN</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;kmeans.txt&quot;</span>, delimiter=<span class=\"string\">&quot; &quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">result = model.fit_predict(data)</span><br><span class=\"line\">result</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画出各个数据点，用不同颜色表示分类</span></span><br><span class=\"line\">mark = [<span class=\"string\">&#x27;or&#x27;</span>, <span class=\"string\">&#x27;ob&#x27;</span>, <span class=\"string\">&#x27;og&#x27;</span>, <span class=\"string\">&#x27;oy&#x27;</span>, <span class=\"string\">&#x27;ok&#x27;</span>, <span class=\"string\">&#x27;om&#x27;</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i,d <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(data):</span><br><span class=\"line\">    plt.plot(d[<span class=\"number\">0</span>], d[<span class=\"number\">1</span>], mark[result[i]])</span><br><span class=\"line\">    </span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607205310944.png\"  style=\"zoom:50%;\" /></p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">x1, y1 = datasets.make_circles(n_samples=<span class=\"number\">2000</span>, factor=<span class=\"number\">0.5</span>, noise=<span class=\"number\">0.05</span>)</span><br><span class=\"line\">x2, y2 = datasets.make_blobs(n_samples=<span class=\"number\">1000</span>, centers=[[<span class=\"number\">1.2</span>,<span class=\"number\">1.2</span>]], cluster_std=[[<span class=\"number\">.1</span>]])</span><br><span class=\"line\"></span><br><span class=\"line\">x = np.concatenate((x1, x2))</span><br><span class=\"line\">plt.scatter(x[:, <span class=\"number\">0</span>], x[:, <span class=\"number\">1</span>], marker=<span class=\"string\">&#x27;o&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.cluster <span class=\"keyword\">import</span> DBSCAN</span><br><span class=\"line\">y_pred = DBSCAN(eps = <span class=\"number\">0.2</span>, min_samples=<span class=\"number\">50</span>).fit_predict(x)</span><br><span class=\"line\">plt.scatter(x[:, <span class=\"number\">0</span>], x[:, <span class=\"number\">1</span>], c=y_pred)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607205925872.png\"  style=\"zoom:50%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607205903894.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://www.bilibili.com/video/BV1Rt411q7WJ?p=71&amp;vd_source=fe8e916be2bd597efffd8dfd95249141\">聚类算法</a></p>\r\n",
            "tags": [
                "Python",
                "Jupyter Notebook"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/",
            "url": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95/",
            "title": "贝叶斯算法",
            "date_published": "2023-06-07T07:56:38.000Z",
            "content_html": "<h1 id=\"贝叶斯算法\">贝叶斯算法</h1>\r\n<ul>\r\n<li>总体信息：当前总体样本符合某种分布。比如抛硬币符合二项 分布；学生的某一科的成绩符合正态分布。</li>\r\n<li>样本信息：通过抽样得到的部分样本的某种分布。</li>\r\n<li>抽样信息=总体信息+样本信息</li>\r\n<li>先验信息：抽样之前，有关推断问题中未知参数的一些信息， 通常来自于经验或历史资料。</li>\r\n</ul>\r\n<p>基于抽样信息进行统计推断的理论和方法称为经典统计学。</p>\r\n<p>基于抽样信息+先验信息进行统计推断的方法和理 论，称为贝叶斯统计学。</p>\r\n<h2 id=\"贝叶斯定理\"><a href=\"https://baike.baidu.com/item/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F/9683982?fr=aladdin\">贝叶斯定理</a></h2>\r\n<p>已知<span class=\"math inline\">\\(P(X|H)\\)</span>，要求解<span class=\"math inline\">\\(P(H|X)\\)</span> <span class=\"math display\">\\[\r\nP(H|X)=\\frac{P(X|H)P(H)}{P(X)}\r\n\\]</span></p>\r\n<h2 id=\"示例代码\">示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入算法包以及数据集</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report,confusion_matrix</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.naive_bayes <span class=\"keyword\">import</span> MultinomialNB,BernoulliNB,GaussianNB</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">x_train,x_test,y_train,y_test = train_test_split(iris.data, iris.target) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并拟合模型</span></span><br><span class=\"line\">mul_nb = GaussianNB()</span><br><span class=\"line\">mul_nb.fit(x_train,y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 评估</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(mul_nb.predict(x_test),y_test))</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607165131324.png\"  style=\"zoom: 67%;\" /></p>\r\n<h2 id=\"词袋模型bag-of-words\">词袋模型(Bag of Words)</h2>\r\n<p>Bag of words model（BoW）最早出现在自然语言处理（Natural Language Processing）和信息检索 （Information Retrieval）领域。</p>\r\n<p>该模型忽略掉文本的语法和语序等要素，将其仅仅看作是若干个词汇的集合，文档中每个单词的出现都是独立的。BoW使用一组无序的单词(words)来表达一段文字或一个文档。</p>\r\n<p>简单例子</p>\r\n<p>首先给出两个简单的文本文档如下：</p>\r\n<p>John likes to watch movies. Mary likes too.</p>\r\n<p>John also likes to watch football games.</p>\r\n<p>对于上述两个文档中出现的单词，构建如下一个词典 (dictionary)：</p>\r\n<p>{“John”: 1, “likes”: 2,“to”: 3, “watch”: 4, “movies”: 5,“also”: 6, “football”: 7, “games”: 8,“Mary”: 9, “too”: 10}</p>\r\n<p>上面的词典中包含10个单词, 每个单词有唯一的索引, 那么每个文本可以使用一个10维的向量来表示。</p>\r\n<p>[1, 2, 1, 1, 1, 0, 0, 0, 1, 1]</p>\r\n<p>[1, 1,1, 1, 0, 1, 1, 1, 0, 0]</p>\r\n<p>该向量与原来文本中单词出现的顺序没有关系，而是词典中每个单词在文本中出现的频率。</p>\r\n<h2 id=\"tf-idf\">TF-IDF</h2>\r\n<p>TF（Term Frequency） 词频</p>\r\n<p>IDF （Inverse Document Frequency）逆文档频率</p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://www.bilibili.com/video/BV1Rt411q7WJ?p=60\">贝叶斯算法</a></p>\r\n",
            "tags": [
                "Python",
                "Jupyter Notebook"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/",
            "url": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/",
            "title": "集成学习",
            "date_published": "2023-06-07T01:32:09.000Z",
            "content_html": "<h1 id=\"集成学习ensemble-learning\"><a href=\"https://baike.baidu.com/item/%E5%88%86%E7%B1%BB%E5%99%A8%E9%9B%86%E6%88%90/21512231?fromtitle=%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0&amp;fromid=3440721&amp;fr=aladdin\">集成学习（Ensemble Learning）</a></h1>\r\n<p>集成学习就是组合多个学习器，最后可以得到一个更 好的学习器。</p>\r\n<p>集成学习算法：</p>\r\n<ol type=\"1\">\r\n<li><p>个体学习器之间不存在强依赖关系，装袋（Bagging）</p></li>\r\n<li><p>随机森林（Random Forest）</p></li>\r\n<li><p>个体学习器之间存在强依赖关系，提升（Boosting）</p></li>\r\n<li><p>Stacking</p></li>\r\n</ol>\r\n<span id=\"more\"></span>\r\n<h2 id=\"bagging\">Bagging</h2>\r\n<p>Bagging也叫做Bootstrap Aggregating，是在原始 数据集选择S次后得到S个新数据集的一种技术。是一 种有放回抽样。</p>\r\n<p>原始训练数据集<span class=\"math inline\">\\(0,1,2,3,4,5,6,7,8,9\\)</span></p>\r\n<p>Bagging采样<span class=\"math inline\">\\(1,3,5,2,6,4,2,5,7,0——未采样8,9\\)</span></p>\r\n<h3 id=\"示例代码\">示例代码</h3>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入算法包以及数据集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> neighbors</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> BaggingClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">划分数据集</span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">x_data = iris.data[:,:<span class=\"number\">2</span>]</span><br><span class=\"line\">y_data = iris.target</span><br><span class=\"line\"></span><br><span class=\"line\">x_train,x_test,y_train,y_test = train_test_split(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并训练KNN模型</span></span><br><span class=\"line\">knn = neighbors.KNeighborsClassifier()</span><br><span class=\"line\">knn.fit(x_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot</span>(<span class=\"params\">model</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">    x_min, x_max = x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">    y_min, y_max = x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">    xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                         np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    z = model.predict(np.c_[xx.ravel(), yy.ravel()])<span class=\"comment\"># ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据</span></span><br><span class=\"line\">    z = z.reshape(xx.shape)</span><br><span class=\"line\">    <span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">    cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">plot(knn)</span><br><span class=\"line\"><span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&quot;knn&quot;</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\">knn.score(x_test, y_test) <span class=\"comment\"># KNN模型准确率</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并训练bagging_knn模型</span></span><br><span class=\"line\">bagging_knn = BaggingClassifier(knn, n_estimators=<span class=\"number\">100</span>)</span><br><span class=\"line\">bagging_knn.fit(x_train, y_train)</span><br><span class=\"line\">plot(bagging_knn)</span><br><span class=\"line\"><span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;bagging_knn&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\">bagging_knn.score(x_test, y_test) <span class=\"comment\"># bagging_knn模型准确率</span></span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607113057905.png\"  style=\"zoom:50%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607113349947.png\"  style=\"zoom:50%;\" /></p>\r\n<h2 id=\"随机森林random-forest\"><a href=\"https://baike.baidu.com/item/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/1974765?fr=aladdin\">随机森林（Random Forest）</a></h2>\r\n<p>算法流程：</p>\r\n<ol type=\"1\">\r\n<li><p>随机选取样本：在样本集用<strong>bagging</strong>的方式随机选择n个样本。</p></li>\r\n<li><p>随机选取特征：从所有属性d中随机选择k个属性（k&lt;d），然后从k个属性中选择最佳分割属性作为节点建立 CART决策树。</p></li>\r\n<li><p>重复以上两个步骤m次，建立m棵CART决策树。</p></li>\r\n<li><p>这m棵CART决策树形成随机森林，通过投票表决结 果，决定数据属于哪一类。</p></li>\r\n</ol>\r\n<h3 id=\"示例代码-1\">示例代码</h3>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> RandomForestClassifier <span class=\"comment\"># 集成学习中的随机森林模块</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;LR-testSet2.txt&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[:,:-<span class=\"number\">1</span>]</span><br><span class=\"line\">y_data = data[:,-<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">plt.scatter(x_data[:,<span class=\"number\">0</span>],x_data[:,<span class=\"number\">1</span>],c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 划分数据集</span></span><br><span class=\"line\">x_train,x_test,y_train,y_test = train_test_split(x_data, y_data, test_size = <span class=\"number\">0.5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot</span>(<span class=\"params\">model</span>):</span><br><span class=\"line\">    <span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">    x_min, x_max = x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">    y_min, y_max = x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">    xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                         np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    z = model.predict(np.c_[xx.ravel(), yy.ravel()])<span class=\"comment\"># ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据</span></span><br><span class=\"line\">    z = z.reshape(xx.shape)</span><br><span class=\"line\">    <span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">    cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\">    <span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">    plt.scatter(x_test[:, <span class=\"number\">0</span>], x_test[:, <span class=\"number\">1</span>], c=y_test)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并训练随机森林模型</span></span><br><span class=\"line\">RF = RandomForestClassifier(n_estimators=<span class=\"number\">50</span>)</span><br><span class=\"line\">RF.fit(x_train, y_train)</span><br><span class=\"line\">plot(RF)</span><br><span class=\"line\">RF.score(x_test, y_test)</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607114037530.png\"  style=\"zoom:50%;\" /></p>\r\n<h2 id=\"boosting\"><a href=\"https://baike.baidu.com/item/Boosting/1403912?fr=aladdin\">Boosting</a></h2>\r\n<p>AdaBoost （Adaptive Boosting）算法，它的自适应在于，前一个基本分类器被错误分类的样本的权值会增大，而正确分类的样本的权值会减小，并再次用来训练下一个基本分类器。同时，在每一轮迭代中，加入一个新的弱分类器，直到达到某个预定的足够小的错误率或达到预先指定的最大迭代次数才确定最终的强分类器。</p>\r\n<p>算法流程：</p>\r\n<ol type=\"1\">\r\n<li><p>初始化训练数据的权值分布<span class=\"math inline\">\\(D1\\)</span>。假设有<span class=\"math inline\">\\(N\\)</span>个训练样本数据，则每一个训练样本最开始时，都被赋予 相同的权值<span class=\"math inline\">\\(w~1~=1/N\\)</span>。</p></li>\r\n<li><p>训练弱分类器<span class=\"math inline\">\\(h_i\\)</span>。</p>\r\n<ul>\r\n<li><p>如果某个训练样本点，被弱分类器<span class=\"math inline\">\\(h_i\\)</span>准确地分类，那么在构造下一个训练集中，它对应的权值要减小；</p></li>\r\n<li><p>如果某个训练样本点，被弱分类器<span class=\"math inline\">\\(h_i\\)</span>错误分类，那么它的权值就应该增大。权值更新过的样本集被用于训练下一个分类器，整个训练过程如此迭代地进行下去。</p></li>\r\n</ul></li>\r\n<li><p>将各个训练得到的弱分类器组合成一个强分类器。各个弱分类器的训练过程结束后，</p>\r\n<ul>\r\n<li>加大分类误差率小的弱分类器的权重，使其在最终的分类函数中起着较大的决定作用，</li>\r\n<li>降低分类误差率大的弱分类器的权重，使其在最终的分类函数中起着较小的决定作用。</li>\r\n</ul></li>\r\n</ol>\r\n<h3 id=\"示例代码-2\">示例代码</h3>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.ensemble <span class=\"keyword\">import</span> AdaBoostClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_gaussian_quantiles</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成2维正态分布，生成的数据按分位数分为两类，500个样本,2个样本特征</span></span><br><span class=\"line\">x1, y1 = make_gaussian_quantiles(n_samples=<span class=\"number\">500</span>, n_features=<span class=\"number\">2</span>,n_classes=<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"comment\"># 生成2维正态分布，生成的数据按分位数分为两类，400个样本,2个样本特征均值都为3</span></span><br><span class=\"line\">x2, y2 = make_gaussian_quantiles(mean=(<span class=\"number\">3</span>, <span class=\"number\">3</span>), n_samples=<span class=\"number\">500</span>, n_features=<span class=\"number\">2</span>, n_classes=<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"comment\"># 将两组数据合成一组数据</span></span><br><span class=\"line\">x_data = np.concatenate((x1, x2))</span><br><span class=\"line\">y_data = np.concatenate((y1, - y2 + <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># AdaBoost模型</span></span><br><span class=\"line\">model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=<span class=\"number\">3</span>),n_estimators=<span class=\"number\">10</span>)</span><br><span class=\"line\"><span class=\"comment\"># 训练模型</span></span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">x_min, x_max = x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">y_min, y_max = x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                     np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取预测值</span></span><br><span class=\"line\">z = model.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class=\"line\">z = z.reshape(xx.shape)</span><br><span class=\"line\"><span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\"><span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 模型准确率</span></span><br><span class=\"line\">model.score(x_data,y_data)</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607153300730.png\"  style=\"zoom:50%;\" /></p>\r\n<h2 id=\"stacking\">Stacking</h2>\r\n<p>使用多个不同的分类器对训练集进预测，把预测 得到的结果作为一个次级分类器的输入。次级分 类器的输出是整个模型的预测结果。</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607153502918.png\"  style=\"zoom:67%;\" /></p>\r\n<h3 id=\"示例代码-3\">示例代码</h3>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets  </span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> model_selection  </span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LogisticRegression</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier  </span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.tree <span class=\"keyword\">import</span> DecisionTreeClassifier</span><br><span class=\"line\"><span class=\"keyword\">from</span> mlxtend.classifier <span class=\"keyword\">import</span> StackingClassifier</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据集</span></span><br><span class=\"line\">iris = datasets.load_iris()  </span><br><span class=\"line\"><span class=\"comment\"># 只要第1,2列的特征</span></span><br><span class=\"line\">x_data, y_data = iris.data[:, <span class=\"number\">1</span>:<span class=\"number\">3</span>], iris.target  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义三个不同的分类器</span></span><br><span class=\"line\">clf1 = KNeighborsClassifier(n_neighbors=<span class=\"number\">1</span>)  </span><br><span class=\"line\">clf2 = DecisionTreeClassifier() </span><br><span class=\"line\">clf3 = LogisticRegression()  </span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\"># 定义一个次级分类器</span></span><br><span class=\"line\">lr = LogisticRegression()  </span><br><span class=\"line\">sclf = StackingClassifier(classifiers=[clf1, clf2, clf3],   </span><br><span class=\"line\">                          meta_classifier=lr)</span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"keyword\">for</span> clf,label <span class=\"keyword\">in</span> <span class=\"built_in\">zip</span>([clf1, clf2, clf3, sclf],</span><br><span class=\"line\">                      [<span class=\"string\">&#x27;KNN&#x27;</span>,<span class=\"string\">&#x27;Decision Tree&#x27;</span>,<span class=\"string\">&#x27;LogisticRegression&#x27;</span>,<span class=\"string\">&#x27;StackingClassifier&#x27;</span>]):  </span><br><span class=\"line\">    scores = model_selection.cross_val_score(clf, x_data, y_data, cv=<span class=\"number\">3</span>, scoring=<span class=\"string\">&#x27;accuracy&#x27;</span>)  </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Accuracy: %0.2f [%s]&quot;</span> % (scores.mean(), label)) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可视化   </span></span><br><span class=\"line\">sclf.fit(x_train,y_train)</span><br><span class=\"line\">plot(sclf)</span><br><span class=\"line\">plt.scatter(x_data[:,<span class=\"number\">0</span>],x_data[:,<span class=\"number\">1</span>],c=y_data)    </span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607155449811.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://www.bilibili.com/video/BV1Rt411q7WJ/?p=55&amp;spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=fe8e916be2bd597efffd8dfd95249141\">集成学习</a></p>\r\n",
            "tags": [
                "Python",
                "Jupyter Notebook"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/",
            "url": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/",
            "title": "决策树",
            "date_published": "2023-06-06T12:25:49.000Z",
            "content_html": "<h1 id=\"决策树-decision-tree\"><a href=\"https://baike.baidu.com/item/%E5%86%B3%E7%AD%96%E6%A0%91/10377049?fr=aladdin\">决策树 （Decision Tree）</a></h1>\r\n<p>比较适合分析离散数据。 如果是连续数据要先转成离散数据再做分析</p>\r\n<h2 id=\"熵entropy\">熵（entropy）</h2>\r\n<p>1948年，香浓提出了“<a href=\"https://baike.baidu.com/item/%E4%BF%A1%E6%81%AF%E7%86%B5/7302318?fr=aladdin\">信息熵</a>”的概念，</p>\r\n<p><strong>一条信息的信息量大小和它的不确定性有直接的关系， 要搞清楚一件非常非常不确定的事情，或者是一无所知的事情，需要了解大量信息。—&gt;信息量的度量就等于不确定性的多少。</strong></p>\r\n<span id=\"more\"></span>\r\n<p>信息熵公式： <span class=\"math display\">\\[\r\nH[x]=-\\sum_{x}p(x)logp(x)\r\n\\]</span></p>\r\n<h2 id=\"id3算法\"><a href=\"https://baike.baidu.com/item/ID3%E7%AE%97%E6%B3%95/5522381?fr=aladdin\">ID3算法</a></h2>\r\n<p>决策树会选择最大化信息增益来对结点进行划分。</p>\r\n<p>信息增益（Information Gain）计算： <span class=\"math display\">\\[\r\nInfo(D)=-\\sum_{i=1}^{m}p_ilog(p_i)\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nInfo_A(D)=-\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}\\times Info(D_j)\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nGain(A)=Info(D)-Info_A(D)\r\n\\]</span></p>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>RID</th>\r\n<th>age</th>\r\n<th>income</th>\r\n<th>student</th>\r\n<th>credit_rating</th>\r\n<th>class_buys_computer</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td>1</td>\r\n<td>youth</td>\r\n<td>high</td>\r\n<td>no</td>\r\n<td>fair</td>\r\n<td>no</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>2</td>\r\n<td>youth</td>\r\n<td>high</td>\r\n<td>no</td>\r\n<td>excellent</td>\r\n<td>no</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>3</td>\r\n<td>middle_aged</td>\r\n<td>high</td>\r\n<td>no</td>\r\n<td>fair</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>4</td>\r\n<td>senior</td>\r\n<td>medium</td>\r\n<td>no</td>\r\n<td>fair</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>5</td>\r\n<td>senior</td>\r\n<td>low</td>\r\n<td>yes</td>\r\n<td>fair</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>6</td>\r\n<td>senior</td>\r\n<td>low</td>\r\n<td>yes</td>\r\n<td>excellent</td>\r\n<td>no</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>7</td>\r\n<td>middle_aged</td>\r\n<td>low</td>\r\n<td>yes</td>\r\n<td>excellent</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>8</td>\r\n<td>youth</td>\r\n<td>medium</td>\r\n<td>no</td>\r\n<td>fair</td>\r\n<td>no</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>9</td>\r\n<td>youth</td>\r\n<td>low</td>\r\n<td>yes</td>\r\n<td>fair</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>10</td>\r\n<td>senior</td>\r\n<td>medium</td>\r\n<td>yes</td>\r\n<td>fair</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>11</td>\r\n<td>youth</td>\r\n<td>medium</td>\r\n<td>yes</td>\r\n<td>excellent</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>12</td>\r\n<td>middle_aged</td>\r\n<td>medium</td>\r\n<td>no</td>\r\n<td>excellent</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>13</td>\r\n<td>middle_aged</td>\r\n<td>high</td>\r\n<td>yes</td>\r\n<td>fair</td>\r\n<td>yes</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>14</td>\r\n<td>senior</td>\r\n<td>medium</td>\r\n<td>no</td>\r\n<td>excellent</td>\r\n<td>no</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<p>计算<strong>age</strong>的信息增益: <span class=\"math display\">\\[\r\nInfo(D)=-\\frac{9}{14}log_2(\\frac{9}{14})-\\frac{5}{14}log_2(\\frac{5}{14})=0.94\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nInfo_{age}(D)=\\frac{5}{14}(-\\frac{2}{5}log_2\\frac{2}{5}-\\frac{3}{5}log_2\\frac{3}{5})+\r\n\\frac{4}{14}(-\\frac{4}{4}log_2\\frac{4}{4}-\\frac{0}{4}log_2\\frac{0}{4})+\r\n\\frac{5}{14}(-\\frac{3}{5}log_2\\frac{3}{5}-\\frac{2}{5}log_2\\frac{2}{5})\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nGain(age)=Info(D)-Info_A(D)=0.94-0.694=0.246\r\n\\]</span></p>\r\n<p>其他的也是类似计算。</p>\r\n<h2 id=\"c4.5算法\"><a href=\"https://baike.baidu.com/item/C4.5%E7%AE%97%E6%B3%95/20814636\">C4.5算法</a></h2>\r\n<p>信息增益的方法倾向于首先选择因子数较多的变量 。</p>\r\n<p>信息增益的改进：增益率 <span class=\"math display\">\\[\r\nSplitInfo_A(D)=-\\sum_{j=1}^{v}\\frac{|D_j|}{|D|}\\times log_2(\\frac{|D_j|}{|D|})\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nGainRatio(A)=\\frac{Gain(A)}{SpliInfo_A(D)}\r\n\\]</span></p>\r\n<h2 id=\"cart算法\"><a href=\"https://baike.baidu.com/item/CART/17679070\">CART算法</a></h2>\r\n<p>CART决策树的生成就是递归地构建二叉决策树的过程。</p>\r\n<p>CART用基尼（Gini）系数最小化准则来进行特征选择，生成二叉树。</p>\r\n<p>Gini系数计算： <span class=\"math display\">\\[\r\nGini(D)=1-\\sum_{i=1}^{m}p_i^2\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nGini_A(D)=\\frac{|D_1|}{|D|}Gini(D_1)+\\frac{|D_2|}{|D|}Gini(D_2)\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\Delta Gini(A)=Gini(D)-Gini_A(D)\r\n\\]</span></p>\r\n<p>优点：小规模数据集有效</p>\r\n<p>缺点： 处理连续变量不好 类别较多时，错误增加的比较快 不能处理大量数据</p>\r\n<h2 id=\"线性二分类示例代码\">线性二分类示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree <span class=\"comment\"># 决策树模块</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;LR-testSet.csv&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[:,:-<span class=\"number\">1</span>]</span><br><span class=\"line\">y_data = data[:,-<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">plt.scatter(x_data[:,<span class=\"number\">0</span>],x_data[:,<span class=\"number\">1</span>],c=y_data) </span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建决策树模型</span></span><br><span class=\"line\">model = tree.DecisionTreeClassifier()</span><br><span class=\"line\"><span class=\"comment\"># 输入数据建立模型</span></span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">x_min, x_max = x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">y_min, y_max = x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                     np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">z = model.predict(np.c_[xx.ravel(), yy.ravel()])<span class=\"comment\"># ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据</span></span><br><span class=\"line\">z = z.reshape(xx.shape)</span><br><span class=\"line\"><span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\"><span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试与评估</span></span><br><span class=\"line\">predictions = model.predict(x_data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(predictions,y_data))</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607084609741.png\"  style=\"zoom:50%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230606214438933.png\"  style=\"zoom:67%;\" /></p>\r\n<h2 id=\"非线性二分类示例代码\">非线性二分类示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;LR-testSet2.txt&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[:,:-<span class=\"number\">1</span>]</span><br><span class=\"line\">y_data = data[:,-<span class=\"number\">1</span>]</span><br><span class=\"line\">    </span><br><span class=\"line\">plt.scatter(x_data[:,<span class=\"number\">0</span>],x_data[:,<span class=\"number\">1</span>],c=y_data) <span class=\"comment\"># s散点图</span></span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#分割数据</span></span><br><span class=\"line\">x_train,x_test,y_train,y_test = train_test_split(x_data, y_data) </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建决策树模型</span></span><br><span class=\"line\"><span class=\"comment\"># max_depth，树的深度</span></span><br><span class=\"line\"><span class=\"comment\"># min_samples_split 内部节点再划分所需最小样本数</span></span><br><span class=\"line\">model = tree.DecisionTreeClassifier(max_depth=<span class=\"number\">7</span>,min_samples_split=<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"comment\"># 拟合模型</span></span><br><span class=\"line\">model.fit(x_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">x_min, x_max = x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">y_min, y_max = x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                     np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">z = model.predict(np.c_[xx.ravel(), yy.ravel()])<span class=\"comment\"># ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据</span></span><br><span class=\"line\">z = z.reshape(xx.shape)</span><br><span class=\"line\"><span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\"><span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试并评估</span></span><br><span class=\"line\">predictions = model.predict(x_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(predictions,y_test))</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607084429752.png\"  style=\"zoom: 50%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607084526669.png\"  style=\"zoom:67%;\" /></p>\r\n<h2 id=\"回归树示例代码\">回归树示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> tree</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;data.csv&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[:,<span class=\"number\">0</span>,np.newaxis]</span><br><span class=\"line\">y_data = data[:,<span class=\"number\">1</span>,np.newaxis]</span><br><span class=\"line\">plt.scatter(x_data,y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\">model = tree.DecisionTreeRegressor(max_depth=<span class=\"number\">5</span>)</span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\">x_test = np.linspace(<span class=\"number\">20</span>,<span class=\"number\">80</span>,<span class=\"number\">100</span>)</span><br><span class=\"line\">x_test = x_test[:,np.newaxis]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">plt.plot(x_data, y_data, <span class=\"string\">&#x27;b&#x27;</span>)</span><br><span class=\"line\">plt.plot(x_test, model.predict(x_test), <span class=\"string\">&#x27;r&#x27;</span>) </span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230607090010220.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://www.bilibili.com/video/BV1Rt411q7WJ?p=50&amp;vd_source=fe8e916be2bd597efffd8dfd95249141\">决策树</a></p>\r\n",
            "tags": [
                "Python",
                "Jupyter Notebook"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95/",
            "url": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/KNN%E7%AE%97%E6%B3%95/",
            "title": "KNN算法",
            "date_published": "2023-06-06T12:05:23.000Z",
            "content_html": "<h1 id=\"k最近邻k-nearest-neighborknn分类算法\"><a href=\"https://baike.baidu.com/item/k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/9512781?fr=aladdin\">K最近邻（K-Nearest Neighbor，KNN）</a>分类算法</h1>\r\n<ol type=\"1\">\r\n<li>为了判断未知实例的类别，以所有已知类别的实例作为 参照选择参数K</li>\r\n<li>计算未知实例与所有已知实例的距离</li>\r\n<li>选择最近K个已知实例</li>\r\n<li>根据少数服从多数的投票法则(majority-voting)，让 未知实例归类为K个最邻近样本中最多数的类别</li>\r\n</ol>\r\n<span id=\"more\"></span>\r\n<p>欧氏距离 <span class=\"math display\">\\[\r\nE(x,y)=\\sqrt{\\sum_{i=0}^{n}(x_i-y_i)^2}\r\n\\]</span> <a href=\"https://www.cnblogs.com/belfuture/p/5871452.html\">其他的距离衡量</a>：余弦值距离（cos），相关度（correlation），曼哈顿距离（Manhattan distance）</p>\r\n<p>算法缺点：</p>\r\n<ul>\r\n<li>算法复杂度较高（需要比较所有已知实例与要分类的实例）</li>\r\n<li>当其样本分布不平衡时，比如其中一类样本过大（实例数量过多）占主导的时候，新的未知实例容易被归类为这个主导样本，因为这类样本实例的数量过大，但这个新的未知实例实际并没有接近目标样本</li>\r\n</ul>\r\n<h2 id=\"示例代码\">示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 导入算法包以及数据集</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> neighbors</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.model_selection <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(iris)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 打乱数据切分数据集</span></span><br><span class=\"line\"><span class=\"comment\"># x_train,x_test,y_train,y_test = train_test_split(iris.data, iris.target, test_size=0.2) #分割数据0.2为测试数据，0.8为训练数据</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#打乱数据</span></span><br><span class=\"line\">data_size = iris.data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">index = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(data_size)] </span><br><span class=\"line\">random.shuffle(index)  </span><br><span class=\"line\">iris.data = iris.data[index]</span><br><span class=\"line\">iris.target = iris.target[index]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#切分数据集</span></span><br><span class=\"line\">test_size = <span class=\"number\">40</span></span><br><span class=\"line\">x_train = iris.data[test_size:]</span><br><span class=\"line\">x_test =  iris.data[:test_size]</span><br><span class=\"line\">y_train = iris.target[test_size:]</span><br><span class=\"line\">y_test = iris.target[:test_size]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 构建模型</span></span><br><span class=\"line\">model = neighbors.KNeighborsClassifier(n_neighbors=<span class=\"number\">3</span>)</span><br><span class=\"line\">model.fit(x_train, y_train)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试和评估</span></span><br><span class=\"line\">prediction = model.predict(x_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(y_test, prediction))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230606202144425.png\"  style=\"zoom: 67%;\" /></p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://www.bilibili.com/video/BV1Rt411q7WJ?p=41&amp;vd_source=fe8e916be2bd597efffd8dfd95249141\">KNN算法</a></p>\r\n",
            "tags": [
                "Python",
                "Jupyter Notebook"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/",
            "url": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/",
            "title": "逻辑回归",
            "date_published": "2023-06-05T13:32:23.000Z",
            "content_html": "<h1 id=\"逻辑回归logistic-regression\"><a href=\"https://baike.baidu.com/item/logistic%E5%9B%9E%E5%BD%92/2981575?fromtitle=%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92&amp;fromid=17202449&amp;fr=aladdin\">逻辑回归（Logistic Regression）</a></h1>\r\n<p>是一种广义的线性回归分析模型，与多重线性回归有很多相同之处。它们的模型形式基本上相同，都具有$ w’x+b$，其区别在于他们的因变量不同，</p>\r\n<ul>\r\n<li>多重线性回归直接将<span class=\"math inline\">\\(w&#39;x+b\\)</span>作为因变量，</li>\r\n<li>Logistic回归则通过函数L将<span class=\"math inline\">\\(w&#39;x+b\\)</span>对应一个隐状态<span class=\"math inline\">\\(p\\)</span>，<span class=\"math inline\">\\(p =L(w&#39;x+b)\\)</span>，然后根据<span class=\"math inline\">\\(p\\)</span>与<span class=\"math inline\">\\(1-p\\)</span>的大小决定因变量的值。</li>\r\n</ul>\r\n<p>如果L是Logistic函数，就是Logistic回归，</p>\r\n<p>如果L是多项式函数就是多项式回归。</p>\r\n<span id=\"more\"></span>\r\n<h2 id=\"logistic-function\">Logistic Function</h2>\r\n<p>定义逻辑回归的预测函数为<span class=\"math inline\">\\(ℎ_\\theta(x) = 𝑔(\\theta^𝑇𝑥)\\)</span> ，其中g(x)函数是sigmoid函数。 <span class=\"math display\">\\[\r\ng(x)=\\frac{1}{1+e^{-x}}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nh_\\theta(x)=\\frac{1}{1+e^{-\\theta^Tx}}\r\n\\]</span></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230606093600860.png\"  style=\"zoom:50%;\" /></p>\r\n<ol type=\"1\">\r\n<li>当<span class=\"math inline\">\\(\\theta^Tx≥0\\)</span>，<span class=\"math inline\">\\(g(\\theta^Tx)≥0.5\\)</span></li>\r\n<li>当<span class=\"math inline\">\\(\\theta^Tx≤0\\)</span>，<span class=\"math inline\">\\(g(\\theta^Tx)≤0.5\\)</span></li>\r\n</ol>\r\n<h2 id=\"逻辑回归的代价函数cost-function\">逻辑回归的代价函数（Cost Function）</h2>\r\n<p><span class=\"math display\">\\[\r\nCost(h_\\theta(x),y)= \r\n\\begin{cases}\r\n-log(h_\\theta(x))\\quad\\quad\\quad if\\quad y=1\\\\\r\n-log(1-h_\\theta(x))\\quad if\\quad y=0\r\n\\end{cases}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n=-ylog(h_\\theta(x))-(1-y)log(1-h_\\theta(x))\r\n\\]</span></p>\r\n<h2 id=\"梯度下降法gradient-descent\">梯度下降法（Gradient Descent）</h2>\r\n<p><span class=\"math display\">\\[\r\nJ(\\theta)=-\\frac{1}{m}[\\sum_{i=1}^{m}y^{(i)}logh_\\theta(x^{(i)})+(1-y^{(i)})log(1-h_\\theta(x^{(i)}))]\r\n\\]</span></p>\r\n<p>求解 <span class=\"math inline\">\\(min_\\theta J(\\theta)\\)</span> <span class=\"math display\">\\[\r\n\\theta_j:=\\theta_j-\\alpha\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}\r\n\\]</span></p>\r\n<h2 id=\"准确率精准率召回率f1分数\">准确率|精准率|召回率|F<sub>1</sub>分数</h2>\r\n<p>混淆矩阵</p>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th></th>\r\n<th></th>\r\n<th>实际</th>\r\n<th>实际</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td></td>\r\n<td></td>\r\n<td>1</td>\r\n<td>0</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td>预测</td>\r\n<td>1</td>\r\n<td>TP</td>\r\n<td>FP</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td>预测</td>\r\n<td>0</td>\r\n<td>FN</td>\r\n<td>TN</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<ul>\r\n<li>P（Positive）：代表1</li>\r\n<li>N（Negative）：代表0</li>\r\n<li>T（True）：代表预测正确</li>\r\n<li>F（False）：代表预测错误</li>\r\n</ul>\r\n<p><strong>准确率：</strong>即预测正确的结果占总样本的百分比 <span class=\"math display\">\\[\r\n准确率=\\frac{TP+TN}{TP+TN+FP+FN}\r\n\\]</span> <strong>精准率（Precision）：</strong>是指在所有被预测为正的样本中实际为正的样本的概率。 <span class=\"math display\">\\[\r\n精准率=\\frac{TP}{TP+FP}\r\n\\]</span> <strong>精准率就是你认为找的是对的实际上多少是对的</strong></p>\r\n<p><strong>召回率（Recall）：</strong>是指在实际为正的样本中被预测为正样本的概率。 <span class=\"math display\">\\[\r\n召回率=\\frac{TP}{TP+FN}\r\n\\]</span> <strong>F<sub>1</sub>分数：</strong>精准率和召回率之间的一个平衡点。 <span class=\"math display\">\\[\r\nF_1=\\frac{2\\times Precision\\times Recall}{Precision+Recall}\r\n\\]</span></p>\r\n<h2 id=\"逻辑回归示例代码\">逻辑回归示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.metrics <span class=\"keyword\">import</span> classification_report</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> preprocessing</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"><span class=\"comment\"># 数据是否需要标准化</span></span><br><span class=\"line\">scale = <span class=\"literal\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;LR-testSet.csv&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[:,:-<span class=\"number\">1</span>]</span><br><span class=\"line\">y_data = data[:,-<span class=\"number\">1</span>]</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">plot</span>():</span><br><span class=\"line\">    x0 = []</span><br><span class=\"line\">    x1 = []</span><br><span class=\"line\">    y0 = []</span><br><span class=\"line\">    y1 = []</span><br><span class=\"line\">    <span class=\"comment\"># 切分不同类别的数据</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(x_data)):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> y_data[i]==<span class=\"number\">0</span>:</span><br><span class=\"line\">            x0.append(x_data[i,<span class=\"number\">0</span>])</span><br><span class=\"line\">            y0.append(x_data[i,<span class=\"number\">1</span>])</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            x1.append(x_data[i,<span class=\"number\">0</span>])</span><br><span class=\"line\">            y1.append(x_data[i,<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 画图</span></span><br><span class=\"line\">   scatter0 = plt.scatter(x0, y0, c=<span class=\"string\">&#x27;c&#x27;</span>, marker=<span class=\"string\">&#x27;+&#x27;</span>)</span><br><span class=\"line\">    scatter1 = plt.scatter(x1, y1, c=<span class=\"string\">&#x27;y&#x27;</span>, marker=<span class=\"string\">&#x27;*&#x27;</span>)</span><br><span class=\"line\">    <span class=\"comment\">#画图例</span></span><br><span class=\"line\">    plt.legend(handles=[scatter0,scatter1],labels=[<span class=\"string\">&#x27;label0&#x27;</span>,<span class=\"string\">&#x27;label1&#x27;</span>],loc=<span class=\"string\">&#x27;best&#x27;</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">plot()</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并拟合模型</span></span><br><span class=\"line\">logistic = linear_model.LogisticRegression()</span><br><span class=\"line\">logistic.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> scale == <span class=\"literal\">False</span>:</span><br><span class=\"line\">    <span class=\"comment\"># 画图决策边界</span></span><br><span class=\"line\">    plot()</span><br><span class=\"line\">    x_test = np.array([[-<span class=\"number\">4</span>],[<span class=\"number\">3</span>]])</span><br><span class=\"line\">    y_test = (-logistic.intercept_ - x_test*logistic.coef_[<span class=\"number\">0</span>][<span class=\"number\">0</span>])/logistic.coef_[<span class=\"number\">0</span>][<span class=\"number\">1</span>]</span><br><span class=\"line\">    plt.plot(x_test, y_test, <span class=\"string\">&#x27;k&#x27;</span>)</span><br><span class=\"line\">    plt.show()</span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># 测试与评估    </span></span><br><span class=\"line\">predictions = logistic.predict(x_data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(classification_report(y_data, predictions))</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230606164354040.png\"  style=\"zoom:50%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230606164557574.png\"  style=\"zoom: 67%;\" /></p>\r\n<h2 id=\"非线性逻辑回归示例代码\">非线性逻辑回归示例代码</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.datasets <span class=\"keyword\">import</span> make_gaussian_quantiles</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> PolynomialFeatures</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成2维正态分布，生成的数据按分位数分为两类，500个样本,2个样本特征</span></span><br><span class=\"line\"><span class=\"comment\"># 可以生成两类或多类数据</span></span><br><span class=\"line\">x_data, y_data = make_gaussian_quantiles(n_samples=<span class=\"number\">500</span>, n_features=<span class=\"number\">2</span>,n_classes=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并拟合模型</span></span><br><span class=\"line\">logistic = linear_model.LogisticRegression()</span><br><span class=\"line\">logistic.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义多项式回归,degree的值可以调节多项式的特征</span></span><br><span class=\"line\">poly_reg  = PolynomialFeatures(degree=<span class=\"number\">5</span>) </span><br><span class=\"line\"><span class=\"comment\"># 特征处理</span></span><br><span class=\"line\">x_poly = poly_reg.fit_transform(x_data)</span><br><span class=\"line\"><span class=\"comment\"># 定义逻辑回归模型</span></span><br><span class=\"line\">logistic = linear_model.LogisticRegression()</span><br><span class=\"line\"><span class=\"comment\"># 训练模型</span></span><br><span class=\"line\">logistic.fit(x_poly, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 获取数据值所在的范围</span></span><br><span class=\"line\">x_min, x_max = x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">0</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\">y_min, y_max = x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">min</span>() - <span class=\"number\">1</span>, x_data[:, <span class=\"number\">1</span>].<span class=\"built_in\">max</span>() + <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">xx, yy = np.meshgrid(np.arange(x_min, x_max, <span class=\"number\">0.02</span>),</span><br><span class=\"line\">                     np.arange(y_min, y_max, <span class=\"number\">0.02</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">z = logistic.predict(poly_reg.fit_transform(np.c_[xx.ravel(), yy.ravel()]))<span class=\"comment\"># ravel与flatten类似，多维数据转一维。flatten不会改变原始数据，ravel会改变原始数据</span></span><br><span class=\"line\">z = z.reshape(xx.shape)</span><br><span class=\"line\"><span class=\"comment\"># 等高线图</span></span><br><span class=\"line\">cs = plt.contourf(xx, yy, z)</span><br><span class=\"line\"><span class=\"comment\"># 样本散点图</span></span><br><span class=\"line\">plt.scatter(x_data[:, <span class=\"number\">0</span>], x_data[:, <span class=\"number\">1</span>], c=y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;score:&#x27;</span>,logistic.score(x_poly,y_data))</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230606165631817.png\"  style=\"zoom:67%;\" /></p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://www.bilibili.com/video/BV1Rt411q7WJ?p=29\">逻辑回归</a></p>\r\n",
            "tags": [
                "Python",
                "Jupyter Notebook"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%8F%8A%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/",
            "url": "https://liujk6525.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%8F%8A%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/",
            "title": "线性回归及非线性回归",
            "date_published": "2023-06-05T01:37:27.000Z",
            "content_html": "<h1 id=\"基本概念\">基本概念：</h1>\r\n<p>将数据划分为三部分：<span class=\"math inline\">\\(\\begin{cases} 训练集(Train):用来训练，构建模型\\\\ 验证集(Validate):在模型训练阶段，测试模型的好坏\\\\ 测试集(Test):等模型训练好后，评估模型的好坏 \\end{cases}\\)</span></p>\r\n<span id=\"more\"></span>\r\n<p>学习方式：<span class=\"math inline\">\\(\\begin{cases} 监督学习\\\\ 无监督学习\\\\ 半监督学习 \\end{cases}\\)</span></p>\r\n<p>常见应用：<span class=\"math inline\">\\(\\begin{cases} 回归：预测数据为连续型数值。\\\\ 分类：预测数据为类别型数据，并且类别已知。\\\\ 聚类：预测数据为类别型数据，但是类别未知。 \\end{cases}\\)</span></p>\r\n<h1 id=\"回归分析regression\"><a href=\"https://baike.baidu.com/item/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/2625498?fr=aladdin\">回归分析（Regression）</a></h1>\r\n<p>回归分析用来建立方程，模拟两个或者多个变量之间如何关联，</p>\r\n<ul>\r\n<li>被预测的变量叫做：因变量/输出</li>\r\n<li>被用来进行预测的变量叫做： 自变量,/输入</li>\r\n</ul>\r\n<p>一元线性回归包含一个自变量和一个因变量，两个变量的关系用一条直线来模拟，如果包含两个以上的自变量，则称作多元回归分析（multiple regression）</p>\r\n<h1 id=\"一元线性回归\"><a href=\"https://baike.baidu.com/item/%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/22770888?fr=aladdin\">一元线性回归</a></h1>\r\n<p>一元线性回归：<span class=\"math inline\">\\(h_\\theta(x)=\\theta_0+\\theta_1x\\)</span></p>\r\n<h2 id=\"代价函数cost-function\"><a href=\"https://baike.baidu.com/item/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/1783236?fromtitle=%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0&amp;fromid=7048599&amp;fr=aladdin\">代价函数（Cost Function）</a></h2>\r\n<p><strong>最小二乘法</strong></p>\r\n<p>假设真实值为<span class=\"math inline\">\\(y\\)</span>，预测值<span class=\"math inline\">\\(h_\\theta(x)\\)</span> ，则误差平方为<span class=\"math inline\">\\((h_\\theta(x)-y)^2\\)</span></p>\r\n<p>找到合适的参数，使得误差平方和<span class=\"math inline\">\\(J(\\theta_0,\\theta_1)\\)</span>最小。 <span class=\"math display\">\\[\r\nJ(\\theta_0,\\theta_1)=\\frac{1}{2m}\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})^{2}}\r\n\\]</span></p>\r\n<h2 id=\"梯度下降法gradient-descent\"><a href=\"https://baike.baidu.com/item/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/8641233?fr=aladdin\">梯度下降法（Gradient Descent）</a></h2>\r\n<p><strong>最小化目标函数</strong> <span class=\"math inline\">\\(\\underset{\\theta_0,\\theta_1}{min}\\quad J(\\theta_0,\\theta_1)\\)</span></p>\r\n<p>初始化参数<span class=\"math inline\">\\(\\theta_0,\\theta_1\\)</span></p>\r\n<p>不断改变<span class=\"math inline\">\\(\\theta_0,\\theta_1\\)</span> ，直到<span class=\"math inline\">\\(J(\\theta_0,\\theta_1)\\)</span>到达一个全局最小值，或局部极小值。 <span class=\"math display\">\\[\r\n\\theta_j:=\\theta_j-\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta_0,\\theta_1)\\quad (j=0,1,2\\cdots)\r\n\\]</span></p>\r\n<h2 id=\"用梯度下降法求解线性回归\">用梯度下降法求解线性回归</h2>\r\n<p><span class=\"math display\">\\[\r\n\\frac{\\partial}{\\partial\\theta_0}J(\\theta_0,\\theta_1)=\r\n\\frac{1}{m}\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}\r\n\\\\\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\frac{\\partial}{\\partial\\theta_1}J(\\theta_0,\\theta_1)=\r\n\\frac{1}{m}\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}\\times x^{(i)}\r\n\\]</span></p>\r\n<p>不断迭代，直到收敛： <span class=\"math display\">\\[\r\n\\theta_0:=\\theta_0-\\alpha\\frac{1}{m}{\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\theta_1:=\\theta_1-\\alpha\\frac{1}{m}{\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}}\\times x^{(i)}\r\n\\]</span></p>\r\n<h2 id=\"示例代码\">示例代码：</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LinearRegression <span class=\"comment\"># 线性回归模型</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;data.csv&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[:,<span class=\"number\">0</span>]</span><br><span class=\"line\">y_data = data[:,<span class=\"number\">1</span>]</span><br><span class=\"line\">plt.scatter(x_data,y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\">x_data = data[:,<span class=\"number\">0</span>,np.newaxis]</span><br><span class=\"line\">y_data = data[:,<span class=\"number\">1</span>,np.newaxis]</span><br><span class=\"line\"><span class=\"comment\"># 创建并拟合模型</span></span><br><span class=\"line\">model = LinearRegression() <span class=\"comment\"># 线性回归</span></span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试</span></span><br><span class=\"line\">x_test = [[<span class=\"number\">44.5</span>]]</span><br><span class=\"line\">predict = model.predict(x_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&#x27;predict&#x27;</span>,predict)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">plt.plot(x_data, y_data, <span class=\"string\">&#x27;b.&#x27;</span>)</span><br><span class=\"line\">plt.plot(x_data, model.predict(x_data), <span class=\"string\">&#x27;r&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230605203607162.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"多元线性回归multiple-linear-regression\"><a href=\"https://baike.baidu.com/item/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/10702248?fr=aladdin\">多元线性回归（Multiple Linear Regression）</a></h1>\r\n<p>多特征时，假设：<span class=\"math inline\">\\(h_\\theta(x)=\\theta_0+\\theta_1x_1+\\theta_2x_2+\\cdots+\\theta_nx_n\\)</span></p>\r\n<p>当真实值<span class=\"math inline\">\\(y\\)</span>的影响因素不是唯一时，需采用多元线性回归模型。</p>\r\n<p>代价函数： <span class=\"math display\">\\[\r\nJ(\\theta_0,\\theta_1,\\cdots,\\theta_n)=\\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x^{(i)})-y^{(i)})^{2}\r\n\\]</span> 梯度下降法： <span class=\"math display\">\\[\r\n\\theta_j:=\\theta_j-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}{(h_\\theta(x^{(i)})-y^{(i)})}\\times x_j^{(i)}\\quad (j=0,1,2\\cdots,n)\r\n\\]</span> 注意这里的<span class=\"math inline\">\\(j=0\\)</span>时，<span class=\"math inline\">\\(x_0=1\\)</span></p>\r\n<h2 id=\"示例代码-1\">示例代码：</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> numpy <span class=\"keyword\">import</span> genfromtxt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model <span class=\"comment\"># 线性回归模型</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt  </span><br><span class=\"line\"><span class=\"keyword\">from</span> mpl_toolkits.mplot3d <span class=\"keyword\">import</span> Axes3D  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读入数据 </span></span><br><span class=\"line\">data = genfromtxt(<span class=\"string\">r&quot;Delivery.csv&quot;</span>,delimiter=<span class=\"string\">&#x27;,&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 切分数据</span></span><br><span class=\"line\">x_data = data[:,:-<span class=\"number\">1</span>]</span><br><span class=\"line\">y_data = data[:,-<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建模型</span></span><br><span class=\"line\">model = linear_model.LinearRegression()</span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试</span></span><br><span class=\"line\">x_test = [[<span class=\"number\">102</span>,<span class=\"number\">4</span>]]</span><br><span class=\"line\">predict = model.predict(x_test)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;predict:&quot;</span>,predict)</span><br><span class=\"line\"></span><br><span class=\"line\">ax = plt.figure().add_subplot(<span class=\"number\">111</span>, projection = <span class=\"string\">&#x27;3d&#x27;</span>) </span><br><span class=\"line\">ax.scatter(x_data[:,<span class=\"number\">0</span>], x_data[:,<span class=\"number\">1</span>], y_data, c = <span class=\"string\">&#x27;r&#x27;</span>, marker = <span class=\"string\">&#x27;o&#x27;</span>, s = <span class=\"number\">100</span>) <span class=\"comment\">#点为红色三角形  </span></span><br><span class=\"line\">x0 = x_data[:,<span class=\"number\">0</span>]</span><br><span class=\"line\">x1 = x_data[:,<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"comment\"># 生成网格矩阵</span></span><br><span class=\"line\">x0, x1 = np.meshgrid(x0, x1)</span><br><span class=\"line\">z = model.intercept_ + x0*model.coef_[<span class=\"number\">0</span>] + x1*model.coef_[<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"comment\"># 画3D图</span></span><br><span class=\"line\">ax.plot_surface(x0, x1, z)</span><br><span class=\"line\"><span class=\"comment\">#设置坐标轴  </span></span><br><span class=\"line\">ax.set_xlabel(<span class=\"string\">&#x27;Miles&#x27;</span>)  </span><br><span class=\"line\">ax.set_ylabel(<span class=\"string\">&#x27;Num of Deliveries&#x27;</span>)  </span><br><span class=\"line\">ax.set_zlabel(<span class=\"string\">&#x27;Time&#x27;</span>)  </span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"comment\">#显示图像  </span></span><br><span class=\"line\">plt.show()  </span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230605204147960.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"多项式回归\">多项式回归</h1>\r\n<p>假如我们不是要找直线（或者超平面），而是需要找到一 个用多项式所表示的曲线（或者超曲面）</p>\r\n<p>多项式回归：<span class=\"math inline\">\\(h_\\theta(x)=\\theta_0+\\theta_1x+\\theta_2x^2+\\cdots+\\theta_nx^n\\)</span></p>\r\n<h2 id=\"示例代码-2\">示例代码：</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> PolynomialFeatures </span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.linear_model <span class=\"keyword\">import</span> LinearRegression</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 载入数据</span></span><br><span class=\"line\">data = np.genfromtxt(<span class=\"string\">&quot;job.csv&quot;</span>, delimiter=<span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">x_data = data[<span class=\"number\">1</span>:,<span class=\"number\">1</span>]</span><br><span class=\"line\">y_data = data[<span class=\"number\">1</span>:,<span class=\"number\">2</span>]</span><br><span class=\"line\">plt.scatter(x_data,y_data)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\">x_data = x_data[:,np.newaxis]</span><br><span class=\"line\">y_data = y_data[:,np.newaxis]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义多项式回归,degree的值可以调节多项式的特征</span></span><br><span class=\"line\">poly_reg  = PolynomialFeatures(degree=<span class=\"number\">5</span>) </span><br><span class=\"line\"><span class=\"comment\"># 特征处理</span></span><br><span class=\"line\">x_poly = poly_reg.fit_transform(x_data)</span><br><span class=\"line\"><span class=\"comment\"># 定义回归模型</span></span><br><span class=\"line\">lin_reg = LinearRegression()</span><br><span class=\"line\"><span class=\"comment\"># 训练模型</span></span><br><span class=\"line\">lin_reg.fit(x_poly, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\">plt.plot(x_data, y_data, <span class=\"string\">&#x27;b.&#x27;</span>)</span><br><span class=\"line\">x_test = np.linspace(<span class=\"number\">1</span>,<span class=\"number\">10</span>,<span class=\"number\">100</span>)</span><br><span class=\"line\">x_test = x_test[:,np.newaxis]</span><br><span class=\"line\">plt.plot(x_test, lin_reg.predict(poly_reg.fit_transform(x_test)), c=<span class=\"string\">&#x27;r&#x27;</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Truth or Bluff (Polynomial Regression)&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Position level&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Salary&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230605205328029.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"标准方程法normal-equation\">标准方程法（Normal Equation）</h1>\r\n<p>注意这里的符号：<span class=\"math inline\">\\(w\\)</span>其实就是上面公式里的<span class=\"math inline\">\\(\\theta\\)</span>，就是要求解的那个参数。</p>\r\n<p>假设： <span class=\"math display\">\\[\r\nh_w(x)=w_0+w_1x_1+w_2x_2+\\cdots+w_nx_n\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nh_w(x)=xw\\\r\n\\]</span></p>\r\n<p>目标函数: <span class=\"math display\">\\[\r\nJ(w_0,w_1,\\cdots,w_n)=\\frac{1}{2m}\\sum_{i=1}^{m}(h_w(x^{(i)})-y^{(i)})^{2}\r\n\\]</span> 又因为 <span class=\"math display\">\\[\r\n\\sum_{i=1}^{m}(h_w(x^{(i)})-y^{(i)})^{2}=(y-Xw)^T(y-Xw)\r\n\\]</span> 所以 <span class=\"math display\">\\[\r\n\\frac{\\partial J(w)}{\\partial w}=\\frac{\\partial(y-Xw)^T(y-Xw)}{\\partial w}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n=\\frac{\\partial(y^Ty-y^TXw-w^TX^Ty+w^TX^TXw)}{\\partial w}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n=\\frac{\\partial(y^Ty)}{\\partial w}-\\frac{\\partial(y^TXw)}{\\partial w}-\\frac{\\partial(w^TX^Ty)}{\\partial w}+\\frac{\\partial(w^TX^TXw)}{\\partial w}\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n=0-X^Ty-X^Ty+2X^TXw\r\n\\]</span></p>\r\n<p>令 <span class=\"math display\">\\[\r\n\\frac{\\partial J(w)}{\\partial w}=0\r\n\\]</span> 求解： <span class=\"math display\">\\[\r\n-2X^Ty+2X^TXw=0\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nX^TXw=X^Ty\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nw=(X^TX)^{-1}X^Ty\r\n\\]</span></p>\r\n<h1 id=\"特征缩放\"><a href=\"https://baike.baidu.com/item/%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE/17415222?fr=aladdin\">特征缩放</a></h1>\r\n<h2 id=\"数据归一化\">数据归一化</h2>\r\n<p>数据归一化就是把数据的取值范围处理为<span class=\"math inline\">\\(0-1\\)</span>，或者<span class=\"math inline\">\\(-1-1\\)</span>之间。</p>\r\n<p>任意数据转化为0-1之间： <span class=\"math display\">\\[\r\nNewValue = \\frac{OldValue-min}{max-min}\r\n\\]</span> 任意数据转化为-1-1之间： <span class=\"math display\">\\[\r\nNewValue=2\\times(\\frac{OldVaule-min}{max-min}-0.5)\r\n\\]</span></p>\r\n<h2 id=\"均值标准化\">均值标准化</h2>\r\n<p><span class=\"math inline\">\\(x\\)</span>为特征数据，<span class=\"math inline\">\\(u\\)</span>为数据的平均值，<span class=\"math inline\">\\(s\\)</span>为数据的方差。 <span class=\"math display\">\\[\r\nNewValue=\\frac{OldValue-u}{s}\r\n\\]</span></p>\r\n<h1 id=\"过拟合overfitting\">过拟合（Overfitting）</h1>\r\n<p>回归问题拟合有以下三种情况：</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230605154335888.png\"  style=\"zoom:50%;\" /></p>\r\n<p>分类问题有以下三种情况：</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230605154600447.png\" style=\"zoom:50%;\" /></p>\r\n<p>防止过拟合：减少特征；增加数据量；正则化（Regularized）</p>\r\n<h2 id=\"正则化\">正则化</h2>\r\n<p>L2正则化： <span class=\"math display\">\\[\r\nJ(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{\\theta_j^2}}]\r\n\\]</span> L1正则化： <span class=\"math display\">\\[\r\nJ(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{|\\theta_j|}}]\r\n\\]</span></p>\r\n<h1 id=\"岭回归ridge-regression\"><a href=\"https://baike.baidu.com/link?url=J428YjCOAduEv-hDj1BM53FvjQEMC1iR9icG161YvlKwmXXmtsgGoFBvkL_VK2T40KfCjPMUpQQ8ePln0cjp50QpceYEGvvCC4iewQhwY0fGCqcS9kwQCLnbARBjd0mT\">岭回归（Ridge Regression）</a></h1>\r\n<p>由标准方程法得出， <span class=\"math display\">\\[\r\nw = (𝑋^𝑇𝑋)^{-1}𝑋^𝑇y\r\n\\]</span> 如果数据的特征比样本点还多，（数据特征<span class=\"math inline\">\\(n\\)</span>，样本个数<span class=\"math inline\">\\(m\\)</span>），如果<span class=\"math inline\">\\(n&gt;m\\)</span>，<span class=\"math inline\">\\(𝑋^𝑇𝑋\\)</span>不是满秩矩阵，不可逆，计算<span class=\"math inline\">\\(𝑋^𝑇𝑋^{-1}\\)</span>时会出错。</p>\r\n<p>为了解决这个问题，引入了岭回归的概念。<span class=\"math inline\">\\(\\lambda\\)</span>为岭系数，<span class=\"math inline\">\\(I\\)</span>为单位矩阵。 <span class=\"math display\">\\[\r\nw = (𝑋^𝑇𝑋 + \\lambda I)^{-1}𝑋^𝑇y\r\n\\]</span> 推导： <span class=\"math display\">\\[\r\nJ(\\theta)=\\frac{1}{2}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{\\theta_j^2}}]\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n=\\frac{1}{2}(Xw-y)^T(Xw-y)+\\lambda w^Tw\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n=\\frac{1}{2}(w^TX^TXw-w^TX^Ty-y^TXw+y^Ty)+\\lambda w^Tw\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\n\\frac{\\partial J(w)}{\\partial w}=X^TXw-X^Ty+\\lambda w\r\n\\]</span></p>\r\n<p>令 <span class=\"math display\">\\[\r\n\\frac{\\partial J(w)}{\\partial w}=0\r\n\\]</span></p>\r\n<p><span class=\"math display\">\\[\r\nw = (𝑋^𝑇𝑋 + \\lambda I)^{-1}𝑋^𝑇y\r\n\\]</span></p>\r\n<h2 id=\"示例代码-3\">示例代码：</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> numpy <span class=\"keyword\">import</span> genfromtxt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读入数据 </span></span><br><span class=\"line\">data = genfromtxt(<span class=\"string\">r&quot;longley.csv&quot;</span>,delimiter=<span class=\"string\">&#x27;,&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 切分数据</span></span><br><span class=\"line\">x_data = data[<span class=\"number\">1</span>:,<span class=\"number\">2</span>:]</span><br><span class=\"line\">y_data = data[<span class=\"number\">1</span>:,<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建模型</span></span><br><span class=\"line\"><span class=\"comment\"># 生成50个值</span></span><br><span class=\"line\">alphas_to_test = np.linspace(<span class=\"number\">0.001</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\"><span class=\"comment\"># 创建模型，保存误差值</span></span><br><span class=\"line\">model = linear_model.RidgeCV(alphas=alphas_to_test, store_cv_values=<span class=\"literal\">True</span>)</span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 画图</span></span><br><span class=\"line\"><span class=\"comment\"># 岭系数跟loss值的关系</span></span><br><span class=\"line\">plt.plot(alphas_to_test, model.cv_values_.mean(axis=<span class=\"number\">0</span>))</span><br><span class=\"line\"><span class=\"comment\"># 选取的岭系数值的位置</span></span><br><span class=\"line\">plt.plot(model.alpha_, <span class=\"built_in\">min</span>(model.cv_values_.mean(axis=<span class=\"number\">0</span>)),<span class=\"string\">&#x27;ro&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;alphas&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;loss&#x27;</span>)</span><br><span class=\"line\">plt.show()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 测试</span></span><br><span class=\"line\">model.predict(x_data[<span class=\"number\">2</span>,np.newaxis])</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230605210828441.png\"  style=\"zoom:50%;\" /></p>\r\n<h1 id=\"lassoleast-absolute-shrinkage-and\">[LASSO（Least Absolute Shrinkage and</h1>\r\n<p>Selectionator operator）](https://baike.baidu.com/item/Lasso%E7%AE%97%E6%B3%95/22685468?fromtitle=LASSO&amp;fromid=20366865&amp;fr=aladdin)</p>\r\n<p>LASSO的代价函数： <span class=\"math display\">\\[\r\nJ(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{|\\theta_j|}}]\r\n\\]</span></p>\r\n<h2 id=\"示例代码-4\">示例代码：</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> numpy <span class=\"keyword\">import</span> genfromtxt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读入数据 </span></span><br><span class=\"line\">data = genfromtxt(<span class=\"string\">r&quot;longley.csv&quot;</span>,delimiter=<span class=\"string\">&#x27;,&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 切分数据</span></span><br><span class=\"line\">x_data = data[<span class=\"number\">1</span>:,<span class=\"number\">2</span>:]</span><br><span class=\"line\">y_data = data[<span class=\"number\">1</span>:,<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并拟合模型</span></span><br><span class=\"line\">model = linear_model.LassoCV()</span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># lasso系数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(model.alpha_)</span><br><span class=\"line\"><span class=\"comment\"># 相关系数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(model.coef_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 预测</span></span><br><span class=\"line\">model.predict(x_data[-<span class=\"number\">2</span>,np.newaxis])</span><br></pre></td></tr></table></figure>\r\n<h1 id=\"弹性网elastic-net\">弹性网（Elastic Net）</h1>\r\n<p>在<span class=\"math inline\">\\(q\\)</span>取不同值情况下的代价函数 <span class=\"math display\">\\[\r\nJ(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{|\\theta_j|^q}}]\r\n\\]</span> <img src=\"/imgs/$%7Bfiilename%7D/image-20230605164458909.png\"  style=\"zoom:50%;\" /></p>\r\n<p>Elastic Net的代价函数： <span class=\"math display\">\\[\r\nJ(\\theta)=\\frac{1}{2m}[\\sum_{i=1}^{m}{h_\\theta(x^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}{\\alpha\\theta_j^2+(1-\\alpha)|\\theta_j|}}]\r\n\\]</span></p>\r\n<h2 id=\"示例代码-5\">示例代码：</h2>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> numpy <span class=\"keyword\">import</span> genfromtxt</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读入数据 </span></span><br><span class=\"line\">data = genfromtxt(<span class=\"string\">r&quot;longley.csv&quot;</span>,delimiter=<span class=\"string\">&#x27;,&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 切分数据</span></span><br><span class=\"line\">x_data = data[<span class=\"number\">1</span>:,<span class=\"number\">2</span>:]</span><br><span class=\"line\">y_data = data[<span class=\"number\">1</span>:,<span class=\"number\">1</span>]</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x_data)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建并拟合模型</span></span><br><span class=\"line\">model = linear_model.ElasticNetCV()</span><br><span class=\"line\">model.fit(x_data, y_data)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 弹性网系数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(model.alpha_)</span><br><span class=\"line\"><span class=\"comment\"># 相关系数</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(model.coef_)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 预测</span></span><br><span class=\"line\">model.predict(x_data[-<span class=\"number\">2</span>,np.newaxis])</span><br></pre></td></tr></table></figure>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://www.bilibili.com/video/BV1Rt411q7WJ?p=23&amp;vd_source=fe8e916be2bd597efffd8dfd95249141\">线性回归及其非线性回归</a></p>\r\n",
            "tags": [
                "Python",
                "Jupyter Notebook"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E8%B7%91%E9%80%9Assd-pytorch/",
            "url": "https://liujk6525.github.io/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E8%B7%91%E9%80%9Assd-pytorch/",
            "title": "跑通ssd.pytorch",
            "date_published": "2023-05-31T02:16:02.000Z",
            "content_html": "<p><strong>补：</strong></p>\r\n<h1 id=\"expected-a-cuda-device-type-for-generator-but-found-cpu\">Expected a ‘cuda‘ device type for generator but found ‘cpu‘</h1>\r\n<p>后来我在服务器训练的时候，发现出bug了。原来是<code>Pytorch</code>版本的原因，我在<code>faster-rcnn-pytorch</code>这个项目跑的，里面有现成的VOC数据集。但是这个环境<code>Pytorch</code>是1.9。</p>\r\n<ol type=\"1\">\r\n<li><p>修改<code>/root/miniconda3/lib/python3.7/site-packages/torch/utils/data/sampler.py</code>中代码，修改结果如下。</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">generator = torch.Generator(device=<span class=\"string\">&#x27;cuda&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">yield</span> <span class=\"keyword\">from</span> torch.randperm(n, generator=generator, device=<span class=\"string\">&#x27;cuda&#x27;</span>).tolist()</span><br></pre></td></tr></table></figure>\r\n<span id=\"more\"></span></li>\r\n<li><p>修改<code>train.py</code>中代码，修改结果如下。</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data_loader = data.DataLoader(dataset, args.batch_size,</span><br><span class=\"line\">                                  num_workers=args.num_workers,</span><br><span class=\"line\">                                  shuffle=<span class=\"literal\">True</span>, collate_fn=detection_collate,</span><br><span class=\"line\">                                  pin_memory=<span class=\"literal\">True</span>, generator=torch.Generator(device=<span class=\"string\">&#x27;cuda&#x27;</span>))</span><br></pre></td></tr></table></figure></li>\r\n</ol>\r\n<h1 id=\"w-pthreadpool-cpp.cc90-warningleaking-caffe2-thread-pool-after-fork.function-pthreadpool\">[W pthreadpool-cpp.cc:90] Warning:Leaking Caffe2 thread-pool after fork.(function pthreadpool)</h1>\r\n<p>线程撕裂，出现了警告，警告数量为设置的线程数量，如果把线程数改小一些，就不会有警告了，但是会影响运行速度。修改<code>train.py</code>中的代码，修改结果如下。</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data_loader = data.DataLoader(dataset, args.batch_size,</span><br><span class=\"line\">                                 num_workers=args.num_workers,</span><br><span class=\"line\">                                 shuffle=<span class=\"literal\">True</span>, collate_fn=detection_collate,</span><br><span class=\"line\">                                 pin_memory=<span class=\"literal\">False</span>,generator=torch.Generator(device=<span class=\"string\">&#x27;cuda&#x27;</span>))</span><br></pre></td></tr></table></figure>\r\n<hr />\r\n<p>然后我想在服务器上用<code>visdom</code>看训练结果图，bug出现了。</p>\r\n<h1 id=\"nameerror-name-viz-is-not-defined\">NameError: name ‘viz’ is not defined</h1>\r\n<p>修改<code>train.py</code>中的代码，修改结果如下。</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> visdom</span><br><span class=\"line\"><span class=\"keyword\">global</span> viz</span><br><span class=\"line\">viz = visdom.Visdom()</span><br></pre></td></tr></table></figure>\r\n<h1 id=\"assertionerror-must-define-a-window-to-update\">AssertionError: Must define a window to update</h1>\r\n<p>修改<code>train.py</code>中的代码，修改结果如下。</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> args.visdom <span class=\"keyword\">and</span> iteration != <span class=\"number\">0</span> <span class=\"keyword\">and</span> (iteration % epoch_size == <span class=\"number\">0</span>):</span><br><span class=\"line\">    epoch += <span class=\"number\">1</span></span><br><span class=\"line\">    update_vis_plot(epoch, loc_loss, conf_loss, epoch_plot, <span class=\"literal\">None</span>,</span><br></pre></td></tr></table></figure>\r\n<h1 id=\"legacy-autograd-function-with-non-static-forward-method-is-deprecated\">Legacy autograd function with non-static forward method is deprecated</h1>\r\n<p>原因是当前版本要求forward过程是静态的，所以需要将原代码进行修改。</p>\r\n<ol type=\"1\">\r\n<li><p>从<a href=\"https://github.com/sayakbanerjee1999/Single-Shot-Object-Detection-Updated/blob/master/detection.py\"><code>Single-Shot-Object-Detection-Updated</code></a>下载<code>detect.py</code>文件，并将其替换掉原来的<code>layers/functions/detection.py</code></p></li>\r\n<li><p>修改<code>ssd.py</code>中的代码，修改结果如下。</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> phase == <span class=\"string\">&#x27;test&#x27;</span>:</span><br><span class=\"line\">        self.softmax = nn.Softmax(dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\">        self.detect = Detect()</span><br></pre></td></tr></table></figure>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> self.phase == <span class=\"string\">&quot;test&quot;</span>:</span><br><span class=\"line\">        output = self.detect.apply(self.num_classes, <span class=\"number\">0</span>, <span class=\"number\">200</span>, <span class=\"number\">0.01</span>, <span class=\"number\">0.45</span>,</span><br><span class=\"line\">                                   loc.view(loc.size(<span class=\"number\">0</span>), -<span class=\"number\">1</span>, <span class=\"number\">4</span>),  <span class=\"comment\"># loc preds</span></span><br><span class=\"line\">                                   self.softmax(conf.view(-<span class=\"number\">1</span>, self.num_classes)),  <span class=\"comment\"># conf preds</span></span><br><span class=\"line\">                                   self.priors.<span class=\"built_in\">type</span>(<span class=\"built_in\">type</span>(x.data))  <span class=\"comment\"># default boxes</span></span><br><span class=\"line\">                                   )</span><br></pre></td></tr></table></figure></li>\r\n</ol>\r\n<h1 id=\"errno-2-no-such-file-or-directory-test.txt\">[Errno 2] No such file or directory: ‘test.txt’</h1>\r\n<p>修改<code>eval.py</code>中的代码，修改结果如下。</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">imgsetpath = os.path.join(args.voc_root, <span class=\"string\">&#x27;VOC2007&#x27;</span>, <span class=\"string\">&#x27;ImageSets&#x27;</span>, <span class=\"string\">&#x27;Main&#x27;</span>, <span class=\"string\">&#x27;&#123;&#125;.txt&#x27;</span>)</span><br></pre></td></tr></table></figure>\r\n<hr />\r\n<p>做实验对比，所以需要跑通ssd，这里部署的pytroch版本，大佬项目<a href=\"https://github.com/amdegroot/ssd.pytorch\"><code>ssd.pytorch</code></a>，中间踩了不少坑，记录如下</p>\r\n<p>目标：ssd.pytorch</p>\r\n<p>环境：cuda 11.3 | pytorch 1.8.1</p>\r\n<h1 id=\"修改xml文件的绝对路径\">修改xml文件的绝对路径</h1>\r\n<p>这是在之前的电脑打的标签，所以VOC数据集里面的标注文件.xml里面的<code>&lt;path&gt;</code>值还是老路径，</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230531102209091.png\"  style=\"zoom: 67%;\" /></p>\r\n<p>这里我更改成新的路径。</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230531102832023.png\"  style=\"zoom: 65%;\" /></p>\r\n<h1 id=\"indexerrorinvalid-index-of-a-0-dim-tensor\">IndexError:invalid index of a 0-dim tensor…</h1>\r\n<p>修改<code>train.py</code>中代码，<code>.data[0]</code>写法不适用高版本的Pytorch，修改结果如下。</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loc_loss += loss_l.item()</span><br><span class=\"line\">conf_loss += loss_c.item()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> iteration % <span class=\"number\">10</span> == <span class=\"number\">0</span>:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;timer: %.4f sec.&#x27;</span> % (t1 - t0))</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;iter &#x27;</span> + <span class=\"built_in\">repr</span>(iteration) + <span class=\"string\">&#x27; || Loss: %.4f ||&#x27;</span> % (loss.item()), end=<span class=\"string\">&#x27; &#x27;</span>)</span><br></pre></td></tr></table></figure>\r\n<h1 id=\"stopinteration\">StopInteration…</h1>\r\n<p>修改<code>train.py</code>中代码，修改结果如下。</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">try</span>:</span><br><span class=\"line\">    images, targets = <span class=\"built_in\">next</span>(batch_iterator)</span><br><span class=\"line\"><span class=\"keyword\">except</span> StopIteration:</span><br><span class=\"line\">    batch_iterator = <span class=\"built_in\">iter</span>(data_loader)</span><br><span class=\"line\">    images, targets = <span class=\"built_in\">next</span>(batch_iterator)</span><br></pre></td></tr></table></figure>\r\n<h1 id=\"indexerror-the-shape-of-the-mask-14-8732-at-index-0does\">IndexError: The shape of the mask [14, 8732] at index 0does…</h1>\r\n<p>交换<code>layers/modules/multibox_loss.py</code>中代码位置，修改结果如下。</p>\r\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loss_c = loss_c.view(num, -1)</span><br><span class=\"line\">loss_c[pos] = 0  # filter out pos boxes for now</span><br></pre></td></tr></table></figure>\r\n<h1 id=\"lossnan\">loss：NAN</h1>\r\n<p>如果lr设置过高，可能会导致训练过程中loss出现NAN的情况。它默认的参数是1e-3，我这里将学习率修改为1e-4。</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">parser.add_argument(<span class=\"string\">&#x27;--lr&#x27;</span>, <span class=\"string\">&#x27;--learning-rate&#x27;</span>, default=<span class=\"number\">1e-4</span>, <span class=\"built_in\">type</span>=<span class=\"built_in\">float</span>,</span><br></pre></td></tr></table></figure>\r\n<h1 id=\"警告\">警告</h1>\r\n<p><strong>UserWarning: size_average and reduce args will be deprecated, please use reduction=‘sum’ instead. warnings.warn(warning.format(ret))</strong></p>\r\n<p>在高版本的Pytorch中，<code>size_average</code>和<code>reduce</code>这两个参数都将不再支持，修改<code>multibox_loss.py</code>中代码，修改结果如下。</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loss_l = F.smooth_l1_loss(loc_p, loc_t, reduction=<span class=\"string\">&#x27;sum&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">loss_c = F.cross_entropy(conf_p, targets_weighted, reduction=<span class=\"string\">&#x27;sum&#x27;</span>)</span><br></pre></td></tr></table></figure>\r\n<p><strong>UserWarning: volatile was removed and now has no effect. Use ‘with torch.no_grad():’ instead.</strong></p>\r\n<p>版本问题，修改<code>ssd.py</code>中代码，修改结果如下。</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">\tself.priors = Variable(self.priorbox.forward())</span><br></pre></td></tr></table></figure>\r\n<p><strong>UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_ .init.xavier_uniform(param)</strong></p>\r\n<p><code>nn.init.xavier_uniform</code>是以前的版本使用的，在高版本的Pytorch中已经被弃用。修改<code>train.py</code>中代码，修改结果如下。</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">xavier</span>(<span class=\"params\">param</span>):</span><br><span class=\"line\">    init.xavier_uniform_(param)</span><br></pre></td></tr></table></figure>\r\n<p>可以发现很多警告就是版本不匹配的问题，但我是抱着只要能运行的心态，然而<code>UserWarning</code>又很影响观感，那就直接屏蔽它！</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> warnings</span><br><span class=\"line\"></span><br><span class=\"line\">warnings.filterwarnings(<span class=\"string\">&#x27;ignore&#x27;</span>)</span><br></pre></td></tr></table></figure>\r\n<p>或者命令行执行<code>xx.py</code>脚本文件</p>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python -W ignore xx.py</span><br></pre></td></tr></table></figure>\r\n<h1 id=\"运行train.py文件\">运行train.py文件</h1>\r\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python -W ignore train.py</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230531115820400.png\" style=\"zoom: 67%;\" /></p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"amdegroot/ssd.pytorch/issues/421\"><code>amdegroot/ssd.pytorch/issues/421</code></a></p>\r\n<p><a href=\"https://blog.csdn.net/qq_39506912/article/details/116926504?spm=1001.2014.3001.5506\"><code>SSD训练自己的数据集（pytorch版）</code></a></p>\r\n<p><a href=\"https://www.cnblogs.com/shaoxx333/p/16181651.html\"><code>Pytorch搭建SSD模型踩坑集锦</code></a></p>\r\n<p><a href=\"https://www.yii666.com/blog/407628.html\"><code>SSD训练数据集流程（学习记录）</code></a></p>\r\n",
            "tags": [
                "Python",
                "ssd.pytorch"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E8%B7%91%E9%80%9AYolo-v5/",
            "url": "https://liujk6525.github.io/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E8%B7%91%E9%80%9AYolo-v5/",
            "title": "wii11系统跑通Yolo-v5",
            "date_published": "2023-05-27T02:06:35.000Z",
            "content_html": "<p>之前跑Yolo-v5是在服务器跑的，现在把权重文件跑完了，正好最近换了新电脑，在本地部署跑跑看，记录如下：</p>\r\n<p>复现<img src=\"/imgs/$%7Bfiilename%7D/b3809ce4a80e96cf09f6d500abed0fbd_129107_720_720.jpg\"  style=\"zoom:5%;\" />大佬们的项目之前一定要看这个项目所需的配置环境，掉大坑！！！</p>\r\n<p>目标：Yolo-v5 v6.1版本</p>\r\n<p>环境：cuda 11.3 | pytorch 1.8.1</p>\r\n<span id=\"more\"></span>\r\n<h1 id=\"安装anaconda3\">安装Anaconda3</h1>\r\n<p><a href=\"https://www.anaconda.com/\"><code>anaconda官网</code></a></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527104222716.png\" alt=\"image-20230527104222716\" style=\"zoom:33%;\" /></p>\r\n<p>直接点击<code>Download</code>下载安装包，双击安装</p>\r\n<p>我把<code>Anaconda</code>安装在D盘了</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527105216332.png\"  style=\"zoom: 67%;\" /></p>\r\n<h1 id=\"安装cuda\">安装CUDA</h1>\r\n<p>安装之前先看下自己电脑配置条件，在终端输入</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nvidia-smi</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527105741395.png\"  style=\"zoom: 50%;\" /></p>\r\n<p>可以看到<code>Driver Version: 512.98</code></p>\r\n<p>在对照<a href=\"https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html\"><code>nvidia官网显卡驱动</code></a>给出的版本要求选择CUDA版本，这里我选择的是<code>CUDA 11.3</code></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527110416589.png\"  style=\"zoom: 33%;\" /></p>\r\n<p>然后来到<a href=\"https://developer.nvidia.com/cuda-toolkit-archive\"><code>CUDA Toolkit Archive</code></a>，</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527111819649.png\"  style=\"zoom:50%;\" /></p>\r\n<p>点击<code>CUDA Toolkit 11.3.1</code>即可跳转到<a href=\"https://developer.nvidia.com/cuda-11-3-1-download-archive?target_os=Windows&amp;target_arch=x86_64&amp;target_version=10&amp;target_type=exe_local\"><code>CUDA Toolkit 11.3 Update 1 Downloads</code></a></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527112055726.png\"  style=\"zoom: 33%;\" /></p>\r\n<p>直接点击<code>Download(2.7GB)</code>下载安装包，双击安装</p>\r\n<p>这里选择<code>自定义(c)(高级)</code></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527113136663.png\"  style=\"zoom:50%;\" /></p>\r\n<p>选择驱动程序组件时，视情况而定；我这里取消勾选<code>Driver components</code>和<code>Other components</code>，因为当前版本已经安装了。</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527113247098.png\"  style=\"zoom:50%;\" /></p>\r\n<p>点击<code>下一步</code>，等待安装完成。</p>\r\n<h1 id=\"配置cudnn\">配置cuDNN</h1>\r\n<p>进入Nvidia官网<a href=\"https://developer.nvidia.com/rdp/cudnn-archive\"><code>cuDNN Archive</code></a>，选择<code>for CUDA 11.X</code>的。</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527114836975.png\" style=\"zoom:33%;\" /></p>\r\n<p>我这里选择的是<code>v8.8.0</code>版本的，点击<code>Local Install for Windows(Zip)</code>下载</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527114635962.png\"  style=\"zoom: 33%;\" /></p>\r\n<p>解压后里面有三个文件<span class=\"math inline\">\\(bin|include|lib\\)</span></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527123944344.png\"  style=\"zoom: 43%;\" /></p>\r\n<p>将其复制到CUDA安装目录就好了，我这里把CUDA安装在D盘了。</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527124408026.png\"  style=\"zoom:33%;\" /></p>\r\n<h1 id=\"安装pytorch\">安装pytorch</h1>\r\n<p>打开<code>Anaconda Prompt</code>，输入如下命令，创建一个虚拟环境，我这里命名为yolov5；</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda create -n yolov5 python=3.8</span><br></pre></td></tr></table></figure>\r\n<p>所用到的各种包都是在yolov5这个虚拟环境下配置的，所以需要激活yolov5环境</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda activate yolov5</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527131627319.png\"  style=\"zoom:50%;\" /></p>\r\n<p>进入Pytorch官网<a href=\"https://pytorch.org/get-started/previous-versions/#installing-previous-versions-of-pytorch\"><code>Installing Previous Versions Of Pytorch</code></a></p>\r\n<p><strong>conda install 安装</strong></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527130150777.png\"  style=\"zoom: 50%;\" /></p>\r\n<p>我这里是安装的CUDA 11.3，输入以下指令</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda install pytorch==1.8.1 torchvision==0.9.1 torchaudio==0.8.1 cudatoolkit=11.3 -c pytorch -c conda-forge</span><br></pre></td></tr></table></figure>\r\n<p><code>-c pytorch</code> 表示在pytorch的官网下载；<code>-c conda-forge</code> 表示在conda官网下载</p>\r\n<p>但是pytorch官网只有cpu版本的，conda索性找不到了。好在CUDA是向下兼容的，最后选择用pip install的方式下载了。</p>\r\n<p><strong>pip install 安装</strong></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527130231273.png\"  style=\"zoom: 50%;\" /></p>\r\n<p>最后选择的CUDA 11.1，输入以下指令；</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html</span><br></pre></td></tr></table></figure>\r\n<p>到这里pytorch环境就配置好了！</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527133453540.png\"  style=\"zoom: 67%;\" /></p>\r\n<h1 id=\"下载yolo-v5源代码\">下载Yolo-v5源代码</h1>\r\n<p>Yolo-v5更新的很快，但我当时用服务器跑的时候下载的v6.1版本，所以用git bash下载文件。</p>\r\n<p>我是在<code>Pycharm Projects</code>里面创建一个文件夹<code>Yolov5</code>，然后右击选择<code>Git Bash Here</code></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527134730082.png\"  style=\"zoom: 50%;\" /></p>\r\n<p> ifconfigbash</p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> -b v6.1 https://github.com/ultralytics/yolov5.git</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527134152555.png\"  style=\"zoom:50%;\" /></p>\r\n<p>这样就把源代码下载完成了，我这里把它重命名了<code>yolov5-6.1</code>，</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527135851656.png\"  style=\"zoom: 40%;\" /></p>\r\n<p>接下来从requirements.txt安装所需要的包。打开<code>Anaconda Prompt</code>，cd到yolov5-6.1文件夹</p>\r\n<p>我这里是<code>E:\\Pycharm Projects\\Yolov5\\yolov5-6.1</code></p>\r\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527140112538.png\" alt=\"image-20230527140112538\" style=\"zoom:50%;\" /></p>\r\n<p>到这里就全部部署完成好了，接下来就是把自己的权重文件替换成yolov5的预训练权重文件yolov5.pt。</p>\r\n<p>执行detect.py，测试了一下。</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-1317.jpg\"  style=\"zoom: 45%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-1685.jpg\"  style=\"zoom:45%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230527141712871.png\"  style=\"zoom:40%;\" /></p>\r\n<p>还是能较好的把可采摘的苹果和被遮挡的苹果识别出来。</p>\r\n",
            "tags": [
                "Python",
                "Yolov5"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/%E5%9F%BA%E4%BA%8E%E9%87%87%E6%A0%B7%E7%9A%84%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/",
            "url": "https://liujk6525.github.io/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/%E5%9F%BA%E4%BA%8E%E9%87%87%E6%A0%B7%E7%9A%84%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/",
            "title": "基于采样的路径规划",
            "date_published": "2023-05-13T13:41:15.000Z",
            "content_html": "<h1 id=\"基础知识\">基础知识</h1>\r\n<p>虽然<code>基于图搜索的路径规划算法</code>能够给出一个<strong>全局范围内的最优解</strong>，但是当地图过大，空间维度过高时，它的搜索效率就会变得很慢。主要用于低维空间的路径规划问题。</p>\r\n<span id=\"more\"></span>\r\n<h2 id=\"概率路图算法probabilistic-road-map-prm\">概率路图算法(Probabilistic Road Map, <a href=\"https://en.wikipedia.org/wiki/Probabilistic_roadmap\"><code>PRM</code></a>)</h2>\r\n<p><code>PRM</code>算法首先使用随机采样的方式在环境中建立路径网络图，将连续的空间转换为离散的空间，然后在路径网络图上进行路径规划，解决在高维空间中搜索效率低的问题</p>\r\n<p>算法流程</p>\r\n<p>​ <img src=\"/imgs/$%7Bfiilename%7D/prm.png\"  style=\"zoom: 80%;\" /></p>\r\n<p><strong>采样点的数量</strong>和<strong>采样点间存在通道的最大距离</strong>是关键参数，具体的</p>\r\n<p>采样点的数量太少，可能会导致路径规划失败，因为生成的概率路线少了。</p>\r\n<p>随着采样点数量增加，结果会越来越接近最短路径，但同时搜索效率会降低</p>\r\n<h2 id=\"快速扩展随机树rapidly-exploring-random-tree-rrt算法\">快速扩展随机树(Rapidly-exploring Random Tree, <a href=\"https://en.wikipedia.org/wiki/Rapidly-exploring_random_tree\"><code>RRT</code></a>)算法</h2>\r\n<p><code>RRT</code>算法是一种单查询(single-query)算法，搜索过程就像一棵树不断向周围扩展生长。它的复杂度不受地图的离散程度影响，在高维空间中具有很高的搜索效率。</p>\r\n<p>​ <img src=\"/imgs/$%7Bfiilename%7D/RRT.png\"  style=\"zoom:80%;\" /></p>\r\n<p>缺点：只管尽快地找到可行路径，所以最终路径并不是最优的，甚至会非常“绕”。</p>\r\n<h2 id=\"双向快速扩展随机树rrt-connect算法\">双向快速扩展随机树(<a href=\"https://ieeexplore.ieee.org/document/844730\"><code>RRT-Connect</code></a>)算法</h2>\r\n<p>在<code>RRT</code>的基础上引入了双向扩展环节，分别以起点和目标点为根节点生成两棵树进行双向扩展，<strong>加快了搜索速度</strong>，当两棵树建立连接时被认为路径规划成功。</p>\r\n<p>缺点：但是<code>RRT-Connect</code>和<code>RRT</code>一样，都是单查询算法，最终路径并不是最优的。</p>\r\n<h2 id=\"rrt算法\"><a href=\"https://arxiv.org/abs/1105.1186\"><code>RRT*</code></a>算法</h2>\r\n<p><code>RRT*</code>算法是一种渐近最优算法。在<code>RRT</code>算法的基础上，增加了将<span class=\"math inline\">\\(X_{rand}\\)</span>加入搜索树 T 时<strong>父节点的选择策略</strong>。</p>\r\n<p><code>RRT*</code>算法在选择父节点时会有一个<strong>重连(Rewire)</strong>过程，也就是在以<span class=\"math inline\">\\(X_{rand}\\)</span>为圆心、半径为<span class=\"math inline\">\\(r\\)</span>的邻域内，找到与<span class=\"math inline\">\\(X_{new}\\)</span>连接后移动代价(从起点移动到<span class=\"math inline\">\\(X_{new}\\)</span>的路径长度)最小的节点，并重新选择<span class=\"math inline\">\\(X_{min}\\)</span>作为<span class=\"math inline\">\\(X_{new}\\)</span>的父节点，而不是<span class=\"math inline\">\\(X_{near}\\)</span>。</p>\r\n<p>简单理解就是<span class=\"math inline\">\\(Xnear\\)</span>产生了<span class=\"math inline\">\\(Xnew\\)</span>,然而<span class=\"math inline\">\\(Xnew\\)</span>抛弃了<span class=\"math inline\">\\(Xnear\\)</span>，选择了移动代价最小的<span class=\"math inline\">\\(Xmin\\)</span>作为父节点。</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/v2-1b532a8161587f211b6a7a3c9e239589_720w.webp\"  style=\"zoom: 67%;\" /></p>\r\n<p>缺点：<code>RRT*</code>*是对自由空间进行均匀采样，搜索树上会生成很多冗余的分支，所以<code>RRT*</code>的收敛速度很慢。</p>\r\n<h2 id=\"informed-rrt算法\"><a href=\"https://arxiv.org/abs/1404.2334\"><code>Informed-RRT*</code></a>算法</h2>\r\n<p>对<code>RRT*</code>的改进策略：采用椭圆采样来代替全局均匀采样</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230514175249529.png\"  style=\"zoom: 50%;\" /></p>\r\n<p>以起点 <span class=\"math inline\">\\(X_{start}\\)</span>和终点<span class=\"math inline\">\\(X_{goal}\\)</span>作为椭圆的焦点，令<span class=\"math inline\">\\(a\\)</span>等于初始路径长度<span class=\"math inline\">\\(c_{best}\\)</span>的一半，即<span class=\"math inline\">\\(a=\\frac{c_{best}}{2}\\)</span>，则$ c=<span class=\"math inline\">\\(，\\)</span>b=$，这样就可以得到椭圆方程的所有参数。</p>\r\n<p>在之后的迭代中，如果没找到更短的路径，就用<span class=\"math inline\">\\(c_{min}\\)</span>作为新的<span class=\"math inline\">\\(c_{best}\\)</span>，然后在新的椭圆区域进行采样。</p>\r\n<h1 id=\"代码实现\">代码实现</h1>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230514234320378.png\"  style=\"zoom:80%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230514234432119.png\"  style=\"zoom:80%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230514234602917.png\"  style=\"zoom:80%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/image-20230514234911888.png\"  style=\"zoom:80%;\" /></p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://zhuanlan.zhihu.com/p/349074802\"><code>路径规划 | 随机采样算法：PRM、RRT、RRT-Connect、RRT*</code></a></p>\r\n<p><a href=\"https://zhuanlan.zhihu.com/p/372315811\"><code>路径规划 | 随机采样算法：Informed-RRT*</code></a></p>\r\n<p><a href=\"https://www.bilibili.com/video/BV1yT4y1T7Eb?p=5\"><code>机器人路径规划、轨迹优化系列课程</code></a></p>\r\n<p>[1] Lavalle S M . Rapidly-Exploring Random Trees: A New Tool for Path Planning[J]. Research Report, 1999.</p>\r\n<p>[2] Jr J , Lavalle S M . RRT-Connect: An Efficient Approach to Single-Query Path Planning[C]// Proceedings of the 2000 IEEE International Conference on Robotics and Automation, ICRA 2000, April 24-28, 2000, San Francisco, CA, USA. IEEE, 2000.</p>\r\n<p>[3] Karaman S , Frazzoli E . Sampling-based Algorithms for Optimal Motion Planning[J]. The International Journal of Robotics Research, 2011, 30(7):846-894.</p>\r\n<p>[4] Gammell J D , Srinivasa S S , Barfoot T D . Informed RRT*: Optimal Sampling-based Path Planning Focused via Direct Sampling of an Admissible Ellipsoidal Heuristic[J]. IEEE, 2014.</p>\r\n",
            "tags": [
                "python"
            ]
        },
        {
            "id": "https://liujk6525.github.io/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/%E5%9F%BA%E4%BA%8E%E6%90%9C%E7%B4%A2%E7%9A%84%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/",
            "url": "https://liujk6525.github.io/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/%E5%9F%BA%E4%BA%8E%E6%90%9C%E7%B4%A2%E7%9A%84%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/",
            "title": "基于搜索的路径规划",
            "date_published": "2023-05-12T03:36:41.000Z",
            "content_html": "<h1 id=\"基础知识\">基础知识</h1>\r\n<p><strong>图搜索法</strong>是通过利用已有的环境地图和障碍物等数据信息，建立由起点至目标点的可行路线。</p>\r\n<p><strong>配置空间(Configuration Space)</strong> 在实际环境，要将工作空间转换到配置空间中，即将机器人转化为一个<strong>质点</strong>，同时将障碍物按照机器人的体积进行膨胀</p>\r\n<span id=\"more\"></span>\r\n<h2 id=\"基本流程\">基本流程</h2>\r\n<ul>\r\n<li>在容器<code>open list</code>中存放将要访问的节点</li>\r\n<li>将起点加入容器</li>\r\n<li>While True：</li>\r\n<li>弹出：从容器中取出一个节点</li>\r\n<li>扩展：将该节点周围的其他节点放入<code>open list</code></li>\r\n</ul>\r\n<h2 id=\"深度优先搜索depth-first-search-dfs-算法\">深度优先搜索(Depth First Search, <a href=\"https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\"><code>DFS</code></a> )算法</h2>\r\n<ul>\r\n<li>优先扩展搜索深度较大的节点，从起点开始，按照某个顺序一条路走下去，直至不能再继续为止，然后回到上一节点，再换另一条路走下去；</li>\r\n<li>深度优先搜索的过程是一条路走到底后，最后访问的节点最先拿来处理，整个过程可以用<code>栈(stack)</code>来表示——<strong>后进先出</strong>。</li>\r\n<li>深度优先算法优先扩展搜索深度较大的节点，因此能够更迅速的获得下一个可行路径，不过深度优先算法获取的第一个路径通常是比较长的路径。</li>\r\n</ul>\r\n<p>在<strong>无权图</strong>中找到从节点<code>a</code>到节点<code>j</code>的路径为例</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/dfs.png\"  style=\"zoom:80%;\" /></p>\r\n<p>按照<code>DFS</code>的基本流程搜索<code>a</code>到<code>j</code>的路径：</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/dfs-1683872034517-4.png\"  style=\"zoom:80%;\" /></p>\r\n<p>从目标点开始回溯：<code>a-&gt;b-&gt;f-&gt;j</code></p>\r\n<h2 id=\"广度优先搜索breadth-first-search-bfs算法\">广度优先搜索(Breadth First Search, <a href=\"https://zh.wikipedia.org/zh-hans/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\"><code>BFS</code></a>)算法</h2>\r\n<ul>\r\n<li><p>每一步都扩展同一层的所有可能节点，一层一层扩展下去，直到某一层搜索到终点为止。</p></li>\r\n<li><p>广度优先搜索的过程是一层中先访问的节点拿来处理，可以用<code>队列(queue)</code>来表示——<strong>先进先出</strong>。</p></li>\r\n<li><p>广度优先算法优先扩展深入较小的节点，呈<strong>波状推进</strong>的形式搜索。因此广度优先算法检索到的第一个路径通常是最短路径。</p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/bfs.png\"   style=\"zoom:80%;\" /></p></li>\r\n</ul>\r\n<h2 id=\"贪婪最佳优先搜索greedy-best-first-searchgbfs-算法\">贪婪最佳优先搜索(Greedy Best First Search,<a href=\"https://www.codecademy.com/resources/docs/ai/search-algorithms/greedy-best-first-search\"><code>GBFS</code></a> )算法</h2>\r\n<p>使用的是<strong>优先队列(Priority Queue)</strong>，普通队列是一种<strong>先进先出</strong>的数据结构，而在优先队列中元素被赋予了优先级，最高优先级元素优先删除，也就是<code>first in</code>, <code>largest out</code></p>\r\n<p>在图搜索算法中，优先级判断的标准是代价函数 <span class=\"math inline\">\\(f(n)\\)</span> ， <span class=\"math inline\">\\(f(n)\\)</span> 越小，优先级越高。</p>\r\n<p><span class=\"math display\">\\[\r\nf(n)=h(n)\r\n\\]</span></p>\r\n<p><span class=\"math inline\">\\(h(n)\\)</span>是启发式函数，为节点<span class=\"math inline\">\\(n\\)</span>到目标节点之间所形成路径的最小代价值。一般为<a href=\"https://zh.wikipedia.org/wiki/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E8%B7%9D%E7%A6%BB\"><code>欧氏距离</code></a>或者<a href=\"https://zh.wikipedia.org/wiki/%E6%9B%BC%E5%93%88%E9%A0%93%E8%B7%9D%E9%9B%A2\"><code>曼哈顿距离</code></a></p>\r\n<p>遇到障碍物时，它很容易陷入局部最优的陷阱。</p>\r\n<h1 id=\"dijkstra算法\"><a href=\"https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95\"><code>Dijkstra</code></a>算法</h1>\r\n<p>Dijkstra算法是从一个顶点到其余各顶点的最短路径算法，其流程仍然与上述算法基本一致，它也是用优先队列作为<code>open list</code>的数据结构，它和<code>GBFS</code>的区别在于代价函数 <span class=\"math inline\">\\(f(n)\\)</span>的定义:</p>\r\n<p><span class=\"math display\">\\[\r\nf(n)=g(n)\r\n\\]</span> <span class=\"math inline\">\\(g(n)\\)</span>表示从起始节点到当前节点<span class=\"math inline\">\\(n\\)</span>的移动代价函数。</p>\r\n<p>计算起点<code>v1</code>到终点<code>v6</code>的最短路径，箭头上的数值表示<strong>两个节点间的距离</strong></p>\r\n<ol type=\"1\">\r\n<li><p>首先扩展第一个节点，计算其余邻近节点与第一个节点的距离，从未扩展的节点中选择代价函数最小的节点进行扩展，并更新其余节点的代价函数</p></li>\r\n<li><p>重复进行上面的步骤，直到所有节点都已扩展。</p></li>\r\n<li><p>最后标出起点到终点的最短路径</p>\r\n<p>找到一条从<code>1</code>到<code>6</code>的最短路径</p></li>\r\n</ol>\r\n<p>​ <img src=\"/imgs/$%7Bfiilename%7D/image-20230512205640371.png\"  style=\"zoom:80%;\" /></p>\r\n<p><code>open list</code>: 4(1) 2(2) # 存储已经被搜索过但没有被访问过的节点，并对其进行排序</p>\r\n<p><code>closed list</code>:1(0) # 存储已经被访问过的节点</p>\r\n<p>从<code>open list</code>中的节点中选择距离最小的节点作为扩展节点，显然是节点4。</p>\r\n<p>​ <img src=\"/imgs/$%7Bfiilename%7D/image-20230512210430685.png\"  style=\"zoom:80%;\" /></p>\r\n<p><code>open list</code>: 2(2) 3(3) 7(5) 6(9) # 遍历邻接节点，更新距离</p>\r\n<p><code>closed list</code>: 1(0) 4(1)</p>\r\n<p>重复上述操作。选择新的扩展节点，即节点2</p>\r\n<p>​ <img src=\"/imgs/$%7Bfiilename%7D/image-20230512211350445.png\" style=\"zoom:80%;\" /></p>\r\n<p><code>open list</code>: 3(3) 7(5) <strong>6(9)</strong> 5(13)</p>\r\n<p><code>closed list</code>: 1(0) 4(1) 2(2)</p>\r\n<p>选择新的扩展节点，即节点3</p>\r\n<p>​ <img src=\"/imgs/$%7Bfiilename%7D/image-20230512212316556.png\" style=\"zoom:80%;\" /></p>\r\n<p><code>open list</code>: 7(5) <strong>6(8)</strong> 5(13) # 注意这里访问节点3，对它的领接节点6的距离进行了更新</p>\r\n<p><code>closed list</code>: 1(0) 4(1) 2(2) 3(3)</p>\r\n<p>选择新的扩展节点，即节点7</p>\r\n<p>​ <img src=\"/imgs/$%7Bfiilename%7D/image-20230512213110030.png\"  style=\"zoom:80%;\" /></p>\r\n<p><code>open list</code>: <strong>6(6)</strong> 5(13) # 注意这里访问节点7，对它的领接节点6的距离进行了更新</p>\r\n<p><code>closed list</code>: 1(0) 4(1) 2(2) 3(3) 7(5)</p>\r\n<p>​ <img src=\"/imgs/$%7Bfiilename%7D/image-20230512214147752.png\"  style=\"zoom:80%;\" /></p>\r\n<p><code>closed list</code>: 1(0) 4(1) 2(2) 3(3) 7(5) 6(6)</p>\r\n<h1 id=\"a搜索a-search算法\"><code>A*</code>搜索(<a href=\"https://zh.wikipedia.org/wiki/A*%E6%90%9C%E5%B0%8B%E6%BC%94%E7%AE%97%E6%B3%95\"><code>A* search</code></a>)算法</h1>\r\n<p><code>GBFS</code>用节点到目标点的距离作为代价函数，将搜索方向引向目标点，搜索效率高。</p>\r\n<p><code>Dijkstra</code>算法采用起点到当前扩展节点的移动代价作为代价函数，能够确保路径最优。</p>\r\n<p><code>A*</code>搜索算法在<code>Dijkstra</code>算法的基础上增加启发式函数<span class=\"math inline\">\\(h(n)\\)</span>，规定其代价函数为 <span class=\"math display\">\\[\r\nf(n)=g(n)+h(n)\r\n\\]</span></p>\r\n<h1 id=\"代码实现\">代码实现</h1>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/Astart.png\" alt=\"Astart\" style=\"zoom:80%;\" /></p>\r\n<p><img src=\"/imgs/$%7Bfiilename%7D/dijkstra.png\" alt=\"dijkstra\" style=\"zoom:80%;\" /></p>\r\n<h1 id=\"参考\">参考</h1>\r\n<p><a href=\"https://zhuanlan.zhihu.com/p/346666812\"><code>路径规划 | 图搜索算法：DFS、BFS、GBFS、Dijkstra、A*</code></a></p>\r\n<p><a href=\"https://www.bilibili.com/video/BV1yT4y1T7Eb?p=2\">机器人路径规划、轨迹优化系列课程</a></p>\r\n",
            "tags": [
                "Python"
            ]
        }
    ]
}